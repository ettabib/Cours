\documentclass[]{article}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\usepackage{graphicx}
% Redefine \includegraphics so that, unless explicit options are
% given, the image width will not exceed the width of the page.
% Images get their normal width if they fit onto the page, but
% are scaled down if they would overflow the margins.
\makeatletter
\def\ScaleIfNeeded{%
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother
\let\Oldincludegraphics\includegraphics
{%
 \catcode`\@=11\relax%
 \gdef\includegraphics{\@ifnextchar[{\Oldincludegraphics}{\Oldincludegraphics[width=\ScaleIfNeeded]}}%
}%
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={Equation differentielle lineaire d'ordre n},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}
 
/* start css.sty */
.cmr-5{font-size:50%;}
.cmr-7{font-size:70%;}
.cmmi-5{font-size:50%;font-style: italic;}
.cmmi-7{font-size:70%;font-style: italic;}
.cmmi-10{font-style: italic;}
.cmsy-5{font-size:50%;}
.cmsy-7{font-size:70%;}
.cmex-7{font-size:70%;}
.cmex-7x-x-71{font-size:49%;}
.msbm-7{font-size:70%;}
.cmtt-10{font-family: monospace;}
.cmti-10{ font-style: italic;}
.cmbx-10{ font-weight: bold;}
.cmr-17x-x-120{font-size:204%;}
.cmsl-10{font-style: oblique;}
.cmti-7x-x-71{font-size:49%; font-style: italic;}
.cmbxti-10{ font-weight: bold; font-style: italic;}
p.noindent { text-indent: 0em }
td p.noindent { text-indent: 0em; margin-top:0em; }
p.nopar { text-indent: 0em; }
p.indent{ text-indent: 1.5em }
@media print {div.crosslinks {visibility:hidden;}}
a img { border-top: 0; border-left: 0; border-right: 0; }
center { margin-top:1em; margin-bottom:1em; }
td center { margin-top:0em; margin-bottom:0em; }
.Canvas { position:relative; }
li p.indent { text-indent: 0em }
.enumerate1 {list-style-type:decimal;}
.enumerate2 {list-style-type:lower-alpha;}
.enumerate3 {list-style-type:lower-roman;}
.enumerate4 {list-style-type:upper-alpha;}
div.newtheorem { margin-bottom: 2em; margin-top: 2em;}
.obeylines-h,.obeylines-v {white-space: nowrap; }
div.obeylines-v p { margin-top:0; margin-bottom:0; }
.overline{ text-decoration:overline; }
.overline img{ border-top: 1px solid black; }
td.displaylines {text-align:center; white-space:nowrap;}
.centerline {text-align:center;}
.rightline {text-align:right;}
div.verbatim {font-family: monospace; white-space: nowrap; text-align:left; clear:both; }
.fbox {padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
div.fbox {display:table}
div.center div.fbox {text-align:center; clear:both; padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
div.minipage{width:100%;}
div.center, div.center div.center {text-align: center; margin-left:1em; margin-right:1em;}
div.center div {text-align: left;}
div.flushright, div.flushright div.flushright {text-align: right;}
div.flushright div {text-align: left;}
div.flushleft {text-align: left;}
.underline{ text-decoration:underline; }
.underline img{ border-bottom: 1px solid black; margin-bottom:1pt; }
.framebox-c, .framebox-l, .framebox-r { padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
.framebox-c {text-align:center;}
.framebox-l {text-align:left;}
.framebox-r {text-align:right;}
span.thank-mark{ vertical-align: super }
span.footnote-mark sup.textsuperscript, span.footnote-mark a sup.textsuperscript{ font-size:80%; }
div.tabular, div.center div.tabular {text-align: center; margin-top:0.5em; margin-bottom:0.5em; }
table.tabular td p{margin-top:0em;}
table.tabular {margin-left: auto; margin-right: auto;}
div.td00{ margin-left:0pt; margin-right:0pt; }
div.td01{ margin-left:0pt; margin-right:5pt; }
div.td10{ margin-left:5pt; margin-right:0pt; }
div.td11{ margin-left:5pt; margin-right:5pt; }
table[rules] {border-left:solid black 0.4pt; border-right:solid black 0.4pt; }
td.td00{ padding-left:0pt; padding-right:0pt; }
td.td01{ padding-left:0pt; padding-right:5pt; }
td.td10{ padding-left:5pt; padding-right:0pt; }
td.td11{ padding-left:5pt; padding-right:5pt; }
table[rules] {border-left:solid black 0.4pt; border-right:solid black 0.4pt; }
.hline hr, .cline hr{ height : 1px; margin:0px; }
.tabbing-right {text-align:right;}
span.TEX {letter-spacing: -0.125em; }
span.TEX span.E{ position:relative;top:0.5ex;left:-0.0417em;}
a span.TEX span.E {text-decoration: none; }
span.LATEX span.A{ position:relative; top:-0.5ex; left:-0.4em; font-size:85%;}
span.LATEX span.TEX{ position:relative; left: -0.4em; }
div.float img, div.float .caption {text-align:center;}
div.figure img, div.figure .caption {text-align:center;}
.marginpar {width:20%; float:right; text-align:left; margin-left:auto; margin-top:0.5em; font-size:85%; text-decoration:underline;}
.marginpar p{margin-top:0.4em; margin-bottom:0.4em;}
.equation td{text-align:center; vertical-align:middle; }
td.eq-no{ width:5%; }
table.equation { width:100%; } 
div.math-display, div.par-math-display{text-align:center;}
math .texttt { font-family: monospace; }
math .textit { font-style: italic; }
math .textsl { font-style: oblique; }
math .textsf { font-family: sans-serif; }
math .textbf { font-weight: bold; }
.partToc a, .partToc, .likepartToc a, .likepartToc {line-height: 200%; font-weight:bold; font-size:110%;}
.chapterToc a, .chapterToc, .likechapterToc a, .likechapterToc, .appendixToc a, .appendixToc {line-height: 200%; font-weight:bold;}
.index-item, .index-subitem, .index-subsubitem {display:block}
.caption td.id{font-weight: bold; white-space: nowrap; }
table.caption {text-align:center;}
h1.partHead{text-align: center}
p.bibitem { text-indent: -2em; margin-left: 2em; margin-top:0.6em; margin-bottom:0.6em; }
p.bibitem-p { text-indent: 0em; margin-left: 2em; margin-top:0.6em; margin-bottom:0.6em; }
.paragraphHead, .likeparagraphHead { margin-top:2em; font-weight: bold;}
.subparagraphHead, .likesubparagraphHead { font-weight: bold;}
.quote {margin-bottom:0.25em; margin-top:0.25em; margin-left:1em; margin-right:1em; text-align:justify;}
.verse{white-space:nowrap; margin-left:2em}
div.maketitle {text-align:center;}
h2.titleHead{text-align:center;}
div.maketitle{ margin-bottom: 2em; }
div.author, div.date {text-align:center;}
div.thanks{text-align:left; margin-left:10%; font-size:85%; font-style:italic; }
div.author{white-space: nowrap;}
.quotation {margin-bottom:0.25em; margin-top:0.25em; margin-left:1em; }
h1.partHead{text-align: center}
.sectionToc, .likesectionToc {margin-left:2em;}
.subsectionToc, .likesubsectionToc {margin-left:4em;}
.subsubsectionToc, .likesubsubsectionToc {margin-left:6em;}
.frenchb-nbsp{font-size:75%;}
.frenchb-thinspace{font-size:75%;}
.figure img.graphics {margin-left:10%;}
/* end css.sty */

\title{Equation differentielle lineaire d'ordre n}
\author{}
\date{}

\begin{document}
\maketitle

\textbf{Warning: 
requires JavaScript to process the mathematics on this page.\\ If your
browser supports JavaScript, be sure it is enabled.}

\begin{center}\rule{3in}{0.4pt}\end{center}

[
[
[]
[

\subsubsection{16.4 Equation différentielle linéaire d'ordre n}

\paragraph{16.4.1 Généralités}

Soit E un K espace vectoriel normé de dimension finie et considérons
\ell_0,\\ldots,\ell_n-1~
des applications continues de I intervalle de \mathbb{R}~ dans L(E). Soit g : I \rightarrow~
E continue. On peut alors considérer l'équation différentielle linéaire
d'ordre n

y^(n) = \ell_ n-1(t).y^(n-1) +
\\ldots + \ell_
0(t).y + g(t)

En introduisant la fonction inconnue Y =
(y,y',\\ldots,y^(n-1)~),
on sait que cette équation est équivalente par réduction à l'ordre 1, à
l'équation Y ' = L(t).Y + G(t) où l'on a posé
L(t).(y_0,\\ldots,y_n-1~)
=
(y_1,\\ldots,y_n-1,\ell_n-1(t).y_n-1~
+ \\ldots~ +
\ell_0(t).y_0) est clairement une application linéaire de
E^n dans lui même et où G(t) =
(0,\\ldots~,0,g(t))
est une application continue de I dans E^n. Ceci va nous
permettre d'appliquer toute la théorie des équations différentielles
linéaires d'ordre 1 aux équations différentielles linéaires d'ordre n en
tenant compte de ce que l'application
\phi\mapsto~(\phi,\phi',\\ldots,\phi^(n-1)~)
est une bijection de l'ensemble des solutions de l'équation d'ordre n,
y^(n) = \ell_n-1(t).y^(n-1) +
\\ldots~ +
\ell_0(t).y + g(t) sur l'ensemble des solutions de l'équation
linéaire d'ordre 1, Y ' = L(t).Y + G(t), cette bijection étant
visiblement linéaire dans le cas où cela a un sens, c'est-à-dire lorsque
ces deux ensembles sont des espaces vectoriels, soit encore dans le cas
d'équations homogènes g = 0 (ce qui équivaut à G = 0).

Par la suite, nous nous intéresserons exclusivement au cas où E = K (le
corps de base). Le lecteur n'aura aucun mal à formuler les résultats
dans le cas d'un E quelconque, tout au moins lorsque cela aura un sens.
L'équation différentielle d'ordre n s'écrit alors sous la forme

y^(n) = a_ n-1(t)y^(n-1) +
\\ldots + a_
0(t)y + b(t)

où les fonctions
a_0,\\ldots,a_n-1~,b
sont des fonctions continues de I dans le corps de base K. L'application
\phi\mapsto~(\phi,\phi',\\ldots,\phi^(n-1)~)
est une bijection de l'ensemble des solutions de l'équation d'ordre n
sur l'ensemble des solutions de l'équation d'ordre 1, Y ' = A(t).Y +
B(t) avec

A(t) = \left (\matrix\,0
&1&0&\\ldots~&0
\cr \⋮~
&\\ldots&\\\ldots&\\\ldots&\\⋮~
\cr 0
&\\ldots&\\\ldots~&0&1
\cr
a_0(t)&\\ldots&\\\ldots&\\\ldots&a_n-1(t)~\right
)

et

B(t) = \left (\matrix\,0
\cr \⋮~
& \cr 0 \cr b(t)\right )

cette bijection étant un isomorphisme de l'espace des solutions de
l'équation homogène y^(n) =
a_n-1(t)y^(n-1) +
\\ldots~ +
a_0(t)y sur l'espace des solutions de l'équation homogène Y ' =
A(t).Y .

\paragraph{16.4.2 Théorie de Cauchy-Lipschitz}

Le théorème suivant se déduit immédiatement du théorème correspondant
pour l'équation Y ' = L(t).Y + B(t)

Théorème~16.4.1 Soit I un intervalle de \mathbb{R}~,
a_0,\\ldots,a_n-1~,b
: I \rightarrow~ K continues. Alors toute solution maximale de l'équation
différentielle linéaire y^(n) =
a_n-1(t)y^(n-1) +
\\ldots~ +
a_0(t)y + b(t) est définie sur I. Pour tout t_0 \in I et
tout
(y_0,\\ldotsy_n-1~)
\in K^n, il existe une et une seule solution (I,\phi) de
l'équation différentielle linéaire y^(n) =
a_n-1(t)y^(n-1) +
\\ldots~ +
a_0(t)y + b(t) vérifiant \phi(t_0) =
y_0,\\ldots,\phi^(n-1)(t_0~)
= y_n-1~; pour toute solution (J,\psi) de l'équation
différentielle vérifiant \psi(t_0) =
y_0,\\ldots,\psi^(n-1)(t_0~)
= y_n-1, on a~:

\text\$J \subset~ I\$ et \$\psi\$ est la restriction de \$\phi\$ à
\$J\$.

\paragraph{16.4.3 Structure des solutions de l'équation homogène.
Wronskien}

Le théorème suivant se déduit immédiatement du théorème correspondant
pour l'équation Y ' = L(t).Y

Théorème~16.4.2 Soit I un intervalle de \mathbb{R}~,
a_0,\\ldots,a_n-1~
: I \rightarrow~ K continues. L'ensemble S_H des solutions définies sur I
de l'équation différentielle homogène y^(n) =
a_n-1(t)y^(n-1) +
\\ldots~ +
a_0(t)y est un espace vectoriel de dimension finie égale à n.
Plus précisément, pour tout t_0 \in I, l'application
\epsilon_t_0 :
\phi\mapsto~(\phi(t_0),\phi'(t_0),\\ldots,\phi^(n-1)(t_0~))
est un isomorphisme d'espaces vectoriels de S_H sur
K^n.

Corollaire~16.4.3 Pour toute famille
(\phi_1,\\ldots,\phi_k~)
de solutions de l'équation homogène, on a

\forall~~t \in I,
\mathrmrg(\phi_1,\\\ldots,\phi_k~)
=\
\mathrmrg(\epsilon_t(\phi_1),\\ldots,\epsilon_t(\phi_k~))

Dans le cas k = n ceci amène à la définition suivante

Définition~16.4.1 Soit
(\phi_1,\\ldots,\phi_n~)
des fonctions de classe C^n de I dans K. On appelle wronskien
de la famille l'application
W_\phi_1,\\ldots,\phi_n~
: I \rightarrow~ K,

t\mapsto~\mathrm{det}~
(\epsilon_t(\phi_1),\\ldots,\epsilon_t(\phi_n~))
= \left
\matrix\,\phi_1(t)
&\\ldots&\phi_n~(t)
\cr \phi_1'(t)
&\\ldots&\phi_n~'(t)
\cr
\\ldots~
&\\ldots&\\\ldots~
\cr
\phi_1^(n-1)(t)&\\ldots&\phi_n^(n-1)(t)~\right


Théorème~16.4.4 Soit I un intervalle de \mathbb{R}~,
a_0,\\ldots,a_n-1~
: I \rightarrow~ K continues. Soit
\phi_1,\\ldots,\phi_n~
des solutions de l'équation différentielle homogène y^(n) =
a_n-1(t)y^(n-1) +
\\ldots~ +
a_0(t)y et W leur wronskien. Alors les conditions suivantes
sont équivalentes

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i)
  (\phi_1,\\ldots,\phi_n~)
  est une base de l'espace vectoriel S_H des solutions de
  l'équation homogène y^(n) =
  a_n-1(t)y^(n-1) +
  \\ldots~ +
  a_0(t)y
\item
  (ii) \exists~t \in I,
  W(t)\neq~0
\item
  (iii) \forall~~t \in I,
  W(t)\neq~0
\end{itemize}

Démonstration Puisque \epsilon_t est un isomorphisme de S_H
sur K^n,
(\phi_1,\\ldots,\phi_n~)
est une base de S_H si et seulement
si~(\epsilon_t(\phi_1),\\ldots,\epsilon_t(\phi_n~))
est une base de K^n, c'est-à-dire si et seulement
si~\mathrm{det}~
(\epsilon_t(\phi_1),\\ldots,\epsilon_t(\phi_n))\mathrel\neq~~0
ce qui montre bien l'équivalence des trois assertions. La proposition
suivante expliquera d'ailleurs complètement l'équivalence entre les
assertions (ii) et (iii).

Proposition~16.4.5 Soit I un intervalle de \mathbb{R}~,
a_0,\\ldots,a_n-1~
: I \rightarrow~ K continues. Soit
\phi_1,\\ldots,\phi_n~
des solutions de l'équation différentielle homogène y^(n) =
a_n-1(t)y^(n-1) +
\\ldots~ +
a_0(t)y et W leur wronskien. Alors pour tout y_0,t \in I
on a W(t) = W(t_0)exp~
\left (\int ~
_t_0^ta_n-1(u) du\right
).

Démonstration On sait que pour dériver W(t) on doit faire la somme de
tous les déterminants obtenus en dérivant la i-ème ligne et en laissant
toutes les autres inchangées. Mais comme dans le wronskien, la i + 1-ème
ligne est la dérivée de la i-ème, en dérivant la i-ème ligne et en
laissant inchangée la i + 1-ième (si elle existe), le déterminant obtenu
a deux lignes égales, donc il est nul. On en déduit que le seul
déterminant non trivialement nul est celui obtenu en dérivant la n-ème
ligne, soit encore

W'(t) = \left
\matrix\,\phi_1(t)
&\\ldots&\phi_n~(t)
\cr \phi_1'(t)
&\\ldots&\phi_n~'(t)
\cr
\\ldots~
&\\ldots&\\\ldots~
\cr
\phi_1^(n-2)(t)&\\ldots&\phi_n^(n-2)~(t)
\cr \phi_1^(n)(t)
&\\ldots&\phi_n^(n)~(t)
\right 

En soustrayant à la dernière ligne a_0(t) fois la première,
a_1(t) fois la
seconde,\\ldots~,
a_n-2(t) fois la dernière et tenant compte de ce que
\phi_j^(n)(t) - a_0(t)\phi_j(t) -
a_1(t)\phi_j'(t)
-\\ldots~ -
a_n-2(t)\phi_j^(n-2)(t) =
a_n-1(t)\phi_j^(n-1)(t), on obtient alors

\begin{align*} W'(t)& = \left
\matrix\,\phi_1(t)
&\\ldots&\phi_n~(t)
\cr \phi_1'(t)
&\\ldots&\phi_n~'(t)
\cr
\\ldots~
&\\ldots&\\\ldots~
\cr \phi_1^(n-2)(t)
&\\ldots&\phi_n^(n-2)~(t)
\cr
a_n-1(t)\phi_1^(n-1)(t)&\\ldots&a_n-1(t)\phi_n^(n-1)(t)~\right
 & \%& \\ & =
a_n-1(t)\left
\matrix\,\phi_1(t)
&\\ldots&\phi_n~(t)
\cr \phi_1'(t)
&\\ldots&\phi_n~'(t)
\cr
\\ldots~
&\\ldots&\\\ldots~
\cr
\phi_1^(n-2)(t)&\\ldots&\phi_n^(n-2)~(t)
\cr
\phi_1^(n-1)(t)&\\ldots&\phi_n^(n-1)(t)~\right
 = a_n-1(t)W(t)& \%&
\\ \end{align*}

en utilisant la linéarité du déterminant par rapport à sa dernière
ligne. Donc W est solution de l'équation différentielle linéaire
scalaire d'ordre 1, y' = a_n-1(t)y ce qui implique
immédiatement la formule voulue.

Remarque~16.4.1 Les fonctions \phi_1 :
t\mapsto~t et \phi_2 :
t\mapsto~sin~ t ont comme
wronskien W(t) = \left
\matrix\,t&sin~
t\cr 1 &cos~
t\right  = tcos~ t
- sin~ t. Ce wronskien n'est pas identiquement
nul et pourtant il s'annule en 0. Ceci montre que ces deux fonctions ne
peuvent pas être toutes deux solutions d'une même équation
différentielle homogène d'ordre 2 à coefficients continus sur \mathbb{R}~.

\paragraph{16.4.4 Méthode de variation des constantes}

Supposons connue une base
(\phi_1,\\ldots,\phi_n~)
de l'espace S_H de l'équation différentielle homogène
y^(n) = a_n-1(t)y^(n-1) +
\\ldots~ +
a_0(t)y et posons \Phi_j(t) = \left
(\matrix\,\phi_j(t)
\cr \phi_j'(t) \cr
\\ldots~
\cr \phi_j^(n-1)(t)\right
). Alors
(\Phi_1,\\ldots,\Phi_n~)
est une base de l'espace des solutions du système homogène Y ' = A(t)Y
où

A(t) = \left (\matrix\,0
&1&0&\\ldots~&0
\cr \⋮~
&\\ldots&\\\ldots&\\\ldots&\\⋮~
\cr 0
&\\ldots&\\\ldots~&0&1
\cr
a_0(t)&\\ldots&\\\ldots&\\\ldots&a_n-1(t)~\right
)

Si b : I \rightarrow~ \mathbb{R}~ est une fonction continue, la résolution de l'équation
linéaire y^(n) = a_n-1(t)y^(n-1) +
\\ldots~ +
a_0(t)y + b(t) est équivalente à la résolution du système
différentiel linéaire Y ' = A(t)Y + B(t) où B(t) = \left
(\matrix\,0 \cr
\⋮~ &
\cr 0 \cr b(t)\right ).
Comme nous connaissons une base de l'espace des solutions du système
homogène, nous pouvons résoudre ce système linéaire en posant Y (t) =
\lambda_1(t)\Phi_1(t) +
\\ldots~ +
\lambda_n(t)\Phi_n(t) où
\lambda_1,\\ldots,\lambda_n~
sont des fonctions de classe \mathcal{C}^1 de I dans K. Comme Y (t) =
\left (\matrix\,y(t)
\cr y'(t) \cr
\\ldots~
\cr y^(n-1)(t)\right ) ceci
revient à poser

\begin{align*} y(t)& =&
\lambda_1(t)\phi_1(t) +
\\ldots~ +
\lambda_n(t)\phi_n(t) \%& \\
y'(t)& =& \lambda_1(t)\phi_1'(t) +
\\ldots~ +
\lambda_n(t)\phi_n'(t) \%& \\
\\ldots~& & \%&
\\ y^(n-1)(t)& =& \lambda_
1(t)\phi_1^(n-1)(t) +
\\ldots + \lambda~_
n(t)\phi_n^(n-1)(t)\%& \\
\end{align*}

autrement dit, d'après la règle de dérivation des produits, cela revient
à imposer aux fonctions
\lambda_1,\\ldots,\lambda_n~
de vérifier les conditions

\begin{align*} \lambda_1'(t)\phi_1(t) +
\\ldots~ +
\lambda_n'(t)\phi_n(t)& =& 0\%&
\\ \lambda_1'(t)\phi_1'(t) +
\\ldots~ +
\lambda_n'(t)\phi_n'(t)& =& 0\%&
\\ &
\\ldots~& \%&
\\
\lambda_1'(t)\phi_1^(n-2)(t) +
\\ldots + \lambda~_
n'(t)\phi_n^(n-2)(t)& =& 0\%&
\\ \end{align*}

Dans ces conditions, par dérivation de y^(n-1)(t) =
\lambda_1(t)\phi_1^(n-1)(t) +
\\ldots~ +
\lambda_n(t)\phi_n^(n-1)(t), on obtient

\begin{align*} y^(n)(t)& =& \lambda_
1(t)\phi_1^(n)(t) +
\\ldots + \lambda~_
n(t)\phi_n^(n)(t) \%& \\
& & \quad +
\lambda_1'(t)\phi_1^(n-1)(t) +
\\ldots + \lambda~_
n'(t)\phi_n^(n-1)(t) \%&
\\ & =&
\lambda_1(t)\\sum
_k=0^n-1a_ k(t)\phi_1^(k)(t) +
\ldots + \lambda~_
n(t)\sum _k=0^n-1a_
k(t)\phi_n^(k)(t)\%& \\ &
& \quad + \lambda_1'(t)\phi_1^(n-1)(t) +
\\ldots + \lambda~_
n'(t)\phi_n^(n-1)(t) \%&
\\ & =& \\sum
_k=0^n-1a_ k(t)\left
(\lambda_1(t)\phi_1^(k)(t) +
\ldots + \lambda~_
n(t)\phi_n^(k)(t)\right ) \%&
\\ & & \quad +
\lambda_1'(t)\phi_1^(n-1)(t) +
\\ldots + \lambda~_
n'(t)\phi_n^(n-1)(t) \%&
\\ & =& \\sum
_k=0^n-1a_ k(t)y^(k)(t) \%&
\\ & & \quad +
\lambda_1'(t)\phi_1^(n-1)(t) +
\\ldots + \lambda~_
n'(t)\phi_n^(n-1)(t) \%&
\\ \end{align*}

si bien que

\begin{align*} y^(n)(t) = a_
n-1(t)y^(n-1) +
\\ldots + a_
0(t)y + b(t) \Leftrightarrow&& \%&
\\ & &
\lambda_1'(t)\phi_1^(n-1)(t) +
\\ldots + \lambda~_
n'(t)\phi_n^(n-1)(t) = b(t)\%&
\\ \end{align*}

En conclusion,
\lambda_1'(t),\\ldots,\lambda_n~'(t)
doivent être solutions du système d'équations linéaires

\left \\array
\lambda_1'(t)\phi_1(t) +
\\ldots~ +
\lambda_n'(t)\phi_n(t) & = 0 \cr
\lambda_1'(t)\phi_1'(t) +
\\ldots~ +
\lambda_n'(t)\phi_n'(t) & = 0\cr
\\ldots~
\cr \lambda_1'(t)\phi_1^(n-2)(t) +
\\ldots~ +
\lambda_n'(t)\phi_n^(n-2)(t)& = 0 \cr
\lambda_1'(t)\phi_1^(n-1)(t) +
\\ldots~ +
\lambda_n'(t)\phi_n^(n-1)(t)& = b(t) 
\right .

Or ce système est un système de Cramer (son déterminant est le wronskien
de
\phi_1,\\ldots,\phi_n~
qui par hypothèse ne s'annule pas)~; sa résolution conduit à la
détermination de
\lambda_1',\\ldots,\lambda_n~'
et il reste à faire n calculs de primitives de fonctions à valeurs dans
K pour terminer la résolution de l'équation linéaire.

Méthode. Supposons connue une base
(\phi_1,\\ldots,\phi_n~)
de l'espace S_H de l'équation différentielle homogène
y^(n) = a_n-1(t)y^(n-1) +
\\ldots~ +
a_0(t)y. On résout l'équation linéaire y^(n) =
a_n-1(t)y^(n-1) +
\\ldots~ +
a_0(t)y + b(t) en posant y(t) = \lambda_1(t)\phi_1(t)
+ \\ldots~ +
\lambda_n(t)\phi_n(t), où
\lambda_1,\\ldots,\lambda_n~
sont des fonctions de classe \mathcal{C}^1 auxquelles on impose les
conditions

\begin{align*} \lambda_1'(t)\phi_1(t) +
\\ldots~ +
\lambda_n'(t)\phi_n(t)& = 0& \%&
\\ \lambda_1'(t)\phi_1'(t) +
\\ldots~ +
\lambda_n'(t)\phi_n'(t)& = 0& \%&
\\
\\ldots~& & \%&
\\
\lambda_1'(t)\phi_1^(n-2)(t) +
\\ldots + \lambda~_
n'(t)\phi_n^(n-2)(t)& = 0& \%&
\\ \end{align*}

Alors les fonctions
\lambda_1',\\ldots,\lambda_n~'
sont solution du système de Cramer

\left \\array
\lambda_1'(t)\phi_1(t) +
\\ldots~ +
\lambda_n'(t)\phi_n(t) & = 0 \cr
\lambda_1'(t)\phi_1'(t) +
\\ldots~ +
\lambda_n'(t)\phi_n'(t) & = 0\cr
\\ldots~
\cr \lambda_1'(t)\phi_1^(n-2)(t) +
\\ldots~ +
\lambda_n'(t)\phi_n^(n-2)(t)& = 0 \cr
\lambda_1'(t)\phi_1^(n-1)(t) +
\\ldots~ +
\lambda_n'(t)\phi_n^(n-1)(t)& = b(t) 
\right .

On résout ce système, puis n calculs de primitives permettent de
déterminer les fonctions
\lambda_1,\\ldots,\lambda_n~.

\paragraph{16.4.5 Méthode d'abaissement du degré}

Cette méthode ne présente réellement d'intérêt que pour une équation
linéaire d'ordre 2, y'`= a(t)y' + b(t)y + c(t). Supposons connue une
solution \phi de l'équation homogène qui ne s'annule pas sur I et faisons
le changement de fonction inconnue z(t) = y(t) \over
\phi(t) autrement dit y(t) = z(t)\phi(t). On a alors y'(t) = z'(t)\phi(t) +
z(t)\phi'(t) et y'`(t) = z'`(t)\phi(t) + 2z'(t)\phi'(t) + z(t)\phi''(t), si bien que

\begin{align*} y'`(t) - a(t)y'(t) - c(t)y(t)&&
\%& \\ & =& z'`(t)\phi(t) + (2\phi'(t) -
\phi(t))z'(t) \%& \\ & &
\quad + (\phi'`(t) - a(t)\phi'(t) - b(t)\phi(t))z(t)\%&
\\ & =& z'`(t)\phi(t) + (2\phi'(t) -
\phi(t))z'(t) \%& \\
\end{align*}

compte tenu de ce que \phi'`(t) - a(t)\phi'(t) - b(t)\phi(t) = 0. On en déduit
que

\begin{align*} y'`(t) = a(t)y'(t) + b(t)y(t) + c(t)
\Leftrightarrow&& \%& \\
& & z'`(t)\phi(t) + (2\phi'(t) - \phi(t))z'(t) = c(t)\%&
\\ \end{align*}

qui est une équation différentielle d'ordre 1 en la fonction inconnue
z'(t), que l'on sait donc résoudre à l'aide de deux calculs de
primitives.

Remarque~16.4.2 Cette méthode n'est à utiliser qu'en dernier recours,
c'est-à-dire lorsqu'on ne dispose que d'une seule solution de l'équation
homogène, et on doit toujours lui préférer (lorsque c'est possible) la
méthode de variation des constantes. En effet la méthode d'abaissement
du degré demande que soit réalisée une condition contraignante (une
solution ne s'annulant pas) et conduit à deux calculs de primitives pour
obtenir z'(t) et un troisième calcul de primitive pour obtenir z(t). De
plus ces trois calculs s'enchaînent (toute erreur dans l'un des calculs
oblige à recommencer l'ensemble des calculs). Par contre, la méthode de
variation des constantes n'impose aucune condition restrictive aux
solutions de l'équation homogène et ne nécessite que deux calculs de
primitives, qui plus est indépendants l'un de l'autre.

\paragraph{16.4.6 Equation homogène à coefficients constants}

Nous étudierons dans ce paragraphe l'équation y^(n) +
a_n-1y^(n-1) +
\\ldots~ +
a_0y = 0 où
a_0,\\ldots,a_n-1~
sont des éléments donnés du corps de base K (égal à \mathbb{R}~ ou \mathbb{C}). En cas de
besoin et pour unifier les notations, nous poserons a_n = 1.

Définition~16.4.2 Le polynôme \chi(X) = X^n +
a_n-1X^n-1 +
\\ldots~ +
a_0 \in K[X] est appelé le polynôme caractéristique de
l'équation homogène y^(n) + a_n-1y^(n-1)
+ \\ldots~ +
a_0y = 0.

Remarque~16.4.3 t\mapsto~e^\lambda~t est
solution de y^(n) + a_n-1y^(n-1) +
\\ldots~ +
a_0y = 0 si et seulement si~\chi(\lambda~) = 0.

Lemme~16.4.6 Soit P(X) \in K[X] et \lambda~ \in K. Soit f :
t\mapsto~P(t)e^\lambda~t de \mathbb{R}~ dans K. Alors

\forall~t \in \mathbb{R}~, f^(n)(t) + a_
n-1f^(n-1)(t) +
\\ldots + a_
0f(t) = e^\lambda~t \\sum
_p=0^n 1 \over p!
\chi^(p)(\lambda~)P^(p)(t)

Démonstration La formule de Leibnitz nous donne f^(k)(t)
= \\sum ~
_p=0^kC_k^pP^(p)(t)\lambda~^k-pe^\lambda~t
si bien que

\begin{align*} f^(n)(t) + a_
n-1f^(n-1)(t) +
\\ldots + a_
0f(t) = \sum _k=0^na_
kf^(k)(t)&&\%& \\ & =&
e^\lambda~t \\sum
_k=0^na_ k \\sum
_p=0^k k! \over p!(k - p)!
P^(p)(t)\lambda~^k-p \%&
\\ & =& e^\lambda~t
\sum _0\leqp\leqk\leqna_k~ k!
\over p!(k - p)! P^(p)(t)\lambda~^k-p
\%& \\ & =& e^\lambda~t
\sum _p=0^n~ 1
\over p! P^(p)(t)\\sum
_k=p^na_ k k! \over (k - p)!
\lambda~^k-p\%& \\ & =&
e^\lambda~t \sum _p=0^n~ 1
\over p! \chi^(p)(\lambda~)P^(p)(t) \%&
\\ \end{align*}

Supposons donc que \lambda~ est une racine de \chi de multiplicité m et que
deg~ P \leq m - 1. On a alors
\forall~p \leq m - 1, \chi^(p)~(\lambda~) = 0 et
\forall~p ≥ m, P^(p)~(t) = 0, si bien que
\forall~~p \in [0,n],
\chi^(p)(\lambda~)P^(p)(t) = 0. On en déduit donc que f :
t\mapsto~e^\lambda~tP(t) est solution de
l'équation différentielle y^(n) +
a_n-1y^(n-1) +
\\ldots~ +
a_0y = 0.

Lemme~16.4.7 Soit
\lambda_1,\\ldots,\lambda_k~
des éléments distincts de K et
m_1,\\ldots,m_k~
des entiers naturels. Alors la famille des applications
t\mapsto~t^je^\lambda_it
avec 1 \leq i \leq k et 0 \leq j \leq m_i - 1 est libre.

Démonstration Supposons que cette famille est liée. Notons n =
m_1 + ⋯ + m_k,
f_1,\\ldots,f_n~
ces fonctions. Il existe donc
\alpha_1,\\ldots,\alpha_n~
\in K, non tous nuls, tels que \forall~~t \in \mathbb{R}~,
\alpha_1f_1(t) +
\\ldots~ +
\alpha_nf_n(t) = 0. Fixons t_0 \in \mathbb{R}~. Par dérivation
de l'identité précédente au point t_0, on a donc
\forall~~k \in \mathbb{N}~,
a_1f_1^(k)(t_0) +
\\ldots~ +
\alpha_nf_n^(k)(t_0) = 0 et en particulier
la matrice wronskienne \left
(\matrix\,f_1(t_0)
&\\ldots&f_n(t_0~)
\cr f_1'(t_0)
&\\ldots&f_n'(t_0~)
\cr
\\ldots~
&\\ldots&\\\ldots~
\cr
f_1^(n-1)(t_0)&\\ldots&f_n^(n-1)(t_0)~\right
) n'est pas inversible puisque ses vecteurs colonnes forment une famille
liée. On en déduit que ses vecteurs lignes forment une famille liée, et
que donc il existe
\beta_0,\\ldots,\beta_n-1~
non tous nuls (mais dépendant de t_0) tels que

\forall~~j \in [1,n],
\beta_0f_j(t_0) +
\beta_1f_j'(t_0) +
\\ldots~ +
\beta_n-1f_j^(n-1)(t_ 0) = 0

Posons alors \chi(X) = \beta_n-1X^n-1 +
⋯ + \beta_0. Le lemme précédent (où l'on
remplace n par n - 1) nous montre que si f(t) = e^\lambda~tP(t),
alors

\beta_0f(t_0) + \beta_1f'(t_0) +
\\ldots~ +
\beta_n-1f^(n-1)(t_ 0) =
e^\lambda~t_0  \\sum
_p=0^n-1 1 \over p!
\chi^(p)(\lambda~)P^(p)(t_ 0)

En particulier, pour P(X) = X^j et \lambda~ = \lambda_i, on
obtient

\begin{align*} \beta_0f(t_0) +
\beta_1f'(t_0) +
\\ldots~ +
\beta_n-1f^(n-1)(t_ 0)& & \%&
\\ = e^\lambda_it_0
 \sum _p=0^j~ 1
\over p! \chi^(p)(\lambda_ i) j!
\over (j - p)! t_0^j-p& & \%&
\\ \end{align*}

car les dérivées suivantes de X^j sont nulles. On en déduit
que

\forall~j \leq m_i~ - 1,
\sum _p=0^j~ 1
\over p! \chi^(p)(\lambda_ i) j!
\over (j - p)! t_0^j-p = 0

autrement dit (compte tenu de  j! \over p!(p-j)! =
C_j^p)

\left \\array
C_0^0\chi(\lambda_i) & = 0 \cr
C_1^0\chi(\lambda_i)t_0 +
C_1^1\chi'(\lambda_i) & = 0 \cr
C_2^0\chi(\lambda_i)t_0^2 +
C_2^1\chi'(\lambda_i)t +
C_2^2\chi''(\lambda_i) = 0\cr
&\\ldots~
\cr
C_m_i-1^0\chi(\lambda~)t_0^m_i-1
+ \\ldots~ +
C_m_
i-1^m_i-2\chi^(m_i-2)(\lambda~)t +
C_
m_i-1^m_i-1\chi^(m_i-1)(\lambda_
i)& = 0  \right .

ce qui implique évidemment que \chi(\lambda_i) =
\\ldots~ =
\chi^(m_i-1)(\lambda_i) = 0. Donc \lambda_i est
racine de \chi de multiplicité au moins égale à m_i. Mais alors la
somme des multiplicités des racines du polynôme non nul \chi(X) est au
moins égale à m_1 +
\\ldots~ +
m_k = n alors qu'il est de degré au plus n - 1. C'est absurde,
ce qui montre que la famille est libre.

Revenons à notre équation différentielle homogène y^(n) +
a_n-1y^(n-1) +
\\ldots~ +
a_0y = 0 et supposons que son polynôme caractéristique \chi(X) est
scindé sur K (ce qui est automatique si K = \mathbb{C}). Soit
\lambda_1,\\ldots,\lambda_k~
ses racines distinctes de multiplicités respectives
m_1,\\ldots,m_k~,
si bien que m_1 +
\\ldots~ +
m_k = n. Alors les n fonctions
t\mapsto~t^je^\lambda_it
avec 1 \leq i \leq k et 0 \leq j \leq m_i - 1 sont solutions de l'équation
différentielle homogène et forment une famille libre. Comme l'espace des
solutions de l'équation homogène est de dimension n, ces fonctions
forment une base de l'espace des solutions. Autrement dit les solutions
de l'équation homogène sont exactement les fonctions qui s'écrivent sous
la forme

t\mapsto~\\sum
_i=1^k \\sum
_j=0^m_i-1\alpha_
i,jt^je^\lambda_it =
\sum _i=1^kP_
i(t)e^\lambda_it

avec P_i(X) =\
\sum ~
_i=0^m_i-1\alpha_i,jX^j \in K[X]
et deg P_i \leq m_i~ - 1. On a
donc démontré le résultat suivant

Théorème~16.4.8 Soit
a_0,\\ldots,a_n-1~
\in K et l'équation différentielle homogène y^(n) +
a_n-1y^(n-1) +
\\ldots~ +
a_0y = 0. On suppose que le polynôme caractéristique \chi(X) =
X^n + a_n-1X^n-1 +
\\ldots~ +
a_0 est scindé sur K (ce qui est automatique si K = \mathbb{C}). Soit
\lambda_1,\\ldots,\lambda_k~
ses racines distinctes de multiplicités respectives
m_1,\\ldots,m_k~.
Alors les solutions de l'équation homogène sont exactement les fonctions

t\mapsto~\\sum
_i=1^kP_
i(t)e^\lambda_it\quad
\text avec \$P_ i(X) \in K[X]\$ et \$deg
P_i \leq m_i - 1\$.

\paragraph{16.4.7 Equation linéaire à coefficients constants}

Il s'agit ici de résoudre une équation différentielle linéaire à
coefficients constants y^(n) +
a_n-1y^(n-1) +
\\ldots~ +
a_0y = b(t) où b est une application continue de I dans K. Dans
le cas général, puisque nous savons résoudre l'équation homogène, la
méthode de variation des constantes permet d'aboutir au résultat au prix
du calcul de n primitives. Mais d'autre part, il suffit évidemment de
déterminer une solution particulière de l'équation différentielle
linéaire pour en avoir la solution générale en ajoutant à cette solution
particulière la solution générale de l'équation homogène.

Examinons le cas particulier où b(t) = Q(t)e^\mut avec Q(X) \in
K[X] et \mu \in K. Nous allons rechercher une solution particulière du
type f(t) = P(t)e^\mut. On sait alors que

f^(n)(t) + a_ n-1f^(n-1)(t) +
\\ldots + a_
0f(t) = e^\lambda~t \\sum
_p=0^n 1 \over p!
\chi^(p)(\lambda~)P^(p)(t)

Autrement dit, f sera solution de l'équation linéaire si et seulement
si~\\sum ~
_p=0^n 1 \over p!
\chi^(p)(\lambda~)P^(p)(X) = Q(X). Soit m la multiplicité de
\mu comme racine de \chi (nous poserons m = 0 si \mu n'est pas racine de \chi). On
a alors \chi(\mu) =
\\ldots~ =
\chi^(m-1)(\mu) = 0 et
\chi^(m)(\mu)\neq~0. On a donc à résoudre
l'équation

\sum _p=m^n~ 1
\over p! \chi^(p)(\mu)P^(p)(X) = Q(X)

Cela se fera par identification si nous connaissons un majorant du degré
de P. Mais pour cela il suffit d'appliquer le lemme suivant, où l'on
désigne par K_p[X] l'espace des polynômes de degré
inférieur ou égal à p,

Lemme~16.4.9 Soit d \in \mathbb{N}~, l'application \theta :
P\mapsto~\\\sum
 _p=m^n 1 \over p!
\chi^(p)(\mu)P^(p)(X) est une application linéaire
surjective de K_d+m[X] dans K_d[X].

Démonstration Si deg~ P \leq d + m, alors pour p ≥
m, on a deg P^(p)~(X) \leq d ce qui
montre que \theta(P) =\ \\sum
 _p=m^n 1 \over p!
\chi^(p)(\mu)P^(p)(X) \in K_ d[X]. Cette
application est visiblement linéaire. Cherchons le rang de cette
application linéaire et pour cela déterminons sa matrice. Si j \leq d + m,
on a

\theta(X^j) = \sum _p=m^j~
1 \over p! \chi^(p)(\mu) j!
\over (j - p)! X^j-p =
\sum _p=m^jC_
j^p\chi^(p)(\mu)X^j-p

si bien que la matrice de \theta dans les bases canoniques
(1,X,\\ldots,X^d+m~)
et
(1,X,\\ldots,X^d~)
est la matrice

\left ( \includegraphics{cours9x.png}
\,\right )

Or la matrice formée par les d + 1 dernières colonnes est visiblement
inversible, ce qui montre que le rang de \theta est égal à d + 1
= dim K_d~[X] et donc que \theta est
surjective. On a donc la proposition suivante

Proposition~16.4.10 Soit
a_0,\\ldots,a_n-1~
\in K, Q \in K[X] et \mu \in K. L'équation différentielle linéaire
y^(n) + a_n-1y^(n-1) +
\\ldots~ +
a_0y = Q(t)e^\mut admet au moins une solution de la
forme P(t)e^\mut où P \in K[X] et
deg P \leq\ deg~ Q + m, m
désignant la multiplicité de \mu comme racine du polynôme caractéristique
de l'équation homogène.

Remarque~16.4.4 Le fait qu'il faille ajouter au degré de Q la
multiplicité m de \mu comme racine de \chi s'appelle le phénomène de
résonance. Il implique que même si Q est constante, il peut exister des
solutions du type P(t)e^\mut avec deg~
P ≥ 1 qui peuvent être non bornées et entraîner des catastrophes dans le
système contrôlé par l'équation différentielle.

Remarque~16.4.5 La méthode précédente par identification permet
également de résoudre des équations du type y^(n) +
a_n-1y^(n-1) +
\\ldots~ +
a_0y = \\sum ~
_i=1^qQ_i(t)e^\mu_it en
remarquant que si f_i est une particulière de l'équation
y^(n) + a_n-1y^(n-1) +
\\ldots~ +
a_0y = Q_i(t)e^\mu_it, alors
f_1 + ⋯ + f_q est solution
de y^(n) + a_n-1y^(n-1) +
\\ldots~ +
a_0y = \\sum ~
_i=1^qQ_i(t)e^\mu_it (ce que
l'on appelle le principe de superposition des solutions). Elle
s'applique en particulier à des équations du type y^(n) +
a_n-1y^(n-1) +
\\ldots~ +
a_0y = Q(t)cos~ (\omegat) ou
y^(n) + a_n-1y^(n-1) +
\\ldots~ +
a_0y = Q(t)sin~ (\omegat) pour lesquelles
il suffit de passer en exponentielle complexe~: poser
cos (\omegat) = 1 \over 2~
(e^i\omegat + e^-i\omegat) et sin~
(\omegat) = 1 \over 2i (e^i\omegat -
e^-i\omegat).

\paragraph{16.4.8 Equations d'Euler}

Considérons une équation différentielle homogène du type
t^ny^(n) +
a_n-1t^n-1y^(n-1) +
\\ldots~ +
a_1ty' + a_0y = 0 que nous étudierons sur ]0,+\infty~[
(il suffit de changer t en - t pour faire une étude similaire sur ]
-\infty~,0[). Faisons le changement de variable t = e^u, soit
encore u = log~ t. Nous poserons donc y(t) =
z(u) soit encore y(t) = z(log~ t). Une
récurrence facile montre que

\forall~k \in \mathbb{N}~, y^(k)~(t) = 1
\over t^k  \\sum
_p=0^k\lambda_ k,pz^(p)(log t)

C'est clair pour k = 0 et si c'est vrai pour k, on a

\begin{align*} y^(k+1)(t)& =& - k
\over t^k+1  \\sum
_p=0^k\lambda_ k,pz^(p)(log t) + 1
\over t^k  \\sum
_p=0^k\lambda_ k,p 1 \over t
z^(p+1)(log t) \%& \\ & =&
- k \over t^k+1 
\sum _p=0^k\lambda~_
k,pz^(p)(log t) + 1 \over
t^k+1  \\sum
_p=0^k\lambda_ k,pz^(p+1)(log t)\%&
\\ & =& 1 \over
t^k+1  \\sum
_p=0^k+1\lambda_ k+1,pz^(p)(log t) \%&
\\ \end{align*}

avec \lambda_k+1,p = -k\lambda_k,p + \lambda_k,p-1 si 1 \leq p \leq
k, \lambda_k+1,0 = -k\lambda_k,0 et \lambda_k+1,k+1 =
\lambda_k,k.

On a donc t^ky^(k)(t) =\
\sum ~
_p=0^k\lambda_k,pz^(p)(u) si bien que
l'équation devient une équation homogène d'ordre n à coefficients
constants en la fonction z(u). Ses solutions sont du type z(u)
= \\sum ~
_i=1^ke^\lambda_iuP_i(u) si bien
que les solutions de l'équation d'Euler sont de la forme

y(t) = \\sum
_i=1^kt^\lambda_i P_i(log t)

On retiendra

Proposition~16.4.11 Dans une équation d'Euler
t^ny^(n) +
a_n-1t^n-1y^(n-1) +
\\ldots~ +
a_1ty' + a_0y = 0, le changement de variable t =
e^u conduit à une équation différentielle homogène d'ordre n
à coefficients constants.

[
[
[
[

\end{document}

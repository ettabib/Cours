\documentclass[]{article}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\usepackage{graphicx}
% Redefine \includegraphics so that, unless explicit options are
% given, the image width will not exceed the width of the page.
% Images get their normal width if they fit onto the page, but
% are scaled down if they would overflow the margins.
\makeatletter
\def\ScaleIfNeeded{%
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother
\let\Oldincludegraphics\includegraphics
{%
 \catcode`\@=11\relax%
 \gdef\includegraphics{\@ifnextchar[{\Oldincludegraphics}{\Oldincludegraphics[width=\ScaleIfNeeded]}}%
}%
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={Equation differentielle lineaire d'ordre n},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}
 
/* start css.sty */
.cmr-5{font-size:50%;}
.cmr-7{font-size:70%;}
.cmmi-5{font-size:50%;font-style: italic;}
.cmmi-7{font-size:70%;font-style: italic;}
.cmmi-10{font-style: italic;}
.cmsy-5{font-size:50%;}
.cmsy-7{font-size:70%;}
.cmex-7{font-size:70%;}
.cmex-7x-x-71{font-size:49%;}
.msbm-7{font-size:70%;}
.cmtt-10{font-family: monospace;}
.cmti-10{ font-style: italic;}
.cmbx-10{ font-weight: bold;}
.cmr-17x-x-120{font-size:204%;}
.cmsl-10{font-style: oblique;}
.cmti-7x-x-71{font-size:49%; font-style: italic;}
.cmbxti-10{ font-weight: bold; font-style: italic;}
p.noindent { text-indent: 0em }
td p.noindent { text-indent: 0em; margin-top:0em; }
p.nopar { text-indent: 0em; }
p.indent{ text-indent: 1.5em }
@media print {div.crosslinks {visibility:hidden;}}
a img { border-top: 0; border-left: 0; border-right: 0; }
center { margin-top:1em; margin-bottom:1em; }
td center { margin-top:0em; margin-bottom:0em; }
.Canvas { position:relative; }
li p.indent { text-indent: 0em }
.enumerate1 {list-style-type:decimal;}
.enumerate2 {list-style-type:lower-alpha;}
.enumerate3 {list-style-type:lower-roman;}
.enumerate4 {list-style-type:upper-alpha;}
div.newtheorem { margin-bottom: 2em; margin-top: 2em;}
.obeylines-h,.obeylines-v {white-space: nowrap; }
div.obeylines-v p { margin-top:0; margin-bottom:0; }
.overline{ text-decoration:overline; }
.overline img{ border-top: 1px solid black; }
td.displaylines {text-align:center; white-space:nowrap;}
.centerline {text-align:center;}
.rightline {text-align:right;}
div.verbatim {font-family: monospace; white-space: nowrap; text-align:left; clear:both; }
.fbox {padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
div.fbox {display:table}
div.center div.fbox {text-align:center; clear:both; padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
div.minipage{width:100%;}
div.center, div.center div.center {text-align: center; margin-left:1em; margin-right:1em;}
div.center div {text-align: left;}
div.flushright, div.flushright div.flushright {text-align: right;}
div.flushright div {text-align: left;}
div.flushleft {text-align: left;}
.underline{ text-decoration:underline; }
.underline img{ border-bottom: 1px solid black; margin-bottom:1pt; }
.framebox-c, .framebox-l, .framebox-r { padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
.framebox-c {text-align:center;}
.framebox-l {text-align:left;}
.framebox-r {text-align:right;}
span.thank-mark{ vertical-align: super }
span.footnote-mark sup.textsuperscript, span.footnote-mark a sup.textsuperscript{ font-size:80%; }
div.tabular, div.center div.tabular {text-align: center; margin-top:0.5em; margin-bottom:0.5em; }
table.tabular td p{margin-top:0em;}
table.tabular {margin-left: auto; margin-right: auto;}
div.td00{ margin-left:0pt; margin-right:0pt; }
div.td01{ margin-left:0pt; margin-right:5pt; }
div.td10{ margin-left:5pt; margin-right:0pt; }
div.td11{ margin-left:5pt; margin-right:5pt; }
table[rules] {border-left:solid black 0.4pt; border-right:solid black 0.4pt; }
td.td00{ padding-left:0pt; padding-right:0pt; }
td.td01{ padding-left:0pt; padding-right:5pt; }
td.td10{ padding-left:5pt; padding-right:0pt; }
td.td11{ padding-left:5pt; padding-right:5pt; }
table[rules] {border-left:solid black 0.4pt; border-right:solid black 0.4pt; }
.hline hr, .cline hr{ height : 1px; margin:0px; }
.tabbing-right {text-align:right;}
span.TEX {letter-spacing: -0.125em; }
span.TEX span.E{ position:relative;top:0.5ex;left:-0.0417em;}
a span.TEX span.E {text-decoration: none; }
span.LATEX span.A{ position:relative; top:-0.5ex; left:-0.4em; font-size:85%;}
span.LATEX span.TEX{ position:relative; left: -0.4em; }
div.float img, div.float .caption {text-align:center;}
div.figure img, div.figure .caption {text-align:center;}
.marginpar {width:20%; float:right; text-align:left; margin-left:auto; margin-top:0.5em; font-size:85%; text-decoration:underline;}
.marginpar p{margin-top:0.4em; margin-bottom:0.4em;}
.equation td{text-align:center; vertical-align:middle; }
td.eq-no{ width:5%; }
table.equation { width:100%; } 
div.math-display, div.par-math-display{text-align:center;}
math .texttt { font-family: monospace; }
math .textit { font-style: italic; }
math .textsl { font-style: oblique; }
math .textsf { font-family: sans-serif; }
math .textbf { font-weight: bold; }
.partToc a, .partToc, .likepartToc a, .likepartToc {line-height: 200%; font-weight:bold; font-size:110%;}
.chapterToc a, .chapterToc, .likechapterToc a, .likechapterToc, .appendixToc a, .appendixToc {line-height: 200%; font-weight:bold;}
.index-item, .index-subitem, .index-subsubitem {display:block}
.caption td.id{font-weight: bold; white-space: nowrap; }
table.caption {text-align:center;}
h1.partHead{text-align: center}
p.bibitem { text-indent: -2em; margin-left: 2em; margin-top:0.6em; margin-bottom:0.6em; }
p.bibitem-p { text-indent: 0em; margin-left: 2em; margin-top:0.6em; margin-bottom:0.6em; }
.paragraphHead, .likeparagraphHead { margin-top:2em; font-weight: bold;}
.subparagraphHead, .likesubparagraphHead { font-weight: bold;}
.quote {margin-bottom:0.25em; margin-top:0.25em; margin-left:1em; margin-right:1em; text-align:\jmathustify;}
.verse{white-space:nowrap; margin-left:2em}
div.maketitle {text-align:center;}
h2.titleHead{text-align:center;}
div.maketitle{ margin-bottom: 2em; }
div.author, div.date {text-align:center;}
div.thanks{text-align:left; margin-left:10%; font-size:85%; font-style:italic; }
div.author{white-space: nowrap;}
.quotation {margin-bottom:0.25em; margin-top:0.25em; margin-left:1em; }
h1.partHead{text-align: center}
.sectionToc, .likesectionToc {margin-left:2em;}
.subsectionToc, .likesubsectionToc {margin-left:4em;}
.subsubsectionToc, .likesubsubsectionToc {margin-left:6em;}
.frenchb-nbsp{font-size:75%;}
.frenchb-thinspace{font-size:75%;}
.figure img.graphics {margin-left:10%;}
/* end css.sty */

\title{Equation differentielle lineaire d'ordre n}
\author{}
\date{}

\begin{document}
\maketitle

\textbf{Warning: 
requires JavaScript to process the mathematics on this page.\\ If your
browser supports JavaScript, be sure it is enabled.}

\begin{center}\rule{3in}{0.4pt}\end{center}

{[}
{[}
{[}{]}
{[}

\subsubsection{16.4 Equation différentielle linéaire d'ordre n}

\paragraph{16.4.1 Généralités}

Soit E un K espace vectoriel normé de dimension finie et considérons
\ell\_0,\\ldots,\ell\_n-1~
des applications continues de I intervalle de \mathbb{R}~ dans L(E). Soit g : I \rightarrow~
E continue. On peut alors considérer l'équation différentielle linéaire
d'ordre n

y^(n) = \ell\_ n-1(t).y^(n-1) +
\\ldots + \ell~\_
0(t).y + g(t)

En introduisant la fonction inconnue Y =
(y,y',\\ldots,y^(n-1)~),
on sait que cette équation est équivalente par réduction à l'ordre 1, à
l'équation Y ' = L(t).Y + G(t) où l'on a posé
L(t).(y\_0,\\ldots,y\_n-1~)
=
(y\_1,\\ldots,y\_n-1,\ell\_n-1(t).y\_n-1~
+ \\ldots~ +
\ell\_0(t).y\_0) est clairement une application linéaire de
E^n dans lui même et où G(t) =
(0,\\ldots~,0,g(t))
est une application continue de I dans E^n. Ceci va nous
permettre d'appliquer toute la théorie des équations différentielles
linéaires d'ordre 1 aux équations différentielles linéaires d'ordre n en
tenant compte de ce que l'application
\phi\mapsto~(\phi,\phi',\\ldots,\phi^(n-1)~)
est une bi\jmathection de l'ensemble des solutions de l'équation d'ordre n,
y^(n) = \ell\_n-1(t).y^(n-1) +
\\ldots~ +
\ell\_0(t).y + g(t) sur l'ensemble des solutions de l'équation
linéaire d'ordre 1, Y ' = L(t).Y + G(t), cette bi\jmathection étant
visiblement linéaire dans le cas où cela a un sens, c'est-à-dire lorsque
ces deux ensembles sont des espaces vectoriels, soit encore dans le cas
d'équations homogènes g = 0 (ce qui équivaut à G = 0).

Par la suite, nous nous intéresserons exclusivement au cas où E = K (le
corps de base). Le lecteur n'aura aucun mal à formuler les résultats
dans le cas d'un E quelconque, tout au moins lorsque cela aura un sens.
L'équation différentielle d'ordre n s'écrit alors sous la forme

y^(n) = a\_ n-1(t)y^(n-1) +
\\ldots + a~\_
0(t)y + b(t)

où les fonctions
a\_0,\\ldots,a\_n-1~,b
sont des fonctions continues de I dans le corps de base K. L'application
\phi\mapsto~(\phi,\phi',\\ldots,\phi^(n-1)~)
est une bi\jmathection de l'ensemble des solutions de l'équation d'ordre n
sur l'ensemble des solutions de l'équation d'ordre 1, Y ' = A(t).Y +
B(t) avec

A(t) = \left (\matrix\,0
&1&0&\\ldots~&0
\cr \⋮~
&\\ldots&\\\ldots&\\\ldots&\\⋮~
\cr 0
&\\ldots&\\\ldots~&0&1
\cr
a\_0(t)&\\ldots&\\\ldots&\\\ldots&a\_n-1(t)~\right
)

et

B(t) = \left (\matrix\,0
\cr \⋮~
& \cr 0 \cr b(t)\right )

cette bi\jmathection étant un isomorphisme de l'espace des solutions de
l'équation homogène y^(n) =
a\_n-1(t)y^(n-1) +
\\ldots~ +
a\_0(t)y sur l'espace des solutions de l'équation homogène Y ' =
A(t).Y .

\paragraph{16.4.2 Théorie de Cauchy-Lipschitz}

Le théorème suivant se déduit immédiatement du théorème correspondant
pour l'équation Y ' = L(t).Y + B(t)

Théorème~16.4.1 Soit I un intervalle de \mathbb{R}~,
a\_0,\\ldots,a\_n-1~,b
: I \rightarrow~ K continues. Alors toute solution maximale de l'équation
différentielle linéaire y^(n) =
a\_n-1(t)y^(n-1) +
\\ldots~ +
a\_0(t)y + b(t) est définie sur I. Pour tout t\_0 \in I et
tout
(y\_0,\\ldotsy\_n-1~)
\in K^n, il existe une et une seule solution (I,\phi) de
l'équation différentielle linéaire y^(n) =
a\_n-1(t)y^(n-1) +
\\ldots~ +
a\_0(t)y + b(t) vérifiant \phi(t\_0) =
y\_0,\\ldots,\phi^(n-1)(t\_0~)
= y\_n-1~; pour toute solution (J,\psi) de l'équation
différentielle vérifiant \psi(t\_0) =
y\_0,\\ldots,\psi^(n-1)(t\_0~)
= y\_n-1, on a~:

\text\$J \subset~ I\$ et \$\psi\$ est la restriction de \$\phi\$ à
\$J\$.

\paragraph{16.4.3 Structure des solutions de l'équation homogène.
Wronskien}

Le théorème suivant se déduit immédiatement du théorème correspondant
pour l'équation Y ' = L(t).Y

Théorème~16.4.2 Soit I un intervalle de \mathbb{R}~,
a\_0,\\ldots,a\_n-1~
: I \rightarrow~ K continues. L'ensemble S\_H des solutions définies sur I
de l'équation différentielle homogène y^(n) =
a\_n-1(t)y^(n-1) +
\\ldots~ +
a\_0(t)y est un espace vectoriel de dimension finie égale à n.
Plus précisément, pour tout t\_0 \in I, l'application
\epsilon\_t\_0 :
\phi\mapsto~(\phi(t\_0),\phi'(t\_0),\\ldots,\phi^(n-1)(t\_0~))
est un isomorphisme d'espaces vectoriels de S\_H sur
K^n.

Corollaire~16.4.3 Pour toute famille
(\phi\_1,\\ldots,\phi\_k~)
de solutions de l'équation homogène, on a

\forall~~t \in I,
\mathrmrg(\phi\_1,\\\ldots,\phi\_k~)
=\
\mathrmrg(\epsilon\_t(\phi\_1),\\ldots,\epsilon\_t(\phi\_k~))

Dans le cas k = n ceci amène à la définition suivante

Définition~16.4.1 Soit
(\phi\_1,\\ldots,\phi\_n~)
des fonctions de classe C^n de I dans K. On appelle wronskien
de la famille l'application
W\_\phi\_1,\\ldots,\phi\_n~
: I \rightarrow~ K,

t\mapsto~\mathrm{det}~
(\epsilon\_t(\phi\_1),\\ldots,\epsilon\_t(\phi\_n~))
= \left
\textbar{}\matrix\,\phi\_1(t)
&\\ldots&\phi\_n~(t)
\cr \phi\_1'(t)
&\\ldots&\phi\_n~'(t)
\cr
\\ldots~
&\\ldots&\\\ldots~
\cr
\phi\_1^(n-1)(t)&\\ldots&\phi\_n^(n-1)(t)~\right
\textbar{}

Théorème~16.4.4 Soit I un intervalle de \mathbb{R}~,
a\_0,\\ldots,a\_n-1~
: I \rightarrow~ K continues. Soit
\phi\_1,\\ldots,\phi\_n~
des solutions de l'équation différentielle homogène y^(n) =
a\_n-1(t)y^(n-1) +
\\ldots~ +
a\_0(t)y et W leur wronskien. Alors les conditions suivantes
sont équivalentes

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i)
  (\phi\_1,\\ldots,\phi\_n~)
  est une base de l'espace vectoriel S\_H des solutions de
  l'équation homogène y^(n) =
  a\_n-1(t)y^(n-1) +
  \\ldots~ +
  a\_0(t)y
\item
  (ii) \exists~t \in I,
  W(t)\neq~0
\item
  (iii) \forall~~t \in I,
  W(t)\neq~0
\end{itemize}

Démonstration Puisque \epsilon\_t est un isomorphisme de S\_H
sur K^n,
(\phi\_1,\\ldots,\phi\_n~)
est une base de S\_H si et seulement
si~(\epsilon\_t(\phi\_1),\\ldots,\epsilon\_t(\phi\_n~))
est une base de K^n, c'est-à-dire si et seulement
si~\mathrm{det}~
(\epsilon\_t(\phi\_1),\\ldots,\epsilon\_t(\phi\_n))\mathrel\neq~~0
ce qui montre bien l'équivalence des trois assertions. La proposition
suivante expliquera d'ailleurs complètement l'équivalence entre les
assertions (ii) et (iii).

Proposition~16.4.5 Soit I un intervalle de \mathbb{R}~,
a\_0,\\ldots,a\_n-1~
: I \rightarrow~ K continues. Soit
\phi\_1,\\ldots,\phi\_n~
des solutions de l'équation différentielle homogène y^(n) =
a\_n-1(t)y^(n-1) +
\\ldots~ +
a\_0(t)y et W leur wronskien. Alors pour tout y\_0,t \in I
on a W(t) = W(t\_0)exp~
\left (\int ~
\_t\_0^ta\_n-1(u) du\right
).

Démonstration On sait que pour dériver W(t) on doit faire la somme de
tous les déterminants obtenus en dérivant la i-ème ligne et en laissant
toutes les autres inchangées. Mais comme dans le wronskien, la i + 1-ème
ligne est la dérivée de la i-ème, en dérivant la i-ème ligne et en
laissant inchangée la i + 1-ième (si elle existe), le déterminant obtenu
a deux lignes égales, donc il est nul. On en déduit que le seul
déterminant non trivialement nul est celui obtenu en dérivant la n-ème
ligne, soit encore

W'(t) = \left
\textbar{}\matrix\,\phi\_1(t)
&\\ldots&\phi\_n~(t)
\cr \phi\_1'(t)
&\\ldots&\phi\_n~'(t)
\cr
\\ldots~
&\\ldots&\\\ldots~
\cr
\phi\_1^(n-2)(t)&\\ldots&\phi\_n^(n-2)~(t)
\cr \phi\_1^(n)(t)
&\\ldots&\phi\_n^(n)~(t)
\right \textbar{}

En soustrayant à la dernière ligne a\_0(t) fois la première,
a\_1(t) fois la
seconde,\\ldots~,
a\_n-2(t) fois la dernière et tenant compte de ce que
\phi\_\jmath^(n)(t) - a\_0(t)\phi\_\jmath(t) -
a\_1(t)\phi\_\jmath'(t)
-\\ldots~ -
a\_n-2(t)\phi\_\jmath^(n-2)(t) =
a\_n-1(t)\phi\_\jmath^(n-1)(t), on obtient alors

\begin{align*} W'(t)& = \left
\textbar{}\matrix\,\phi\_1(t)
&\\ldots&\phi\_n~(t)
\cr \phi\_1'(t)
&\\ldots&\phi\_n~'(t)
\cr
\\ldots~
&\\ldots&\\\ldots~
\cr \phi\_1^(n-2)(t)
&\\ldots&\phi\_n^(n-2)~(t)
\cr
a\_n-1(t)\phi\_1^(n-1)(t)&\\ldots&a\_n-1(t)\phi\_n^(n-1)(t)~\right
\textbar{} & \%& \\ & =
a\_n-1(t)\left
\textbar{}\matrix\,\phi\_1(t)
&\\ldots&\phi\_n~(t)
\cr \phi\_1'(t)
&\\ldots&\phi\_n~'(t)
\cr
\\ldots~
&\\ldots&\\\ldots~
\cr
\phi\_1^(n-2)(t)&\\ldots&\phi\_n^(n-2)~(t)
\cr
\phi\_1^(n-1)(t)&\\ldots&\phi\_n^(n-1)(t)~\right
\textbar{} = a\_n-1(t)W(t)& \%&
\\ \end{align*}

en utilisant la linéarité du déterminant par rapport à sa dernière
ligne. Donc W est solution de l'équation différentielle linéaire
scalaire d'ordre 1, y' = a\_n-1(t)y ce qui implique
immédiatement la formule voulue.

Remarque~16.4.1 Les fonctions \phi\_1 :
t\mapsto~t et \phi\_2 :
t\mapsto~sin~ t ont comme
wronskien W(t) = \left
\textbar{}\matrix\,t&sin~
t\cr 1 &cos~
t\right \textbar{} = tcos~ t
- sin~ t. Ce wronskien n'est pas identiquement
nul et pourtant il s'annule en 0. Ceci montre que ces deux fonctions ne
peuvent pas être toutes deux solutions d'une même équation
différentielle homogène d'ordre 2 à coefficients continus sur \mathbb{R}~.

\paragraph{16.4.4 Méthode de variation des constantes}

Supposons connue une base
(\phi\_1,\\ldots,\phi\_n~)
de l'espace S\_H de l'équation différentielle homogène
y^(n) = a\_n-1(t)y^(n-1) +
\\ldots~ +
a\_0(t)y et posons \Phi\_\jmath(t) = \left
(\matrix\,\phi\_\jmath(t)
\cr \phi\_\jmath'(t) \cr
\\ldots~
\cr \phi\_\jmath^(n-1)(t)\right
). Alors
(\Phi\_1,\\ldots,\Phi\_n~)
est une base de l'espace des solutions du système homogène Y ' = A(t)Y
où

A(t) = \left (\matrix\,0
&1&0&\\ldots~&0
\cr \⋮~
&\\ldots&\\\ldots&\\\ldots&\\⋮~
\cr 0
&\\ldots&\\\ldots~&0&1
\cr
a\_0(t)&\\ldots&\\\ldots&\\\ldots&a\_n-1(t)~\right
)

Si b : I \rightarrow~ \mathbb{R}~ est une fonction continue, la résolution de l'équation
linéaire y^(n) = a\_n-1(t)y^(n-1) +
\\ldots~ +
a\_0(t)y + b(t) est équivalente à la résolution du système
différentiel linéaire Y ' = A(t)Y + B(t) où B(t) = \left
(\matrix\,0 \cr
\⋮~ &
\cr 0 \cr b(t)\right ).
Comme nous connaissons une base de l'espace des solutions du système
homogène, nous pouvons résoudre ce système linéaire en posant Y (t) =
\lambda~\_1(t)\Phi\_1(t) +
\\ldots~ +
\lambda~\_n(t)\Phi\_n(t) où
\lambda~\_1,\\ldots,\lambda~\_n~
sont des fonctions de classe \mathcal{C}^1 de I dans K. Comme Y (t) =
\left (\matrix\,y(t)
\cr y'(t) \cr
\\ldots~
\cr y^(n-1)(t)\right ) ceci
revient à poser

\begin{align*} y(t)& =&
\lambda~\_1(t)\phi\_1(t) +
\\ldots~ +
\lambda~\_n(t)\phi\_n(t) \%& \\
y'(t)& =& \lambda~\_1(t)\phi\_1'(t) +
\\ldots~ +
\lambda~\_n(t)\phi\_n'(t) \%& \\
\\ldots~& & \%&
\\ y^(n-1)(t)& =& \lambda~\_
1(t)\phi\_1^(n-1)(t) +
\\ldots + \lambda~~\_
n(t)\phi\_n^(n-1)(t)\%& \\
\end{align*}

autrement dit, d'après la règle de dérivation des produits, cela revient
à imposer aux fonctions
\lambda~\_1,\\ldots,\lambda~\_n~
de vérifier les conditions

\begin{align*} \lambda~\_1'(t)\phi\_1(t) +
\\ldots~ +
\lambda~\_n'(t)\phi\_n(t)& =& 0\%&
\\ \lambda~\_1'(t)\phi\_1'(t) +
\\ldots~ +
\lambda~\_n'(t)\phi\_n'(t)& =& 0\%&
\\ &
\\ldots~& \%&
\\
\lambda~\_1'(t)\phi\_1^(n-2)(t) +
\\ldots + \lambda~~\_
n'(t)\phi\_n^(n-2)(t)& =& 0\%&
\\ \end{align*}

Dans ces conditions, par dérivation de y^(n-1)(t) =
\lambda~\_1(t)\phi\_1^(n-1)(t) +
\\ldots~ +
\lambda~\_n(t)\phi\_n^(n-1)(t), on obtient

\begin{align*} y^(n)(t)& =& \lambda~\_
1(t)\phi\_1^(n)(t) +
\\ldots + \lambda~~\_
n(t)\phi\_n^(n)(t) \%& \\
& & \quad +
\lambda~\_1'(t)\phi\_1^(n-1)(t) +
\\ldots + \lambda~~\_
n'(t)\phi\_n^(n-1)(t) \%&
\\ & =&
\lambda~\_1(t)\\sum
\_k=0^n-1a\_ k(t)\phi\_1^(k)(t) +
\ldots + \lambda~~\_
n(t)\sum \_k=0^n-1a~\_
k(t)\phi\_n^(k)(t)\%& \\ &
& \quad + \lambda~\_1'(t)\phi\_1^(n-1)(t) +
\\ldots + \lambda~~\_
n'(t)\phi\_n^(n-1)(t) \%&
\\ & =& \\sum
\_k=0^n-1a\_ k(t)\left
(\lambda~\_1(t)\phi\_1^(k)(t) +
\ldots + \lambda~~\_
n(t)\phi\_n^(k)(t)\right ) \%&
\\ & & \quad +
\lambda~\_1'(t)\phi\_1^(n-1)(t) +
\\ldots + \lambda~~\_
n'(t)\phi\_n^(n-1)(t) \%&
\\ & =& \\sum
\_k=0^n-1a\_ k(t)y^(k)(t) \%&
\\ & & \quad +
\lambda~\_1'(t)\phi\_1^(n-1)(t) +
\\ldots + \lambda~~\_
n'(t)\phi\_n^(n-1)(t) \%&
\\ \end{align*}

si bien que

\begin{align*} y^(n)(t) = a\_
n-1(t)y^(n-1) +
\\ldots + a~\_
0(t)y + b(t) \Leftrightarrow&& \%&
\\ & &
\lambda~\_1'(t)\phi\_1^(n-1)(t) +
\\ldots + \lambda~~\_
n'(t)\phi\_n^(n-1)(t) = b(t)\%&
\\ \end{align*}

En conclusion,
\lambda~\_1'(t),\\ldots,\lambda~\_n~'(t)
doivent être solutions du système d'équations linéaires

\left \\array
\lambda~\_1'(t)\phi\_1(t) +
\\ldots~ +
\lambda~\_n'(t)\phi\_n(t) & = 0 \cr
\lambda~\_1'(t)\phi\_1'(t) +
\\ldots~ +
\lambda~\_n'(t)\phi\_n'(t) & = 0\cr
\\ldots~
\cr \lambda~\_1'(t)\phi\_1^(n-2)(t) +
\\ldots~ +
\lambda~\_n'(t)\phi\_n^(n-2)(t)& = 0 \cr
\lambda~\_1'(t)\phi\_1^(n-1)(t) +
\\ldots~ +
\lambda~\_n'(t)\phi\_n^(n-1)(t)& = b(t) 
\right .

Or ce système est un système de Cramer (son déterminant est le wronskien
de
\phi\_1,\\ldots,\phi\_n~
qui par hypothèse ne s'annule pas)~; sa résolution conduit à la
détermination de
\lambda~\_1',\\ldots,\lambda~\_n~'
et il reste à faire n calculs de primitives de fonctions à valeurs dans
K pour terminer la résolution de l'équation linéaire.

Méthode. Supposons connue une base
(\phi\_1,\\ldots,\phi\_n~)
de l'espace S\_H de l'équation différentielle homogène
y^(n) = a\_n-1(t)y^(n-1) +
\\ldots~ +
a\_0(t)y. On résout l'équation linéaire y^(n) =
a\_n-1(t)y^(n-1) +
\\ldots~ +
a\_0(t)y + b(t) en posant y(t) = \lambda~\_1(t)\phi\_1(t)
+ \\ldots~ +
\lambda~\_n(t)\phi\_n(t), où
\lambda~\_1,\\ldots,\lambda~\_n~
sont des fonctions de classe \mathcal{C}^1 auxquelles on impose les
conditions

\begin{align*} \lambda~\_1'(t)\phi\_1(t) +
\\ldots~ +
\lambda~\_n'(t)\phi\_n(t)& = 0& \%&
\\ \lambda~\_1'(t)\phi\_1'(t) +
\\ldots~ +
\lambda~\_n'(t)\phi\_n'(t)& = 0& \%&
\\
\\ldots~& & \%&
\\
\lambda~\_1'(t)\phi\_1^(n-2)(t) +
\\ldots + \lambda~~\_
n'(t)\phi\_n^(n-2)(t)& = 0& \%&
\\ \end{align*}

Alors les fonctions
\lambda~\_1',\\ldots,\lambda~\_n~'
sont solution du système de Cramer

\left \\array
\lambda~\_1'(t)\phi\_1(t) +
\\ldots~ +
\lambda~\_n'(t)\phi\_n(t) & = 0 \cr
\lambda~\_1'(t)\phi\_1'(t) +
\\ldots~ +
\lambda~\_n'(t)\phi\_n'(t) & = 0\cr
\\ldots~
\cr \lambda~\_1'(t)\phi\_1^(n-2)(t) +
\\ldots~ +
\lambda~\_n'(t)\phi\_n^(n-2)(t)& = 0 \cr
\lambda~\_1'(t)\phi\_1^(n-1)(t) +
\\ldots~ +
\lambda~\_n'(t)\phi\_n^(n-1)(t)& = b(t) 
\right .

On résout ce système, puis n calculs de primitives permettent de
déterminer les fonctions
\lambda~\_1,\\ldots,\lambda~\_n~.

\paragraph{16.4.5 Méthode d'abaissement du degré}

Cette méthode ne présente réellement d'intérêt que pour une équation
linéaire d'ordre 2, y'`= a(t)y' + b(t)y + c(t). Supposons connue une
solution \phi de l'équation homogène qui ne s'annule pas sur I et faisons
le changement de fonction inconnue z(t) = y(t) \over
\phi(t) autrement dit y(t) = z(t)\phi(t). On a alors y'(t) = z'(t)\phi(t) +
z(t)\phi'(t) et y'`(t) = z'`(t)\phi(t) + 2z'(t)\phi'(t) + z(t)\phi''(t), si bien que

\begin{align*} y'`(t) - a(t)y'(t) - c(t)y(t)&&
\%& \\ & =& z'`(t)\phi(t) + (2\phi'(t) -
\phi(t))z'(t) \%& \\ & &
\quad + (\phi'`(t) - a(t)\phi'(t) - b(t)\phi(t))z(t)\%&
\\ & =& z'`(t)\phi(t) + (2\phi'(t) -
\phi(t))z'(t) \%& \\
\end{align*}

compte tenu de ce que \phi'`(t) - a(t)\phi'(t) - b(t)\phi(t) = 0. On en déduit
que

\begin{align*} y'`(t) = a(t)y'(t) + b(t)y(t) + c(t)
\Leftrightarrow&& \%& \\
& & z'`(t)\phi(t) + (2\phi'(t) - \phi(t))z'(t) = c(t)\%&
\\ \end{align*}

qui est une équation différentielle d'ordre 1 en la fonction inconnue
z'(t), que l'on sait donc résoudre à l'aide de deux calculs de
primitives.

Remarque~16.4.2 Cette méthode n'est à utiliser qu'en dernier recours,
c'est-à-dire lorsqu'on ne dispose que d'une seule solution de l'équation
homogène, et on doit tou\jmathours lui préférer (lorsque c'est possible) la
méthode de variation des constantes. En effet la méthode d'abaissement
du degré demande que soit réalisée une condition contraignante (une
solution ne s'annulant pas) et conduit à deux calculs de primitives pour
obtenir z'(t) et un troisième calcul de primitive pour obtenir z(t). De
plus ces trois calculs s'enchaînent (toute erreur dans l'un des calculs
oblige à recommencer l'ensemble des calculs). Par contre, la méthode de
variation des constantes n'impose aucune condition restrictive aux
solutions de l'équation homogène et ne nécessite que deux calculs de
primitives, qui plus est indépendants l'un de l'autre.

\paragraph{16.4.6 Equation homogène à coefficients constants}

Nous étudierons dans ce paragraphe l'équation y^(n) +
a\_n-1y^(n-1) +
\\ldots~ +
a\_0y = 0 où
a\_0,\\ldots,a\_n-1~
sont des éléments donnés du corps de base K (égal à \mathbb{R}~ ou \mathbb{C}). En cas de
besoin et pour unifier les notations, nous poserons a\_n = 1.

Définition~16.4.2 Le polynôme \chi(X) = X^n +
a\_n-1X^n-1 +
\\ldots~ +
a\_0 \in K{[}X{]} est appelé le polynôme caractéristique de
l'équation homogène y^(n) + a\_n-1y^(n-1)
+ \\ldots~ +
a\_0y = 0.

Remarque~16.4.3 t\mapsto~e^\lambda~t est
solution de y^(n) + a\_n-1y^(n-1) +
\\ldots~ +
a\_0y = 0 si et seulement si~\chi(\lambda~) = 0.

Lemme~16.4.6 Soit P(X) \in K{[}X{]} et \lambda~ \in K. Soit f :
t\mapsto~P(t)e^\lambda~t de \mathbb{R}~ dans K. Alors

\forall~t \in \mathbb{R}~, f^(n)(t) + a~\_
n-1f^(n-1)(t) +
\\ldots + a~\_
0f(t) = e^\lambda~t \\sum
\_p=0^n 1 \over p!
\chi^(p)(\lambda~)P^(p)(t)

Démonstration La formule de Leibnitz nous donne f^(k)(t)
= \\sum ~
\_p=0^kC\_k^pP^(p)(t)\lambda~^k-pe^\lambda~t
si bien que

\begin{align*} f^(n)(t) + a\_
n-1f^(n-1)(t) +
\\ldots + a~\_
0f(t) = \sum \_k=0^na~\_
kf^(k)(t)&&\%& \\ & =&
e^\lambda~t \\sum
\_k=0^na\_ k \\sum
\_p=0^k k! \over p!(k - p)!
P^(p)(t)\lambda~^k-p \%&
\\ & =& e^\lambda~t
\sum \_0\leqp\leqk\leqna\_k~ k!
\over p!(k - p)! P^(p)(t)\lambda~^k-p
\%& \\ & =& e^\lambda~t
\sum \_p=0^n~ 1
\over p! P^(p)(t)\\sum
\_k=p^na\_ k k! \over (k - p)!
\lambda~^k-p\%& \\ & =&
e^\lambda~t \sum \_p=0^n~ 1
\over p! \chi^(p)(\lambda~)P^(p)(t) \%&
\\ \end{align*}

Supposons donc que \lambda~ est une racine de \chi de multiplicité m et que
deg~ P \leq m - 1. On a alors
\forall~p \leq m - 1, \chi^(p)~(\lambda~) = 0 et
\forall~p ≥ m, P^(p)~(t) = 0, si bien que
\forall~~p \in {[}0,n{]},
\chi^(p)(\lambda~)P^(p)(t) = 0. On en déduit donc que f :
t\mapsto~e^\lambda~tP(t) est solution de
l'équation différentielle y^(n) +
a\_n-1y^(n-1) +
\\ldots~ +
a\_0y = 0.

Lemme~16.4.7 Soit
\lambda~\_1,\\ldots,\lambda~\_k~
des éléments distincts de K et
m\_1,\\ldots,m\_k~
des entiers naturels. Alors la famille des applications
t\mapsto~t^\jmathe^\lambda~\_it
avec 1 \leq i \leq k et 0 \leq \jmath \leq m\_i - 1 est libre.

Démonstration Supposons que cette famille est liée. Notons n =
m\_1 + ⋯ + m\_k,
f\_1,\\ldots,f\_n~
ces fonctions. Il existe donc
\alpha~\_1,\\ldots,\alpha~\_n~
\in K, non tous nuls, tels que \forall~~t \in \mathbb{R}~,
\alpha~\_1f\_1(t) +
\\ldots~ +
\alpha~\_nf\_n(t) = 0. Fixons t\_0 \in \mathbb{R}~. Par dérivation
de l'identité précédente au point t\_0, on a donc
\forall~~k \in \mathbb{N}~,
a\_1f\_1^(k)(t\_0) +
\\ldots~ +
\alpha~\_nf\_n^(k)(t\_0) = 0 et en particulier
la matrice wronskienne \left
(\matrix\,f\_1(t\_0)
&\\ldots&f\_n(t\_0~)
\cr f\_1'(t\_0)
&\\ldots&f\_n'(t\_0~)
\cr
\\ldots~
&\\ldots&\\\ldots~
\cr
f\_1^(n-1)(t\_0)&\\ldots&f\_n^(n-1)(t\_0)~\right
) n'est pas inversible puisque ses vecteurs colonnes forment une famille
liée. On en déduit que ses vecteurs lignes forment une famille liée, et
que donc il existe
\beta~\_0,\\ldots,\beta~\_n-1~
non tous nuls (mais dépendant de t\_0) tels que

\forall~~\jmath \in {[}1,n{]},
\beta~\_0f\_\jmath(t\_0) +
\beta~\_1f\_\jmath'(t\_0) +
\\ldots~ +
\beta~\_n-1f\_\jmath^(n-1)(t\_ 0) = 0

Posons alors \chi(X) = \beta~\_n-1X^n-1 +
⋯ + \beta~\_0. Le lemme précédent (où l'on
remplace n par n - 1) nous montre que si f(t) = e^\lambda~tP(t),
alors

\beta~\_0f(t\_0) + \beta~\_1f'(t\_0) +
\\ldots~ +
\beta~\_n-1f^(n-1)(t\_ 0) =
e^\lambda~t\_0  \\sum
\_p=0^n-1 1 \over p!
\chi^(p)(\lambda~)P^(p)(t\_ 0)

En particulier, pour P(X) = X^\jmath et \lambda~ = \lambda~\_i, on
obtient

\begin{align*} \beta~\_0f(t\_0) +
\beta~\_1f'(t\_0) +
\\ldots~ +
\beta~\_n-1f^(n-1)(t\_ 0)& & \%&
\\ = e^\lambda~\_it\_0
 \sum \_p=0^\jmath~ 1
\over p! \chi^(p)(\lambda~\_ i) \jmath!
\over (\jmath - p)! t\_0^\jmath-p& & \%&
\\ \end{align*}

car les dérivées suivantes de X^\jmath sont nulles. On en déduit
que

\forall~\jmath \leq m\_i~ - 1,
\sum \_p=0^\jmath~ 1
\over p! \chi^(p)(\lambda~\_ i) \jmath!
\over (\jmath - p)! t\_0^\jmath-p = 0

autrement dit (compte tenu de  \jmath! \over p!(p-\jmath)! =
C\_\jmath^p)

\left \\array
C\_0^0\chi(\lambda~\_i) & = 0 \cr
C\_1^0\chi(\lambda~\_i)t\_0 +
C\_1^1\chi'(\lambda~\_i) & = 0 \cr
C\_2^0\chi(\lambda~\_i)t\_0^2 +
C\_2^1\chi'(\lambda~\_i)t +
C\_2^2\chi''(\lambda~\_i) = 0\cr
&\\ldots~
\cr
C\_m\_i-1^0\chi(\lambda~)t\_0^m\_i-1
+ \\ldots~ +
C\_m\_
i-1^m\_i-2\chi^(m\_i-2)(\lambda~)t +
C\_
m\_i-1^m\_i-1\chi^(m\_i-1)(\lambda~\_
i)& = 0  \right .

ce qui implique évidemment que \chi(\lambda~\_i) =
\\ldots~ =
\chi^(m\_i-1)(\lambda~\_i) = 0. Donc \lambda~\_i est
racine de \chi de multiplicité au moins égale à m\_i. Mais alors la
somme des multiplicités des racines du polynôme non nul \chi(X) est au
moins égale à m\_1 +
\\ldots~ +
m\_k = n alors qu'il est de degré au plus n - 1. C'est absurde,
ce qui montre que la famille est libre.

Revenons à notre équation différentielle homogène y^(n) +
a\_n-1y^(n-1) +
\\ldots~ +
a\_0y = 0 et supposons que son polynôme caractéristique \chi(X) est
scindé sur K (ce qui est automatique si K = \mathbb{C}). Soit
\lambda~\_1,\\ldots,\lambda~\_k~
ses racines distinctes de multiplicités respectives
m\_1,\\ldots,m\_k~,
si bien que m\_1 +
\\ldots~ +
m\_k = n. Alors les n fonctions
t\mapsto~t^\jmathe^\lambda~\_it
avec 1 \leq i \leq k et 0 \leq \jmath \leq m\_i - 1 sont solutions de l'équation
différentielle homogène et forment une famille libre. Comme l'espace des
solutions de l'équation homogène est de dimension n, ces fonctions
forment une base de l'espace des solutions. Autrement dit les solutions
de l'équation homogène sont exactement les fonctions qui s'écrivent sous
la forme

t\mapsto~\\sum
\_i=1^k \\sum
\_\jmath=0^m\_i-1\alpha~\_
i,\jmatht^\jmathe^\lambda~\_it =
\sum \_i=1^kP~\_
i(t)e^\lambda~\_it

avec P\_i(X) =\
\sum ~
\_i=0^m\_i-1\alpha~\_i,\jmathX^\jmath \in K{[}X{]}
et deg P\_i \leq m\_i~ - 1. On a
donc démontré le résultat suivant

Théorème~16.4.8 Soit
a\_0,\\ldots,a\_n-1~
\in K et l'équation différentielle homogène y^(n) +
a\_n-1y^(n-1) +
\\ldots~ +
a\_0y = 0. On suppose que le polynôme caractéristique \chi(X) =
X^n + a\_n-1X^n-1 +
\\ldots~ +
a\_0 est scindé sur K (ce qui est automatique si K = \mathbb{C}). Soit
\lambda~\_1,\\ldots,\lambda~\_k~
ses racines distinctes de multiplicités respectives
m\_1,\\ldots,m\_k~.
Alors les solutions de l'équation homogène sont exactement les fonctions

t\mapsto~\\sum
\_i=1^kP\_
i(t)e^\lambda~\_it\quad
\text avec \$P\_ i(X) \in K{[}X{]}\$ et \$deg
P\_i \leq m\_i - 1\$.

\paragraph{16.4.7 Equation linéaire à coefficients constants}

Il s'agit ici de résoudre une équation différentielle linéaire à
coefficients constants y^(n) +
a\_n-1y^(n-1) +
\\ldots~ +
a\_0y = b(t) où b est une application continue de I dans K. Dans
le cas général, puisque nous savons résoudre l'équation homogène, la
méthode de variation des constantes permet d'aboutir au résultat au prix
du calcul de n primitives. Mais d'autre part, il suffit évidemment de
déterminer une solution particulière de l'équation différentielle
linéaire pour en avoir la solution générale en a\jmathoutant à cette solution
particulière la solution générale de l'équation homogène.

Examinons le cas particulier où b(t) = Q(t)e^\mut avec Q(X) \in
K{[}X{]} et \mu \in K. Nous allons rechercher une solution particulière du
type f(t) = P(t)e^\mut. On sait alors que

f^(n)(t) + a\_ n-1f^(n-1)(t) +
\\ldots + a~\_
0f(t) = e^\lambda~t \\sum
\_p=0^n 1 \over p!
\chi^(p)(\lambda~)P^(p)(t)

Autrement dit, f sera solution de l'équation linéaire si et seulement
si~\\sum ~
\_p=0^n 1 \over p!
\chi^(p)(\lambda~)P^(p)(X) = Q(X). Soit m la multiplicité de
\mu comme racine de \chi (nous poserons m = 0 si \mu n'est pas racine de \chi). On
a alors \chi(\mu) =
\\ldots~ =
\chi^(m-1)(\mu) = 0 et
\chi^(m)(\mu)\neq~0. On a donc à résoudre
l'équation

\sum \_p=m^n~ 1
\over p! \chi^(p)(\mu)P^(p)(X) = Q(X)

Cela se fera par identification si nous connaissons un ma\jmathorant du degré
de P. Mais pour cela il suffit d'appliquer le lemme suivant, où l'on
désigne par K\_p{[}X{]} l'espace des polynômes de degré
inférieur ou égal à p,

Lemme~16.4.9 Soit d \in \mathbb{N}~, l'application \theta :
P\mapsto~\\\sum
 \_p=m^n 1 \over p!
\chi^(p)(\mu)P^(p)(X) est une application linéaire
sur\jmathective de K\_d+m{[}X{]} dans K\_d{[}X{]}.

Démonstration Si deg~ P \leq d + m, alors pour p ≥
m, on a deg P^(p)~(X) \leq d ce qui
montre que \theta(P) =\ \\sum
 \_p=m^n 1 \over p!
\chi^(p)(\mu)P^(p)(X) \in K\_ d{[}X{]}. Cette
application est visiblement linéaire. Cherchons le rang de cette
application linéaire et pour cela déterminons sa matrice. Si \jmath \leq d + m,
on a

\theta(X^\jmath) = \sum \_p=m^\jmath~
1 \over p! \chi^(p)(\mu) \jmath!
\over (\jmath - p)! X^\jmath-p =
\sum \_p=m^\jmathC~\_
\jmath^p\chi^(p)(\mu)X^\jmath-p

si bien que la matrice de \theta dans les bases canoniques
(1,X,\\ldots,X^d+m~)
et
(1,X,\\ldots,X^d~)
est la matrice

\left ( \includegraphics{cours9x.png}
\,\right )

Or la matrice formée par les d + 1 dernières colonnes est visiblement
inversible, ce qui montre que le rang de \theta est égal à d + 1
= dim K\_d~{[}X{]} et donc que \theta est
sur\jmathective. On a donc la proposition suivante

Proposition~16.4.10 Soit
a\_0,\\ldots,a\_n-1~
\in K, Q \in K{[}X{]} et \mu \in K. L'équation différentielle linéaire
y^(n) + a\_n-1y^(n-1) +
\\ldots~ +
a\_0y = Q(t)e^\mut admet au moins une solution de la
forme P(t)e^\mut où P \in K{[}X{]} et
deg P \leq\ deg~ Q + m, m
désignant la multiplicité de \mu comme racine du polynôme caractéristique
de l'équation homogène.

Remarque~16.4.4 Le fait qu'il faille a\jmathouter au degré de Q la
multiplicité m de \mu comme racine de \chi s'appelle le phénomène de
résonance. Il implique que même si Q est constante, il peut exister des
solutions du type P(t)e^\mut avec deg~
P ≥ 1 qui peuvent être non bornées et entraîner des catastrophes dans le
système contrôlé par l'équation différentielle.

Remarque~16.4.5 La méthode précédente par identification permet
également de résoudre des équations du type y^(n) +
a\_n-1y^(n-1) +
\\ldots~ +
a\_0y = \\sum ~
\_i=1^qQ\_i(t)e^\mu\_it en
remarquant que si f\_i est une particulière de l'équation
y^(n) + a\_n-1y^(n-1) +
\\ldots~ +
a\_0y = Q\_i(t)e^\mu\_it, alors
f\_1 + ⋯ + f\_q est solution
de y^(n) + a\_n-1y^(n-1) +
\\ldots~ +
a\_0y = \\sum ~
\_i=1^qQ\_i(t)e^\mu\_it (ce que
l'on appelle le principe de superposition des solutions). Elle
s'applique en particulier à des équations du type y^(n) +
a\_n-1y^(n-1) +
\\ldots~ +
a\_0y = Q(t)cos~ (\omegat) ou
y^(n) + a\_n-1y^(n-1) +
\\ldots~ +
a\_0y = Q(t)sin~ (\omegat) pour lesquelles
il suffit de passer en exponentielle complexe~: poser
cos (\omegat) = 1 \over 2~
(e^i\omegat + e^-i\omegat) et sin~
(\omegat) = 1 \over 2i (e^i\omegat -
e^-i\omegat).

\paragraph{16.4.8 Equations d'Euler}

Considérons une équation différentielle homogène du type
t^ny^(n) +
a\_n-1t^n-1y^(n-1) +
\\ldots~ +
a\_1ty' + a\_0y = 0 que nous étudierons sur {]}0,+\infty~{[}
(il suffit de changer t en - t pour faire une étude similaire sur {]}
-\infty~,0{[}). Faisons le changement de variable t = e^u, soit
encore u = log~ t. Nous poserons donc y(t) =
z(u) soit encore y(t) = z(log~ t). Une
récurrence facile montre que

\forall~k \in \mathbb{N}~, y^(k)~(t) = 1
\over t^k  \\sum
\_p=0^k\lambda~\_ k,pz^(p)(log t)

C'est clair pour k = 0 et si c'est vrai pour k, on a

\begin{align*} y^(k+1)(t)& =& - k
\over t^k+1  \\sum
\_p=0^k\lambda~\_ k,pz^(p)(log t) + 1
\over t^k  \\sum
\_p=0^k\lambda~\_ k,p 1 \over t
z^(p+1)(log t) \%& \\ & =&
- k \over t^k+1 
\sum \_p=0^k\lambda~~\_
k,pz^(p)(log t) + 1 \over
t^k+1  \\sum
\_p=0^k\lambda~\_ k,pz^(p+1)(log t)\%&
\\ & =& 1 \over
t^k+1  \\sum
\_p=0^k+1\lambda~\_ k+1,pz^(p)(log t) \%&
\\ \end{align*}

avec \lambda~\_k+1,p = -k\lambda~\_k,p + \lambda~\_k,p-1 si 1 \leq p \leq
k, \lambda~\_k+1,0 = -k\lambda~\_k,0 et \lambda~\_k+1,k+1 =
\lambda~\_k,k.

On a donc t^ky^(k)(t) =\
\sum ~
\_p=0^k\lambda~\_k,pz^(p)(u) si bien que
l'équation devient une équation homogène d'ordre n à coefficients
constants en la fonction z(u). Ses solutions sont du type z(u)
= \\sum ~
\_i=1^ke^\lambda~\_iuP\_i(u) si bien
que les solutions de l'équation d'Euler sont de la forme

y(t) = \\sum
\_i=1^kt^\lambda~\_i P\_i(log t)

On retiendra

Proposition~16.4.11 Dans une équation d'Euler
t^ny^(n) +
a\_n-1t^n-1y^(n-1) +
\\ldots~ +
a\_1ty' + a\_0y = 0, le changement de variable t =
e^u conduit à une équation différentielle homogène d'ordre n
à coefficients constants.

{[}
{[}
{[}
{[}

\end{document}

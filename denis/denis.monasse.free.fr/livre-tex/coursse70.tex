\documentclass[]{article}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={Formes quadratiques reelles},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}
 
/* start css.sty */
.cmr-5{font-size:50%;}
.cmr-7{font-size:70%;}
.cmmi-5{font-size:50%;font-style: italic;}
.cmmi-7{font-size:70%;font-style: italic;}
.cmmi-10{font-style: italic;}
.cmsy-5{font-size:50%;}
.cmsy-7{font-size:70%;}
.cmex-7{font-size:70%;}
.cmex-7x-x-71{font-size:49%;}
.msbm-7{font-size:70%;}
.cmtt-10{font-family: monospace;}
.cmti-10{ font-style: italic;}
.cmbx-10{ font-weight: bold;}
.cmr-17x-x-120{font-size:204%;}
.cmsl-10{font-style: oblique;}
.cmti-7x-x-71{font-size:49%; font-style: italic;}
.cmbxti-10{ font-weight: bold; font-style: italic;}
p.noindent { text-indent: 0em }
td p.noindent { text-indent: 0em; margin-top:0em; }
p.nopar { text-indent: 0em; }
p.indent{ text-indent: 1.5em }
@media print {div.crosslinks {visibility:hidden;}}
a img { border-top: 0; border-left: 0; border-right: 0; }
center { margin-top:1em; margin-bottom:1em; }
td center { margin-top:0em; margin-bottom:0em; }
.Canvas { position:relative; }
li p.indent { text-indent: 0em }
.enumerate1 {list-style-type:decimal;}
.enumerate2 {list-style-type:lower-alpha;}
.enumerate3 {list-style-type:lower-roman;}
.enumerate4 {list-style-type:upper-alpha;}
div.newtheorem { margin-bottom: 2em; margin-top: 2em;}
.obeylines-h,.obeylines-v {white-space: nowrap; }
div.obeylines-v p { margin-top:0; margin-bottom:0; }
.overline{ text-decoration:overline; }
.overline img{ border-top: 1px solid black; }
td.displaylines {text-align:center; white-space:nowrap;}
.centerline {text-align:center;}
.rightline {text-align:right;}
div.verbatim {font-family: monospace; white-space: nowrap; text-align:left; clear:both; }
.fbox {padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
div.fbox {display:table}
div.center div.fbox {text-align:center; clear:both; padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
div.minipage{width:100%;}
div.center, div.center div.center {text-align: center; margin-left:1em; margin-right:1em;}
div.center div {text-align: left;}
div.flushright, div.flushright div.flushright {text-align: right;}
div.flushright div {text-align: left;}
div.flushleft {text-align: left;}
.underline{ text-decoration:underline; }
.underline img{ border-bottom: 1px solid black; margin-bottom:1pt; }
.framebox-c, .framebox-l, .framebox-r { padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
.framebox-c {text-align:center;}
.framebox-l {text-align:left;}
.framebox-r {text-align:right;}
span.thank-mark{ vertical-align: super }
span.footnote-mark sup.textsuperscript, span.footnote-mark a sup.textsuperscript{ font-size:80%; }
div.tabular, div.center div.tabular {text-align: center; margin-top:0.5em; margin-bottom:0.5em; }
table.tabular td p{margin-top:0em;}
table.tabular {margin-left: auto; margin-right: auto;}
div.td00{ margin-left:0pt; margin-right:0pt; }
div.td01{ margin-left:0pt; margin-right:5pt; }
div.td10{ margin-left:5pt; margin-right:0pt; }
div.td11{ margin-left:5pt; margin-right:5pt; }
table[rules] {border-left:solid black 0.4pt; border-right:solid black 0.4pt; }
td.td00{ padding-left:0pt; padding-right:0pt; }
td.td01{ padding-left:0pt; padding-right:5pt; }
td.td10{ padding-left:5pt; padding-right:0pt; }
td.td11{ padding-left:5pt; padding-right:5pt; }
table[rules] {border-left:solid black 0.4pt; border-right:solid black 0.4pt; }
.hline hr, .cline hr{ height : 1px; margin:0px; }
.tabbing-right {text-align:right;}
span.TEX {letter-spacing: -0.125em; }
span.TEX span.E{ position:relative;top:0.5ex;left:-0.0417em;}
a span.TEX span.E {text-decoration: none; }
span.LATEX span.A{ position:relative; top:-0.5ex; left:-0.4em; font-size:85%;}
span.LATEX span.TEX{ position:relative; left: -0.4em; }
div.float img, div.float .caption {text-align:center;}
div.figure img, div.figure .caption {text-align:center;}
.marginpar {width:20%; float:right; text-align:left; margin-left:auto; margin-top:0.5em; font-size:85%; text-decoration:underline;}
.marginpar p{margin-top:0.4em; margin-bottom:0.4em;}
.equation td{text-align:center; vertical-align:middle; }
td.eq-no{ width:5%; }
table.equation { width:100%; } 
div.math-display, div.par-math-display{text-align:center;}
math .texttt { font-family: monospace; }
math .textit { font-style: italic; }
math .textsl { font-style: oblique; }
math .textsf { font-family: sans-serif; }
math .textbf { font-weight: bold; }
.partToc a, .partToc, .likepartToc a, .likepartToc {line-height: 200%; font-weight:bold; font-size:110%;}
.chapterToc a, .chapterToc, .likechapterToc a, .likechapterToc, .appendixToc a, .appendixToc {line-height: 200%; font-weight:bold;}
.index-item, .index-subitem, .index-subsubitem {display:block}
.caption td.id{font-weight: bold; white-space: nowrap; }
table.caption {text-align:center;}
h1.partHead{text-align: center}
p.bibitem { text-indent: -2em; margin-left: 2em; margin-top:0.6em; margin-bottom:0.6em; }
p.bibitem-p { text-indent: 0em; margin-left: 2em; margin-top:0.6em; margin-bottom:0.6em; }
.paragraphHead, .likeparagraphHead { margin-top:2em; font-weight: bold;}
.subparagraphHead, .likesubparagraphHead { font-weight: bold;}
.quote {margin-bottom:0.25em; margin-top:0.25em; margin-left:1em; margin-right:1em; text-align:\jmathustify;}
.verse{white-space:nowrap; margin-left:2em}
div.maketitle {text-align:center;}
h2.titleHead{text-align:center;}
div.maketitle{ margin-bottom: 2em; }
div.author, div.date {text-align:center;}
div.thanks{text-align:left; margin-left:10%; font-size:85%; font-style:italic; }
div.author{white-space: nowrap;}
.quotation {margin-bottom:0.25em; margin-top:0.25em; margin-left:1em; }
h1.partHead{text-align: center}
.sectionToc, .likesectionToc {margin-left:2em;}
.subsectionToc, .likesubsectionToc {margin-left:4em;}
.subsubsectionToc, .likesubsubsectionToc {margin-left:6em;}
.frenchb-nbsp{font-size:75%;}
.frenchb-thinspace{font-size:75%;}
.figure img.graphics {margin-left:10%;}
/* end css.sty */

\title{Formes quadratiques reelles}
\author{}
\date{}

\begin{document}
\maketitle

\textbf{Warning: 
requires JavaScript to process the mathematics on this page.\\ If your
browser supports JavaScript, be sure it is enabled.}

\begin{center}\rule{3in}{0.4pt}\end{center}

{[}
{[}
{[}{]}
{[}

\subsubsection{12.4 Formes quadratiques réelles}

\paragraph{12.4.1 Formes positives, négatives}

Définition~12.4.1 Soit E un \mathbb{R}~ espace vectoriel et \Phi une forme
quadratique sur E. On dit que \Phi est positive (resp. négative) si
\forall~~x \in E, \Phi(x) ≥ 0 (resp. \leq 0).

Remarque~12.4.1 On déduit de la définition précédente que \Phi est à la
fois définie et positive si et seulement
si~\forall~x\mathrel\neq~~0, \Phi(x)
\textgreater{} 0.

Notons aussi la proposition suivante

Proposition~12.4.1 Soit E un \mathbb{R}~ espace vectoriel et \Phi une forme
quadratique définie sur E. Alors \Phi est soit positive, soit négative.

Démonstration Supposons que \Phi n'est ni positive, ni négative. Soit x \in E
tel que \Phi(x) \textless{} 0 (\Phi n'est pas positive) et y \in E tel que \Phi(y)
\textgreater{} 0 (\Phi n'est pas négative). Alors la famille (x,y) est
libre~: sinon il existerait par exemple \lambda~ \in \mathbb{R}~ tel que y = \lambda~x et on
aurait \Phi(y) = \lambda~^2\Phi(x) \leq 0. Pour t \in {[}0,1{]}, posons f(t) =
\Phi((1 - t)x + ty)~; l'identité de polarisation montre que f est un
polynôme du second degré en t et l'on a f(0) = \Phi(x) \textless{} 0, f(1)
= \Phi(y) \textgreater{} 0. Le théorème des valeurs intermédiaires assure
qu'il existe t\_0 \in {[}0,1{]} tel que f(t\_0) = 0, soit
\Phi((1 - t\_0)x + t\_0y) = 0~; mais comme la famille (x,y)
est libre, on a (1 - t\_0)x +
t\_0y\neq~0, ce qui montre que \Phi n'est
pas définie.

Remarque~12.4.2 Un raisonnement similaire montre que si E est un
\mathbb{C}-espace vectoriel ~de dimension supérieure ou égale à 2, il ne peut pas
exister de forme quadratique définie sur E.

\paragraph{12.4.2 Bases de Sylvester. Signature}

Soit E un \mathbb{R}~ espace vectoriel de dimension finie et \Phi une forme
quadratique sur E. Soit \mathcal{E} une base orthogonale de E et \Omega
= \mathrmMat~ (\Phi,\mathcal{E})
=\
\mathrmdiag(\alpha~\_1,\\ldots,\alpha~\_n~)
la matrice de \Phi dans cette base (avec donc \alpha~\_i =
\Phi(e\_i)). Quitte à permuter les vecteurs de la base, on peut
supposer que \alpha~\_1 \textgreater{}
0,\\ldots,\alpha~\_p~
\textgreater{} 0,\alpha~\_p+1 \textless{}
0,\\ldots,\alpha~\_p+q~
\textless{} 0,\alpha~\_p+q+1 =
\\ldots~ =
\alpha~\_n = 0 avec p ≥ 0,q ≥ 0,p + q \leq n.

Théorème~12.4.2 (inertie de Sylvester). Les entiers p et q sont
indépendants de la base orthogonale choisie~: l'entier p (resp. q) est
la dimension maximale des sous-espaces F de E tels que la restriction de
\Phi à F soit définie positive (resp. définie négative).

Démonstration Pour x
\in\mathrmVect(e\_1,\\\ldots,e\_p~),
on a \Phi(x) = \\sum ~
\_i=1^p\alpha~\_ix\_i^2 ≥ 0 avec égalité
si et seulement si~\forall~i, x\_i~ = 0 soit x
= 0. Ceci montre que la restriction de \Phi à
\mathrmVect(e\_1,\\\ldots,e\_p~)
est définie positive. Soit maintenant F un sous-espace de E tel que la
restriction de \Phi à F soit définie positive. Pour x
\in\mathrmVect(e\_p+1,\\\ldots,e\_n~),
on a \Phi(x) = \\sum ~
\_i=p+1^p+q\alpha~\_ix\_i^2 \leq 0. Pour x \in
F \diagdown\0\ on a \Phi(x) \textgreater{} 0. On
en déduit que F
\bigcap\mathrmVect(e\_p+1,\\\ldots,e\_n~)
= \0\ et donc ces deux sous-espaces
sont en somme directe. En conséquence, dim~ F
+ dim~
\mathrmVect(e\_p+1,\\\ldots,e\_n~)
\leq n, soit encore dim~ F + n - p \leq n, d'où
dim~ F \leq p. Donc p est la dimension maximale
des sous-espaces F de E tels que la restriction de \Phi à F soit définie
positive. Le raisonnement est similaire pour l'entier q.

Définition~12.4.2 Le couple (p,q) est appelé la signature de la forme
quadratique \Phi. On a p + q =\
\mathrmrg\Phi.

Remarque~12.4.3 \Phi est positive (resp. définie positive) si et seulement
si~elle est de signature (p,0) (resp. (n,0)).

Reprenons alors notre base orthogonale \mathcal{E} avec \alpha~\_1
\textgreater{}
0,\\ldots,\alpha~\_p~
\textgreater{} 0,\alpha~\_p+1 \textless{}
0,\\ldots,\alpha~\_p+q~
\textless{} 0,\alpha~\_p+q+1 =
\\ldots~ =
\alpha~\_n = 0. Pour i \in {[}1,p + q{]} posons \epsilon\_i = 1
\over \sqrt\textbar{}\alpha~\_i 
\textbar{} e\_i et pour i \in {[}p + q + 1,n{]}, \epsilon\_i
= e\_i. Nous obtenons alors une nouvelle base orthogonale \mathcal{E}' de
E telle que

\Phi(\epsilon\_1) =
\\ldots~ =
\Phi(\epsilon\_p) = 1,\Phi(\epsilon\_p+1) =
\\ldots~ =
\Phi(\epsilon\_p+q) = -1

\Phi(\epsilon\_p+q+1) =
\\ldots~ =
\Phi(\epsilon\_n) = 0

Définition~12.4.3 Une telle base orthogonale sera appelée une base de
Sylvester de E.

Par définition même, la matrice de \Phi dans une base de Sylvester est la
matrice \left
(\matrix\,I\_p&0 &0
\cr 0 &-I\_q&0 \cr 0 &0
&0\right ).

Remarque~12.4.4 Bien entendu, si \Phi est définie positive, une base de
Sylvester est simplement une base orthonormée.

\paragraph{12.4.3 Inégalités}

Théorème~12.4.3 (inégalité de Schwarz). Soit E un \mathbb{R}~ espace vectoriel et
\Phi une forme quadratique positive sur E de forme polaire \phi. Alors

\forall~x,y \in E, \phi(x,y)^2~ \leq \Phi(x)\Phi(y)

Si \Phi est en plus définie, alors il y a égalité si et seulement si~la
famille (x,y) est liée.

Démonstration On écrit \forall~~t \in \mathbb{R}~, \Phi(x + ty) ≥ 0,
soit encore t^2\Phi(y) + 2t\phi(x,y) + \Phi(x) ≥ 0. Ce trinome de
degré inférieur ou égal à 2 doit donc avoir un discriminant réduit
négatif, soit \phi(x,y)^2 - \Phi(x)\Phi(y) \leq 0. Supposons que \Phi est
définie~; si on a l'égalité, deux cas sont possibles. Soit y = 0 auquel
cas la famille (x,y) est liée, soit \Phi(y)\neq~0~;
mais dans ce cas ce trinome en t a une racine double t\_0, et
donc \Phi(x + t\_0y) = 0 d'où x + t\_0y = 0 et donc la
famille est liée. Inversement, si la famille (x,y) est liée, on a par
exemple x = \lambda~y et dans ce cas \phi(x,y)^2 =
\lambda~^2\Phi(y)^2 = \Phi(x)\Phi(y).

Corollaire~12.4.4 Soit E un \mathbb{R}~ espace vectoriel et \Phi une forme
quadratique positive sur E de forme polaire \phi. Alors le noyau de \Phi est
l'ensemble des vecteurs isotropes pour \Phi. En particulier, \Phi est non
dégénérée si et seulement si~elle est définie.

Démonstration Tout vecteur du noyau est bien entendu isotrope.
Inversement, si x est un vecteur isotrope et si y \in E, alors 0 \leq
\phi(x,y)^2 \leq \Phi(x)\Phi(y) = 0, soit \phi(x,y) = 0 et donc x est dans
le noyau de \phi.

Théorème~12.4.5 (inégalité de Minkowski). Soit E un \mathbb{R}~ espace vectoriel
et \Phi une forme quadratique positive sur E. Alors

\forall~x,y \in E, \sqrt\Phi(x + y)~
\leq\sqrt\Phi(x) + \sqrt\Phi(y)

Si \Phi est en plus définie, alors il y a égalité si et seulement si~la
famille (x,y) est positivement liée.

Démonstration On a

\begin{align*} \Phi(x + y)& = \Phi(x) + 2\phi(x,y) + \Phi(y) \leq
\Phi(x) + 2\textbar{}\phi(x,y)\textbar{} + \Phi(y)& \%&
\\ & \leq \Phi(x) +
2\sqrt\Phi(x)\Phi(y) + \Phi(y) = \left
(\sqrt\Phi(x) +
\sqrt\Phi(y)\right )^2& \%&
\\ \end{align*}

d'où \sqrt\Phi(x + y) \leq\sqrt\Phi(x) +
\sqrt\Phi(y). Si \Phi est définie, l'égalité nécessite à la
fois que \textbar{}\phi(x,y)\textbar{} = \sqrt\Phi(x)\Phi(y),
donc que (x,y) soit liée, et que \phi(x,y) ≥ 0, soit que le coefficient de
proportionnalité soit positif.

\paragraph{12.4.4 Espaces préhilbertiens réels}

Définition~12.4.4 On appelle espace préhilbertien réel un couple (E,\Phi)
d'un \mathbb{R}~-espace vectoriel ~E et d'une forme quadratique définie positive
sur E.

Théorème~12.4.6 Soit (E,\Phi) un espace préhilbertien réel. Alors
l'application x\mapsto~\sqrt\Phi(x)
est une norme sur E appelée norme euclidienne.

Démonstration La propriété de séparation provient du fait que \Phi est
définie. L'homogénéité provient de l'homogénéité de la forme
quadratique. Quant à l'inégalité triangulaire, ce n'est autre que
l'inégalité de Minkowski.

Définition~12.4.5 On notera (x∣y) = \phi(x,y) et
\\textbar{}x\\textbar{}^2 =
(x∣x) = \Phi(x)

Théorème~12.4.7 Soit E un espace préhilbertien réel et F un sous-espace
vectoriel de dimension finie de E. Alors l'orthogonal F^\bot de
F dans E est un supplémentaire de F, appelé le supplémentaire orthogonal
de F. La pro\jmathection sur F parallèlement à F^\bot est appelée la
pro\jmathection orthogonale sur F. On a
codimF^\bot~ =\
dim F et F^\bot\bot = F.

Démonstration Tout d'abord, si x \in F \bigcap F^\bot, on a x \bot x et
donc (x∣x) = 0 ce qui implique x = 0~; on a
donc F \bigcap F^\bot = \0\. Soit
maintenant x \in E et soit f : F \rightarrow~ \mathbb{R}~ définie par f(y) =
(x∣y). Clairement, f est une forme linéaire
sur l'espace F~; comme F est un espace vectoriel de dimension finie muni
d'une forme bilinéaire symétrique non dégénérée, il existe x\_1
\in F tel que \forall~~y \in F, f(y) =
(x\_1∣y). On a donc
\forall~y \in F, (x\mathrel∣~y) =
(x\_1∣y) et donc
\forall~~y \in F, (x -
x\_1∣y) = 0. On en déduit que x -
x\_1 \in F^\bot. Comme x = x\_1 + (x -
x\_1), on a bien E = F + F^\bot. On en déduit que E = F
\oplus~ F^\bot, et donc que
codimF^\bot~ =\
dim F.

On a clairement F \subset~ F^\bot\bot. Inversement, soit x \in
F^\bot\bot et écrivons x = x\_1 + x\_2 avec
x\_1 \in F et x\_2 \in F^\bot~; comme x\_2 \in
F^\bot et x \in F^\bot\bot, on a
(x\_2∣x) = 0 soit encore
(x\_2∣x\_1) +
(x\_2∣x\_2) = 0, soit encore,
compte tenu de (x\_2∣x\_1) =
0, (x\_2∣x\_2) = 0 et donc
x\_2 = 0~; ceci nous montre que x \in F, soit encore
F^\bot\bot\subset~ F et donc F^\bot\bot = F.

Théorème~12.4.8 Soit E un espace préhilbertien réel et F un sous-espace
vectoriel de dimension finie de E. Soit x \in E. Il existe un unique v \in F
tel que d(x,F) =\\textbar{} x -
v\\textbar{}~; v est la pro\jmathection orthogonale de x sur
F.

Démonstration Ecrivons x = v + w avec v \in F et y \in F^\bot, et
donc v = p\_F(x). Pour y \in F, on a, en tenant compte de v - y \in
F et w \in F^\bot qui impliquent que v - y \bot w,

\begin{align*} \\textbar{}x -
y\\textbar{}^2& =&
\\textbar{}(v - y) +
w\\textbar{}^2 =\\textbar{} v -
y\\textbar{}^2 +\\textbar{}
w\\textbar{}^2\%&
\\ & =& \\textbar{}v -
y\\textbar{}^2 +\\textbar{} x -
v\\textbar{}^2 ≥\\textbar{} x -
v\\textbar{}^2 \%&
\\ \end{align*}

avec égalité si et seulement si~y = v, ce qui démontre la première
partie du résultat.

Proposition~12.4.9 Si
(v\_1,\\ldots,v\_p~)
est une base de F, on a

d(x,F)^2 =
\mathrm{det}~
Gram(v\_1,\\\ldots,v\_p~,x)
\over
\mathrm{det}~
Gram(v\_1,\\\ldots,v\_p)~

Démonstration Si x \in F, la formule est évidente puisque les deux membres
de la formule sont nuls (la famille
(v\_1,\\ldots,v\_p~,x)
étant liée, son déterminant de Gram est nul). On a

\begin{align*}
\mathrm{det}~
Gram(v\_1,\\\ldots,v\_p~,x)&&
\%& \\ & =& \left
\textbar{}\matrix\,Gram(v\_1,\\\ldots,v\_p)&\matrix\,(v\_1\mathrel∣~x)
\cr \⋮~
\cr (v\_p∣x)
\cr
\matrix\,(v\_1∣x)&\\ldots&(v\_p\mathrel∣x)~
&\\textbar{}x\\textbar{}^2
\right \textbar{} \%& \\
& =& \left
\textbar{}\matrix\,Gram(v\_1,\\\ldots,v\_p)&\matrix\,(v\_1\mathrel∣~v)
\cr \⋮~
\cr (v\_p∣v)
\cr
\matrix\,(v\_1∣v)&\\ldots&(v\_p\mathrel∣v)~
&\\textbar{}v\\textbar{}^2
+\\textbar{}
w\\textbar{}^2\right
\textbar{} \%& \\ & =&
\left
\textbar{}\matrix\,Gram(v\_1,\\\ldots,v\_p)&\matrix\,(v\_1\mathrel∣~v)
\cr \⋮~
\cr (v\_p∣v)
\cr
\matrix\,(v\_1∣v)&\\ldots&(v\_p\mathrel∣v)~
&\\textbar{}v\\textbar{}^2
\right \textbar{} + \left
\textbar{}\matrix\,Gram(v\_1,\\\ldots,v\_p~)&\matrix\,0
\cr \⋮~
\cr 0 \cr
\matrix\,(v\_1∣v)&\\ldots&(v\_p\mathrel∣v)~
&\\textbar{}w\\textbar{}^2\right
\textbar{} \%& \\ & =&
\mathrm{det}~
Gram(v\_1,\\\ldots,v\_p~,v)
+\\textbar{}
w\\textbar{}^2\
\mathrm{det} Gram(v~\_
1,\\ldots,v\_p~)\%&
\\ & =&
\\textbar{}w\\textbar{}^2\
\mathrm{det} Gram(v~\_
1,\\ldots,v\_p~)
\%& \\ & =&
\mathrm{det}~
Gram(v\_1,\\\ldots,v\_p)d(x,F)^2~
\%& \\ \end{align*}

en remarquant que (v\_i∣x) =
(v\_i∣v),
\\textbar{}x\\textbar{}^2
=\\textbar{} v\\textbar{}^2
+\\textbar{} w\\textbar{}^2,
que v est une combinaison linéaire de
(v\_1,\\ldots,v\_p~)
ce qui implique que
\mathrm{det}~
Gram(v\_1,\\\ldots,v\_p~,v)
= 0 et en utilisant la linéarité du déterminant par rapport à sa
dernière colonne. Ceci démontre que

d(x,F)^2 =
\mathrm{det}~
Gram(v\_1,\\\ldots,v\_p~,x)
\over
\mathrm{det}~
Gram(v\_1,\\\ldots,v\_p)~

Remarque~12.4.5 En dimension 3, en tenant compte de divers résultats qui
expriment le déterminant de Gram en fonction du produit mixte ou de la
norme du produit vectoriel, on obtient les formules

d(x, \mathbb{R}~u) = \\textbar{}x ∧ u\\textbar{}
\over
\\textbar{}u\\textbar{}

et

d(x,\mathrmVect~(u,v)) =
\big \textbar{} {[}u,v,x{]} \big
\textbar{} \over \\textbar{}u ∧
v\\textbar{}

\paragraph{12.4.5 Espaces euclidiens}

Définition~12.4.6 On appelle espace euclidien un espace préhilbertien
réel de dimension finie.

Récapitulons les principales propriétés des espaces euclidiens qui
découlent presque immédiatement de tout ce que nous avons dé\jmathà vu
précédemment

Théorème~12.4.10 Soit E un espace euclidien.

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) pour toute forme linéaire f sur E, il existe un unique vecteur
  v\_f \in E tel que \forall~~x \in E, f(x) =
  (x∣v\_f)
\item
  (ii) pour tout sous-espace vectoriel A de E, on a E = A \oplus~
  A^\bot et (A^\bot)^\bot = A
\end{itemize}

Démonstration (i) est une propriété générale des formes non dégénérées~;
(ii) est une propriété générale des formes définies.

\paragraph{12.4.6 Algorithme de Gram-Schmidt}

Théorème~12.4.11 (Algorithme de Gram-Schmidt). Soit E un espace
euclidien. Soit \mathcal{E} =
(e\_1,\\ldots,e\_n~)
une base de E. Alors il existe une base orthogonale \mathcal{E}' =
(\epsilon\_1,\\ldots,\epsilon\_n~)
de E vérifiant les conditions équivalentes suivantes

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) \forall~k \in {[}1,n{]}, \epsilon\_k~
  \in\mathrmVect(e\_1,\\\ldots,e\_k~)
\item
  (ii) \forall~~k \in {[}1,n{]},
  \mathrmVect(\epsilon\_1,\\\ldots,\epsilon\_k~)
  =\
  \mathrmVect(e\_1,\\ldots,e\_k~)
\item
  (iii) la matrice de passage de \mathcal{E} à \mathcal{E}' est triangulaire supérieure
\end{itemize}

Si \mathcal{E}' =
(\epsilon\_1,\\ldots,\epsilon\_n~)
et \mathcal{E}'' =
(\eta\_1,\\ldots,\eta\_n~)
sont deux telles bases orthogonales, il existe des scalaires
\lambda~\_1,\\ldots,\lambda~\_n~
non nuls tels que \forall~i \in {[}1,n{]}, \eta\_i~
= \lambda~\_i\epsilon\_i.

Démonstration Démontrons tout d'abord l'équivalence des trois
propriétés. Il est clair que (i) \Leftrightarrow (iii) et
que (ii) \rigtharrow~(i). De plus, si (i) est vérifié, on a
\forall~i \in {[}1,k{]}, \epsilon\_i~
\in\mathrmVect(e\_1,\\\ldots,e\_i~)
\subset~\mathrmVect(e\_1,\\\ldots,e\_k~)
et donc
\mathrmVect(\epsilon\_1,\\\ldots,\epsilon\_k~)
\subset~\mathrmVect(e\_1,\\\ldots,e\_k~).
Comme les deux sous-espaces ont même dimension, ils sont égaux et donc
(i) \rigtharrow~(ii). Nous allons maintenant démontrer l'existence et l'unicité à
multiplication par des scalaires non nuls près. Posons V \_0 =
\0\, V \_k
=\
\mathrmVect(e\_1,\\ldots,e\_k~)
et remarquons que le fait que la base soit orthogonale se traduit par le
fait que \epsilon\_k est orthogonal à
\mathrmVect(\epsilon\_1,\\\ldots,\epsilon\_k-1~),
soit encore d'après (ii) à
\mathrmVect(e\_1,\\\ldots,e\_k-1~)
= V \_k-1. On voit donc que l'on doit choisir \epsilon\_k \in V
\_k \bigcap V \_k-1^\bot. Mais ce sous-espace n'est autre
que l'orthogonal dans V \_k du sous espace V \_k-1~; cet
orthogonal est de dimension k - (k - 1) = 1~; ceci démontre dé\jmathà que si
\epsilon\_k et \eta\_k conviennent, alors ils sont proportionnels,
d'où la partie unicité de la proposition. Pour l'existence, choisissons
pour chaque k un vecteur non nul \epsilon\_k \in V \_k \bigcap V
\_k-1^\bot. On a alors, puisque V \_k-1 est non
isotrope, V \_k = V \_k-1 \oplus~ K\epsilon\_k~; une
récurrence évidente montre alors que V \_k
=\
\mathrmVect(\epsilon\_1,\\ldots,\epsilon\_k~).
Donc
(\epsilon\_1,\\ldots,\epsilon\_n~)
est une base de E (famille génératrice de cardinal n), évidemment
orthogonale et qui vérifie les conditions voulues.

Remarque~12.4.6 Comme on l'a vu ci-dessus, la base orthogonale n'est pas
unique~; il y a divers moyens de la normaliser. L'un des plus simples
est de demander que \epsilon\_k ait une coordonnée égale à 1 suivant
e\_k (cette coordonnée est bien évidemment non nulle car V
\_k = V \_k-1 \oplus~ Ke\_k et il est exclu que
\epsilon\_k appartienne à V \_k-1)~; dans ce cas la base est
évidemment unique. Une autre normalisation possible est de demander que
la nouvelle base soit orthonormée et que les produits scalaires
(e\_i∣\epsilon\_i) soient tous
positifs.

Nous allons maintenant étudier un algorithme de construction de la base
\mathcal{E}' dans le cadre de cette normalisation. Il se fonde sur la remarque
suivante~: pour chaque k, on doit avoir \epsilon\_k = e\_k +
v\_k avec v\_k \in V \_k-1
=\
\mathrmVect(e\_1,\\ldots,e\_k-1~)
=\
\mathrmVect(\epsilon\_1,\\ldots,\epsilon\_k-1~)~;
ceci impose que,
\epsilon\_1,\\ldots,\epsilon\_k-1~
étant supposés dé\jmathà déterminés, \epsilon\_k = e\_k
+ \\sum ~
\_i=1^k-1\alpha~\_i\epsilon\_i, les \alpha~\_i étant
déterminés par la condition que \epsilon\_k doit être orthogonal à
\epsilon\_1,\\ldots,\epsilon\_k-1~~;
or , pour \jmath \in {[}1,k - 1{]},

(\epsilon\_k∣\epsilon\_\jmath) =
(e\_k∣\epsilon\_\jmath) +
\sum \_i=1^k-1\alpha~~\_
i(\epsilon\_i∣\epsilon\_\jmath) =
(e\_k∣\epsilon\_\jmath) +
\alpha~\_\jmath\\textbar{}\epsilon\_\jmath\\textbar{}^2

puisque (\epsilon\_i∣\epsilon\_\jmath) = 0 si
i\neq~\jmath. On doit donc poser \alpha~\_\jmath = -
(e\_k∣\epsilon\_\jmath)
\over
\\textbar{}\epsilon\_\jmath\\textbar{}^2
.

On obtient donc l'algorithme suivant (pour la première normalisation, où
l'on demande que \epsilon\_k ait une coordonnée égale à 1 suivant
e\_k)

Algorithme de Gram-Schmidt

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \epsilon\_1 = e\_1
\item
  pour k de 2 à n faire
\item
  \quad \quad \epsilon\_k = e\_k
  -\\sum ~
  \_i=1^k-1
  (e\_k∣\epsilon\_i)
  \over
  (\epsilon\_i∣\epsilon\_i) \epsilon\_i
\end{itemize}

Pour la deuxième normalisation, qui demande que la base soit
orthonormée, on a Algorithme de Gram-Schmidt

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \epsilon\_1 = e\_1\over
  \\textbar{}e\_1\\textbar{}
\item
  pour k de 2 à n faire
\item
  \quad \quad \epsilon'\_k = e\_k
  -\\sum ~
  \_i=1^k-1(e\_k∣\epsilon\_i)\epsilon\_i
\item
  \quad \quad \epsilon\_k =
  \epsilon\_k'\over
  \\textbar{}\epsilon\_k'\\textbar{}
\end{itemize}

\paragraph{12.4.7 Application~: polynômes orthogonaux}

Soit -\infty~\leq a \textless{} b \leq +\infty~ et \omega :{]}a,b{[}\rightarrow~ \mathbb{R}~ une application
continue positive non nulle telle que pour tout polynôme P \in \mathbb{R}~{[}X{]} la
fonction P\omega soit intégrable sur {]}a,b{[}.

Théorème~12.4.12 La forme bilinéaire (P∣Q)
=\int  \_{]}a,b{[}~P(t)Q(t)\omega(t) dt est
définie positive sur \mathbb{R}~{[}X{]}.

Démonstration On a (P∣P)
=\int  \_{]}a,b{[}P(t)^2~\omega(t)
dt ≥ 0. De plus, si (P∣P) = 0, comme
P(t)^2\omega(t) est continue positive, on a
\forall~t \in{]}a,b{[}, P(t)^2~\omega(t) = 0. Mais
comme \omega est non nulle, il existe un intervalle {]}c,d{[} sur lequel \omega ne
s'annule pas. On a donc \forall~~t \in{]}c,d{[}, P(t) =
0 et le polynôme P ayant une infinité de racines est le polynôme nul.

Nous pouvons donc appliquer l'algorithme de Gram-Schmidt à la base
(X^n)\_n\in\mathbb{N}~ de \mathbb{R}~{[}X{]} et on obtient donc

Théorème~12.4.13 Il existe une unique famille
(P\_n)\_n\in\mathbb{N}~ de \mathbb{R}~{[}X{]} vérifiant les conditions
suivantes

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) pour tout n, P\_n est un polynôme normalisé de degré n
\item
  (ii) \forall~~i,\jmath \in \mathbb{N}~,
  i\neq~\jmath \rigtharrow~
  (P\_i∣P\_\jmath) = 0
\end{itemize}

Définition~12.4.7 Les polynômes P\_n sont appelés les polynômes
orthogonaux relativement au poids \omega.

Remarque~12.4.7 Pour chaque n \in \mathbb{N}~,
(P\_0,\\ldots,P\_n~)
est une base de l'espace vectoriel \mathbb{R}~\_n{[}X{]} des polynômes de
degré inférieur ou égal à n, puisque c'est une famille libre (échelonnée
en degrés) de cardinal n + 1. On a bien entendu P\_n+1 \bot
\mathbb{R}~\_n{[}X{]}.

Théorème~12.4.14 Le polynôme P\_n a toutes ses racines réelles
distinctes situées dans l'intervalle {]}a,b{[}.

Démonstration Soit
\alpha~\_1,\\ldots,\alpha~\_k~
les racines de P de multiplicités impaires situées dans l'intervalle
{]}a,b{[} (avec k ≥ 0). Soit Q(X) =\
∏  \_i=1^k(X - \alpha~\_i~).
Supposons que k \leq n - 1~; alors Q \in \mathbb{R}~\_n-1{[}X{]} et donc
(Q∣P\_n) = 0, soit
\int  \_{]}a,b{[}~P(t)Q(t)\omega(t) dt = 0.
Mais le polynôme PQ n'a que des racines de multiplicités paires sur
{]}a,b{[}, il est donc de signe constant et donc PQ\omega également. On en
déduit que PQ\omega = 0 sur {]}a,b{[}, puis comme précédemment que PQ = 0, ce
qui est absurde. Donc k = n, ce qui exige que les \alpha~\_i soient de
multiplicités 1 et que P(X) =\
∏  \_i=1^n(X - \alpha~\_i~).

Application à l'intégration.

Théorème~12.4.15 Les racines de P\_n sont les seuls réels
\alpha~\_1,\\ldots,\alpha~\_n~
tels qu'il existe des scalaires
\lambda~\_1,\\ldots,\lambda~\_n~
vérifiant

\forall~P \in \mathbb{R}~\_2n-1~{[}X{]},
\int  \_{]}a,b{[}~P(t)\omega(t) dt =
\sum \_i=1^n\lambda~~\_
iP(\alpha~\_i)

Démonstration Soit
\alpha~\_1,\\ldots,\alpha~\_n~
les racines de P\_n et \epsilon\_i la forme linéaire sur
\mathbb{R}~\_n-1{[}X{]}, P\mapsto~P(\alpha~\_i)~; si
\forall~i, \epsilon\_i~(P) = 0, P est un polynôme de
degré au plus n - 1 qui admet n racines distinctes, il est donc nul.
Donc
P\mapsto~(\epsilon\_1(P),\\ldots,\epsilon\_n~(P))
est in\jmathective, donc bi\jmathective, ce qui implique
\mathrmVect(\epsilon\_1,\\\ldots,\epsilon\_n~)
= \mathbb{R}~\_n-1{[}X{]}^∗. Comme f :
P\mapsto~\int ~
\_{]}a,b{[}P(t)\omega(t) dt est une forme linéaire sur
\mathbb{R}~\_n-1{[}X{]}, elle est combinaison linéaire de
\epsilon\_1,\\ldots,\epsilon\_n~,
soit f = \lambda~\_1\epsilon\_1 +
\\ldots~ +
\lambda~\_n\epsilon\_n. On a alors

\forall~P \in \mathbb{R}~\_n-1~{[}X{]},
\int  \_{]}a,b{[}~P(t)\omega(t) dt =
\sum \_i=1^n\lambda~~\_
iP(\alpha~\_i)

Soit maintenant P \in \mathbb{R}~\_2n-1{[}X{]}. on peut écrire P =
QP\_n + R avec Q,R \in \mathbb{R}~\_n-1{[}X{]}. On a bien entendu
P(\alpha~\_i) = R(\alpha~\_i) et

\begin{align*} \int ~
\_{]}a,b{[}P(t)\omega(t) dt& =&
(Q∣P\_n) +\\int
 \_{]}a,b{[}R(t)\omega(t) dt =\int ~
\_{]}a,b{[}R(t)\omega(t) dt\%& \\ & =&
\sum \_i=1^n\lambda~~\_
iR(\alpha~\_i) = \\sum
\_i=1^n\lambda~\_ iP(\alpha~\_i) \%&
\\ \end{align*}

ce qui montre que
\alpha~\_1,\\ldots,\alpha~\_n~
vérifient les conditions voulues. Inversement, supposons que
\alpha~\_1,\\ldots,\alpha~\_n~
sont n nombres réels vérifiant les conditions voulues et Q(X)
= \∏ ~
\_i=1^n(X - \alpha~\_i). Alors, pour tout P \in
\mathbb{R}~\_n-1{[}X{]}, on a PQ \in \mathbb{R}~\_2n-1{[}X{]} soit

(P∣Q) =\int ~
\_{]}a,b{[}P(t)Q(t)\omega(t) dt = \\sum
\_i=1^n\lambda~\_ iP(\alpha~\_i)Q(\alpha~\_i) = 0

et donc Q \bot R\_n-1{[}X{]}. Comme Q est normalisé, on a Q =
P\_n.

Théorème~12.4.16 Il existe des scalaires a\_n,b\_n tels
que

\forall~n \in \mathbb{N}~^∗, P\_ n+1~ = (X +
a\_n)P\_n + b\_nP\_n-1

Démonstration Soit Q = XP\_n \in \mathbb{R}~\_n+1{[}X{]}~; on a donc
XP\_n = \\sum ~
\_i=0^n+1\lambda~\_iP\_i(X). En considérant le
terme de degré n + 1, les polynômes P\_n+1 et XP\_n
étant normalisés, on a \lambda~\_n+1 = 1. Pour n ≥ 2 et i \leq n - 2, on a

\begin{align*}
\lambda~\_i\\textbar{}P\_i\\textbar{}^2&
=& (Q∣P\_ i)
=\int  \_{]}a,b{[}P\_i~(t)Q(t)\omega(t)
dt =\int ~
\_{]}a,b{[}P\_i(t)tP\_n(t) dt\%&
\\ & =&
(P\_n∣XP\_i) \%&
\\ \end{align*}

Mais puisque i \leq n - 2, XP\_i \in \mathbb{R}~\_n-1{[}X{]} et donc
XP\_i \bot P\_n, soit \lambda~\_i = 0. On a donc

XP\_n = P\_n+1 + \lambda~\_nP\_n +
\lambda~\_n-1P\_n-1

ce qui donne la formule demandée.

Pour certains poids \omega particuliers, les polynômes orthogonaux vérifient
des équations différentielles linéaires d'ordre 2 que nous n'étudierons
pas de manière générale. Citons quelques cas particulièrement importants
de polynômes orthogonaux

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) a = -1,b = 1,\omega(t) = 1~: polynômes de Legendre L\_n(t) =
  \lambda~\_n d^n \over dt^n
  (t^2 - 1)^n
\item
  (ii) a = -\infty~,b = +\infty~,\omega(t) = e^-t^2 ~: polynômes
  d'Hermite H\_n(t)e^-t^2  =
  \lambda~\_n d^n \over dt^n
  e^-t^2 
\item
  (iii) a = -1,b = 1,\omega(t) = 1 \over
  \sqrt1-t^2 ~: polynômes de Tchebychev
  T\_n(cos~ x) =
  \lambda~\_n cos~ (nx)
\end{itemize}

{[}
{[}
{[}
{[}

\end{document}

\documentclass[]{article}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={Endomorphismes d'un espace euclidien},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}
 
/* start css.sty */
.cmr-5{font-size:50%;}
.cmr-7{font-size:70%;}
.cmmi-5{font-size:50%;font-style: italic;}
.cmmi-7{font-size:70%;font-style: italic;}
.cmmi-10{font-style: italic;}
.cmsy-5{font-size:50%;}
.cmsy-7{font-size:70%;}
.cmex-7{font-size:70%;}
.cmex-7x-x-71{font-size:49%;}
.msbm-7{font-size:70%;}
.cmtt-10{font-family: monospace;}
.cmti-10{ font-style: italic;}
.cmbx-10{ font-weight: bold;}
.cmr-17x-x-120{font-size:204%;}
.cmsl-10{font-style: oblique;}
.cmti-7x-x-71{font-size:49%; font-style: italic;}
.cmbxti-10{ font-weight: bold; font-style: italic;}
p.noindent { text-indent: 0em }
td p.noindent { text-indent: 0em; margin-top:0em; }
p.nopar { text-indent: 0em; }
p.indent{ text-indent: 1.5em }
@media print {div.crosslinks {visibility:hidden;}}
a img { border-top: 0; border-left: 0; border-right: 0; }
center { margin-top:1em; margin-bottom:1em; }
td center { margin-top:0em; margin-bottom:0em; }
.Canvas { position:relative; }
li p.indent { text-indent: 0em }
.enumerate1 {list-style-type:decimal;}
.enumerate2 {list-style-type:lower-alpha;}
.enumerate3 {list-style-type:lower-roman;}
.enumerate4 {list-style-type:upper-alpha;}
div.newtheorem { margin-bottom: 2em; margin-top: 2em;}
.obeylines-h,.obeylines-v {white-space: nowrap; }
div.obeylines-v p { margin-top:0; margin-bottom:0; }
.overline{ text-decoration:overline; }
.overline img{ border-top: 1px solid black; }
td.displaylines {text-align:center; white-space:nowrap;}
.centerline {text-align:center;}
.rightline {text-align:right;}
div.verbatim {font-family: monospace; white-space: nowrap; text-align:left; clear:both; }
.fbox {padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
div.fbox {display:table}
div.center div.fbox {text-align:center; clear:both; padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
div.minipage{width:100%;}
div.center, div.center div.center {text-align: center; margin-left:1em; margin-right:1em;}
div.center div {text-align: left;}
div.flushright, div.flushright div.flushright {text-align: right;}
div.flushright div {text-align: left;}
div.flushleft {text-align: left;}
.underline{ text-decoration:underline; }
.underline img{ border-bottom: 1px solid black; margin-bottom:1pt; }
.framebox-c, .framebox-l, .framebox-r { padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
.framebox-c {text-align:center;}
.framebox-l {text-align:left;}
.framebox-r {text-align:right;}
span.thank-mark{ vertical-align: super }
span.footnote-mark sup.textsuperscript, span.footnote-mark a sup.textsuperscript{ font-size:80%; }
div.tabular, div.center div.tabular {text-align: center; margin-top:0.5em; margin-bottom:0.5em; }
table.tabular td p{margin-top:0em;}
table.tabular {margin-left: auto; margin-right: auto;}
div.td00{ margin-left:0pt; margin-right:0pt; }
div.td01{ margin-left:0pt; margin-right:5pt; }
div.td10{ margin-left:5pt; margin-right:0pt; }
div.td11{ margin-left:5pt; margin-right:5pt; }
table[rules] {border-left:solid black 0.4pt; border-right:solid black 0.4pt; }
td.td00{ padding-left:0pt; padding-right:0pt; }
td.td01{ padding-left:0pt; padding-right:5pt; }
td.td10{ padding-left:5pt; padding-right:0pt; }
td.td11{ padding-left:5pt; padding-right:5pt; }
table[rules] {border-left:solid black 0.4pt; border-right:solid black 0.4pt; }
.hline hr, .cline hr{ height : 1px; margin:0px; }
.tabbing-right {text-align:right;}
span.TEX {letter-spacing: -0.125em; }
span.TEX span.E{ position:relative;top:0.5ex;left:-0.0417em;}
a span.TEX span.E {text-decoration: none; }
span.LATEX span.A{ position:relative; top:-0.5ex; left:-0.4em; font-size:85%;}
span.LATEX span.TEX{ position:relative; left: -0.4em; }
div.float img, div.float .caption {text-align:center;}
div.figure img, div.figure .caption {text-align:center;}
.marginpar {width:20%; float:right; text-align:left; margin-left:auto; margin-top:0.5em; font-size:85%; text-decoration:underline;}
.marginpar p{margin-top:0.4em; margin-bottom:0.4em;}
.equation td{text-align:center; vertical-align:middle; }
td.eq-no{ width:5%; }
table.equation { width:100%; } 
div.math-display, div.par-math-display{text-align:center;}
math .texttt { font-family: monospace; }
math .textit { font-style: italic; }
math .textsl { font-style: oblique; }
math .textsf { font-family: sans-serif; }
math .textbf { font-weight: bold; }
.partToc a, .partToc, .likepartToc a, .likepartToc {line-height: 200%; font-weight:bold; font-size:110%;}
.chapterToc a, .chapterToc, .likechapterToc a, .likechapterToc, .appendixToc a, .appendixToc {line-height: 200%; font-weight:bold;}
.index-item, .index-subitem, .index-subsubitem {display:block}
.caption td.id{font-weight: bold; white-space: nowrap; }
table.caption {text-align:center;}
h1.partHead{text-align: center}
p.bibitem { text-indent: -2em; margin-left: 2em; margin-top:0.6em; margin-bottom:0.6em; }
p.bibitem-p { text-indent: 0em; margin-left: 2em; margin-top:0.6em; margin-bottom:0.6em; }
.paragraphHead, .likeparagraphHead { margin-top:2em; font-weight: bold;}
.subparagraphHead, .likesubparagraphHead { font-weight: bold;}
.quote {margin-bottom:0.25em; margin-top:0.25em; margin-left:1em; margin-right:1em; text-align:\jmathustify;}
.verse{white-space:nowrap; margin-left:2em}
div.maketitle {text-align:center;}
h2.titleHead{text-align:center;}
div.maketitle{ margin-bottom: 2em; }
div.author, div.date {text-align:center;}
div.thanks{text-align:left; margin-left:10%; font-size:85%; font-style:italic; }
div.author{white-space: nowrap;}
.quotation {margin-bottom:0.25em; margin-top:0.25em; margin-left:1em; }
h1.partHead{text-align: center}
.sectionToc, .likesectionToc {margin-left:2em;}
.subsectionToc, .likesubsectionToc {margin-left:4em;}
.subsubsectionToc, .likesubsubsectionToc {margin-left:6em;}
.frenchb-nbsp{font-size:75%;}
.frenchb-thinspace{font-size:75%;}
.figure img.graphics {margin-left:10%;}
/* end css.sty */

\title{Endomorphismes d'un espace euclidien}
\author{}
\date{}

\begin{document}
\maketitle

\textbf{Warning: 
requires JavaScript to process the mathematics on this page.\\ If your
browser supports JavaScript, be sure it is enabled.}

\begin{center}\rule{3in}{0.4pt}\end{center}

{[}
{[}
{[}{]}
{[}

\subsubsection{12.6 Endomorphismes d'un espace euclidien}

\paragraph{12.6.1 Droites et plans stables}

Nous utiliserons à deux reprises le lemme suivant

Lemme~12.6.1 Soit E un \mathbb{R}~-espace vectoriel ~de dimension finie et u \in
L(E). Alors u admet soit une droite stable, soit un plan stable.

Démonstration Soit P un polynôme normalisé annulateur de u et soit P =
P\_1\\ldotsP\_n~
la décomposition de P en polynômes normalisés irréductibles sur \mathbb{R}~. On a
0 = P(u) = P\_1(u) \cdot⋯ \cdot
P\_n(u). Donc l'un des P\_i(u) est non in\jmathectif. Soit x
\in\mathrmKerP\_i~(u)
\diagdown\0\. Deux cas sont possibles~:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  P\_1 est de degré 1, soit P\_1(X) = X - \lambda~, alors (u -
  \lambda~\mathrmId)(x) = 0, x est vecteur propre de u et la
  droite \mathbb{R}~x est stable par u~;
\item
  P\_1 est de degré 2, alors P\_1(X) = X^2 -
  aX - b et on a donc u^2(x) = au(x) + bx~; le sous-espace
  \mathrmVect~(x,u(x)) est
  de dimension au plus 2 (en fait il est facile de vérifier qu'elle est
  égale à 2) et il est stable par u.
\end{itemize}

\paragraph{12.6.2 Réduction des endomorphismes symétriques}

Théorème~12.6.2 Soit E un espace euclidien et u un endomorphisme de E.
Alors on a équivalence de

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) u est un endomorphisme symétrique
\item
  (ii) il existe une base orthonormée formée de vecteurs propres de u
\item
  (iii) il existe une base orthonormée \mathcal{E} telle que
  \mathrmMat~ (u,\mathcal{E}) soit
  diagonale.
\end{itemize}

Démonstration (ii) et (iii) sont clairement équivalents. Si (iii) est
vérifiée, la matrice de u dans la base orthonormée \mathcal{E} est symétrique et
donc u est un endomorphisme symétrique. Il nous reste donc à montrer que
(i) \rigtharrow~(ii), ce que nous allons faire par récurrence sur n
= dim~ E. Montrons pour cela que u a un vecteur
propre. D'après le lemme ci dessus, u admet soit une droite, soit un
plan stable. Si u admet une droite stable, cette droite est engendrée
par un vecteur propre. Si u a un plan stable \Pi, soit u' l'endomorphisme
induit par u sur \Pi (c'est bien entendu un endomorphisme symétrique de
\Pi), \mathcal{E} = (e\_1,e\_2) une base orthonormée de \Pi et
\mathrmMat~ (u',\mathcal{E}) =
\left
(\matrix\,a&b\cr b
&c\right )~; alors \chi\_u(X) = (X - a)(X - c) -
b^2 = X^2 - (a + b)X + ac - b^2 de
discriminant \Delta = (a + c)^2 - 4(ac - b^2) = (a -
c)^2 + 4b^2 ≥ 0~; donc u' a un vecteur propre dans \Pi
qui est également un vecteur propre de u dans E. Supposons donc que tout
endomorphisme symétrique d'un espace de dimension n - 1 admet une base
orthonormée de vecteurs propres. Soit e\_1 un vecteur propre de
u (endomorphisme symétrique d'un espace euclidien de dimension n).
Quitte à remplacer e\_1 par  e\_1 \over
\\textbar{}e\_1\\textbar{} , on
peut supposer que
\\textbar{}e\_1\\textbar{} = 1.
Soit H = e\_1^\bot. Comme Ke\_1 est stable par u,
son orthogonal H est stable par u^∗ = u. La restriction u' de
u à H est un endomorphisme symétrique de H de dimension n - 1, donc
admet une base orthonormée
(e\_2,\\ldots,e\_n~)
formée de vecteurs propres de u' (donc de u)~; alors
(e\_1,\\ldots,e\_n~)
est une base orthonormée de E formée de vecteurs propres de u.

Corollaire~12.6.3 Soit E un espace euclidien et u un endomorphisme
symétrique de E~; alors E est somme directe orthogonale des sous-espaces
propres de u.

Démonstration Puisque u est diagonalisable, E est somme directe des
sous-espaces propres de u. Il suffit de montrer que ces sous-espaces
sont deux à deux orthogonaux. Mais, si x \in E\_u(\lambda~) et y \in
E\_u(\mu) avec \lambda~\neq~\mu, on a

\lambda~(x∣y) = (u(x)\mathrel∣y)
= (x∣u(y)) =
(x∣\muy) = \mu(x\mathrel∣y)

Comme \lambda~\neq~\mu, on a
(x∣y) = 0.

Remarque~12.6.1 Ceci permet une pratique simple de la réduction d'un
endomorphisme symétrique~; il suffit en effet de déterminer une base
orthonormée de chacun des sous-espaces propres de u et de réunir ces
bases~; on obtient une base orthonormée de E formée de vecteurs propres
de u.

Définition~12.6.1 Soit E un espace euclidien et u un endomorphisme
symétrique de E. On dit que u est un endomorphisme positif (resp. défini
positif) s'il vérifie les conditions équivalentes~:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) \forall~~x \in
  E,(u(x)∣x) ≥ 0 (resp.
  \forall~x\neq~0,(u(x)\mathrel∣~x)
  \textgreater{} 0)
\item
  (ii) L'application
  x\mapsto~(u(x)\mathrel∣x) est
  une forme quadratique positive sur E (resp. définie positive)
\item
  (iii) Les valeurs propres de u sont positives (resp. strictement
  positives).
\end{itemize}

Démonstration En remarquant que l'application Q\_u :
x\mapsto~(u(x)\mathrel∣x) est une
forme quadratique de forme polaire
(x,y)\mapsto~(u(x)\mathrel∣y), on
a immédiatement l'équivalence de (i) et (ii). Soit \lambda~ une valeur propre
de u et x un vecteur propre associé~; on a alors
(u(x)∣x) = (\lambda~x\mathrel∣x)
= \lambda~\\textbar{}x\\textbar{}^2,
si bien que \lambda~ = (u(x)∣x)
\over
\\textbar{}x\\textbar{}^2 ~;
il en résulte que (i) \rigtharrow~(iii). Inversement, supposons (iii) vérifiée et
soit
(e\_1,\\ldots,e\_n~)
une base orthonormée formée de vecteurs propres de u, u(e\_i) =
\lambda~\_ie\_i. On a alors, si x =\
\sum  \_ix\_ie\_i~,

(u(x)∣x) = (\\sum
\_i\lambda~\_ix\_ie\_i∣\\sum
\_ix\_ie\_i) = \\sum
\_i\lambda~\_ix\_i^2 ≥ 0

(resp. \textgreater{} 0 si x\neq~0) si bien que
(iii) \rigtharrow~(i).

Théorème~12.6.4 (réduction simultanée des formes quadratiques). Soit E
un \mathbb{R}~ espace vectoriel de dimension finie, \Phi une forme quadratique
définie positive, \Psi une forme quadratique sur E. Alors il existe une
base \mathcal{E} de E orthonormée pour \Phi et orthogonale pour \Psi.

Démonstration On sait qu'il existe un unique endomorphisme u de E tel
que \forall~~x,y \in E, \psi(x,y) = \phi(u(x),y). Comme \psi est
symétrique, u est un endomorphisme symétrique de l'espace euclidien
(E,\Phi) et il existe une base \mathcal{E} =
(e\_1,\\ldots,e\_n~)
orthonormée pour \Phi formée de vecteurs propres de u~: u(e\_i) =
\lambda~\_ie\_i. On a alors

\psi(e\_i,e\_\jmath) = \phi(e\_i,u(e\_\jmath)) =
\phi(e\_i,\lambda~\_\jmathe\_\jmath) =
\lambda~\_\jmath\delta\_i^\jmath

ce qui montre que \mathcal{E} est une base orthogonale pour \psi.

\paragraph{12.6.3 Normes d'endomorphismes}

Théorème~12.6.5 Soit E un espace euclidien et u \in L(E). Alors

\\textbar{}u\\textbar{}
=\
sup\_\\textbar{}x\\textbar{}\leq1,\\textbar{}y\\textbar{}\leq1\textbar{}(u(x)∣y)\textbar{}

Démonstration Supposons que
\\textbar{}x\\textbar{} \leq
1,\\textbar{}y\\textbar{} \leq 1. On a alors
d'après l'inégalité de Schwarz

\textbar{}(u(x)∣y)\textbar{}\leq\\textbar{}
u(x)\\textbar{}\\textbar{}y\\textbar{}
\leq\\textbar{} u\\textbar{}

ce qui montre que \\textbar{}u\\textbar{}
≥\
sup\_\\textbar{}x\\textbar{}\leq1,\\textbar{}y\\textbar{}\leq1\textbar{}(u(x)∣y)\textbar{}.
Mais d'autre part, puisque la boule unité fermée est compacte, il existe
x\_0 tel que
\\textbar{}x\_0\\textbar{} \leq 1
avec \\textbar{}u(x\_0)\\textbar{}
=\
sup\_\\textbar{}x\\textbar{}\leq1\\textbar{}u(x)\\textbar{}
=\\textbar{} u\\textbar{}. Posons alors,
si u\neq~0, y\_0 = u(x\_0)
\over
\\textbar{}u(x\_0)\\textbar{} .
On a \\textbar{}y\_0\\textbar{} =
1 et

\textbar{}(u(x\_0)∣y\_0)\textbar{}
= (u(x\_0)∣u(x\_0))
\over
\\textbar{}u(x\_0)\\textbar{}
=\\textbar{} u(x\_0)\\textbar{}
=\\textbar{} u\\textbar{}

ce qui montre que \\textbar{}u\\textbar{}
\leq\
sup\_\\textbar{}x\\textbar{}\leq1,\\textbar{}y\\textbar{}\leq1\textbar{}(u(x)∣y)\textbar{},
et donc l'égalité.

Corollaire~12.6.6 Soit E un espace euclidien et u \in L(E). Alors
\\textbar{}u\\textbar{}
=\\textbar{} u^∗\\textbar{}.

Démonstration En effet

\\textbar{}u\\textbar{}
=\
sup\_\\textbar{}x\\textbar{}\leq1,\\textbar{}y\\textbar{}\leq1\textbar{}(u(x)∣y)\textbar{}
=\
sup\_\\textbar{}x\\textbar{}\leq1,\\textbar{}y\\textbar{}\leq1\textbar{}(x∣u^∗(y))\textbar{}
=\\textbar{} u^∗\\textbar{}

Théorème~12.6.7 Soit E un espace euclidien et u \in L(E) symétrique
positif. Alors

\\textbar{}u\\textbar{}
=\
sup\_\\textbar{}x\\textbar{}\leq1(u(x)∣x)
=\
max\_\lambda~\in\mathrm{Sp}(u)~\lambda~

Démonstration Supposons que
\\textbar{}x\\textbar{} \leq 1. On a alors
d'après l'inégalité de Schwarz

(u(x)∣x) \leq\\textbar{}
u(x)\\textbar{}\\textbar{}x\\textbar{}
\leq\\textbar{} u\\textbar{}

ce qui montre que \\textbar{}u\\textbar{}
≥\
sup\_\\textbar{}x\\textbar{}\leq1(u(x)∣x).
De plus, soit k =\
sup\_\\textbar{}x\\textbar{}\leq1(u(x)∣x),
si bien que \forall~~x \in
E,(u(x)∣x) \leq
k\\textbar{}x\\textbar{}^2, et
supposons que \\textbar{}x\\textbar{} \leq
1,\\textbar{}y\\textbar{} \leq 1. On a alors,
puisque u est symétrique

\begin{align*}
\textbar{}(u(x)∣y)\textbar{}& =& 1
\over 4 \textbar{}(u(x +
y)∣x + y) - (u(x -
y)∣x - y)\textbar{}\%&
\\ & \leq& k \over 4
(\\textbar{}x + y\\textbar{}^2
+\\textbar{} x -
y\\textbar{}^2) = k \over 2
(\\textbar{}x\\textbar{}^2
+\\textbar{} y\\textbar{}^2) \leq
k \%& \\ \end{align*}

et donc

\\textbar{}u\\textbar{}
=\
sup\_\\textbar{}x\\textbar{}\leq1,\\textbar{}y\\textbar{}\leq1\textbar{}(u(x)∣y)\textbar{}\leq
k

et par conséquent

\\textbar{}u\\textbar{}
=\
sup\_\\textbar{}x\\textbar{}\leq1(u(x)∣x)

Soit
(e\_1,\\ldots,e\_n~)
une base orthonormée formée de vecteurs propres de u, u(e\_i) =
\lambda~\_ie\_i. On peut supposer que \lambda~\_1 \leq
\lambda~\_2
\leq\\ldots~ \leq
\lambda~\_n. On a alors, si x =\
\sum  \_ix\_ie\_i~,

(u(x)∣x) = (\\sum
\_i\lambda~\_ix\_ie\_i∣\\sum
\_ix\_ie\_i) = \\sum
\_i\lambda~\_ix\_i^2 \leq \lambda~\_ n
\sum \_ix\_i^2 \leq \lambda~~\_
n

avec égalité si x = e\_n. Ceci montre que

sup\_\\textbar{}x\\textbar{}\leq1(u(x)\mathrel∣~x)
=\
max\_\lambda~\in\mathrm{Sp}(u)~\lambda~

et achève la démonstration.

Corollaire~12.6.8 Soit E un espace euclidien et u \in L(E). Alors
u^∗u est un endomorphisme symétrique positif et
\\textbar{}u^∗u\\textbar{}
=\\textbar{} u\\textbar{}^2.

Démonstration On a (u^∗u)^∗ =
u^∗u^∗∗ = u^∗u donc u^∗u est
symétrique. De plus (u^∗u(x)∣x) =
(u(x)∣u(x)) =\\textbar{}
u(x)\\textbar{}^2 ≥ 0, ce qui montre que
u^∗u est positif. On a alors

\\textbar{}u^∗u\\textbar{}^2
= sup~\_\\textbar{}
x\\textbar{}\leq1(u^∗u(x)∣x)
= sup~\_\\textbar{}
x\\textbar{}\leq1\\textbar{}u(x)\\textbar{}^2
=\\textbar{} u\\textbar{}^2

Corollaire~12.6.9 \\textbar{}u\\textbar{}
est la racine carrée de la plus grande valeur propre de u^∗u.

Démonstration Résulte immédiatement des résultats précédents.

\paragraph{12.6.4 Endomorphismes orthogonaux d'un plan euclidien}

Remarque~12.6.2 Soit E un \mathbb{R}~-espace vectoriel ~de dimension finie. La
relation définie sur l'ensemble des bases de E par

\mathcal{E}\mathcal{R}\mathcal{E}'\Leftrightarrow
\mathrm{det}~
P\_\mathcal{E}^\mathcal{E}' \textgreater{} 0

est une relation d'équivalence pour laquelle il y a deux classes
d'équivalence appelées orientations de l'espace. Le choix d'une de ces
classes (les bases directes) oriente l'espace E.

Soit E un espace euclidien de dimension 2.

Théorème~12.6.10 Soit u \in O(E) et \mathcal{E} une base orthonormée de E.

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) Si u \in SO(E), alors
  \mathrmMat~ (u,\mathcal{E}) =
  \left
  (\matrix\,cos~
  \theta&-sin~ \theta\cr
  sin \theta &\cos~
  \theta\right ) pour un \theta \in \mathbb{R}~\diagup2\pi~ℤ ne dépendant que de
  l'orientation de la base \mathcal{E} (un changement d'orientation changeant \theta en
  - \theta)~; le groupe SO(E) est commutatif, isomorphe au groupe (\mathbb{R}~\diagup2\pi~ℤ,+)
\item
  (ii) Si \mathrm{det}~ u =
  -1, alors \mathrmMat~
  (u,\mathcal{E}) = \left
  (\matrix\,cos~
  \theta&sin~ \theta \cr
  sin \theta&-\cos~
  \theta\right )~; u est une symétrie orthogonale par
  rapport à une droite.
\end{itemize}

Démonstration Posons \mathcal{E} = (e\_1,e\_2) et u(e\_1)
= ae\_1 + be\_2. On a a^2 + b^2
=\\textbar{}
u(e\_1)\\textbar{}^2
=\\textbar{}
e\_1\\textbar{}^2 = 1, donc il existe
\theta \in \mathbb{R}~\diagup2\pi~ℤ tel que a = cos~ \theta et b
= sin \theta. On a u(e\_2~) \in
u(e\_1)^\bot = \mathbb{R}~(-be\_1 + ae\_2). On en
déduit que u(e\_2) = \lambda~(-sin~
\thetae\_1 + cos \thetae\_2~)~; comme
\\textbar{}u(e\_2)\\textbar{}
=\\textbar{} e\_2\\textbar{} = 1,
on doit avoir \lambda~^2 = 1, soit \lambda~ = ±1. Donc la matrice de u dans
la base \mathcal{E} est de l'une des deux formes

\left
(\matrix\,cos~
\theta&-sin~ \theta \cr
sin \theta&\cos~ \theta
\cr \right )\text ou
\left
(\matrix\,cos~
\theta&sin~ \theta \cr
sin \theta&-\cos~
\theta\right )

Il est clair que le premier cas correspond à
\mathrm{det}~ u = 1 et le
second cas à \mathrm{det}~ u =
-1. Dans le second cas, on vérifie immédiatement que u^2 =
\mathrmId\_E, ce qui montre que u est une
symétrie (évidemment orthogonale). Comme
u\neq~\mathrmId et
u\neq~ -\mathrmId, c'est
nécessairement une symétrie par rapport à une droite.

Dans le premier cas, on a
\mathrm{tr}~u =
2cos~ \theta, ce qui montre que
cos~ \theta est indépendant du choix de la base \mathcal{E},
et que donc \theta \in \mathbb{R}~\diagup2\pi~ℤ est déterminé au signe près. On vérifie
immédiatement que

\begin{align*} \left
(\matrix\,cos~
\theta&-sin~ \theta \cr
sin \theta&\cos~ \theta
\cr \right )\left
(\matrix\,cos~
\theta'&-sin~ \theta'\cr
sin \theta' &\cos~
\theta'\right )&& \%& \\ &
\quad & = \left
(\matrix\,cos~
(\theta + \theta')&-sin~ (\theta + \theta') \cr
sin (\theta + \theta')&\cos~ (\theta
+ \theta')\right )\%& \\
\end{align*}

ce qui montre que le groupe SO(2) = \R(\theta) =
\left
(\matrix\,cos~
\theta&-sin~ \theta\cr
sin \theta &\cos~
\theta\right )∣\theta \in
\mathbb{R}~\diagup2\pi~ℤ\ est commutatif et isomorphe à (\mathbb{R}~\diagup2\pi~ℤ,+). Soit u
\in SO(E)~; si \mathcal{E} et \mathcal{E}' sont deux bases orthonormées de même sens
(c'est-à-dire que
\mathrm{det}~
P\_\mathcal{E}^\mathcal{E}' \textgreater{} 0), alors P =
P\_\mathcal{E}^\mathcal{E}'\in SO(2), on a

\mathrmMat~ (u,\mathcal{E}') =
P^-1 \mathrmMat~
(u,\mathcal{E})P =
P^-1P\mathrmMat~
(u,\mathcal{E}) = \mathrmMat~ (u,\mathcal{E})

puisque SO(2) est commutatif et que P et
\mathrmMat~ (u,\mathcal{E}) sont
toutes deux dans SO(2). Donc \theta ne dépend que de l'orientation de la base
\mathcal{E}. Si maintenant, \mathcal{E} et \mathcal{E}' sont deux bases orthonormées de sens contraire
(c'est-à-dire que
\mathrm{det}~
P\_\mathcal{E}^\mathcal{E}' \textless{} 0), alors
\mathrmMat~ (u,\mathcal{E})P est une
matrice orthogonale de déterminant - 1. Comme on l'a vu, son carré est
nécessairement l'identité de même que le carré de P, ce qui montre que
\mathrmMat~ (u,\mathcal{E}') =
P^-1 \mathrmMat~
(u,\mathcal{E})P = P\mathrmMat~ (u,\mathcal{E})P
= \mathrmMat~
(u,\mathcal{E})^-1 = R(-\theta) (si
\mathrmMat~ (u,\mathcal{E}) = R(\theta))~:
un changement d'orientation de la base change donc \theta en - \theta.

Définition~12.6.2 Soit E un plan euclidien orienté, u \in SO(E). On
appelle mesure de la rotation u l'unique élément \theta de \mathbb{R}~\diagup2\pi~ℤ tel que,
pour toute base orthonormée directe \mathcal{E} de E, on ait
\mathrmMat~ (u,\mathcal{E}) =
\left
(\matrix\,cos~
\theta&-sin~ \theta\cr
sin \theta &\cos~
\theta\right ).

\paragraph{12.6.5 Réduction des endomorphismes orthogonaux}

Théorème~12.6.11 Soit E un espace euclidien et u un endomorphisme
orthogonal de E. Alors il existe une base orthonormée \mathcal{E} de E telle que

\mathrmMat~ (u,\mathcal{E}) =
\left
(\matrix\,I\_p&0
&\\ldots~
&\\ldots&\\\ldots~&0
\cr 0 &-I\_q&0
&\\ldots&\\\ldots&\\⋮~
\cr \⋮~
&0
&A\_1&0&\\ldots&\\⋮~
\cr \⋮~
&\\ldots~
&⋱
&⋱&\mathrel⋱&\⋮~
\cr \⋮~
&\\ldots~
&\\ldots~
&⋱&\mathrel⋱&0
\cr 0
&\\ldots~
&\\ldots~
&\\ldots&0&A\_s~\right
)

avec A\_i = \left
(\matrix\,cos~
\theta\_i&-sin \theta\_i~
\cr sin~
\theta\_i&cos \theta\_i~
\right ), \theta\_i \in \mathbb{R}~ \diagdown 2\pi~ℤ.

Démonstration Par récurrence sur n = dim~ E. Si
n = 1, alors u = ±\mathrmId\_E et le résultat
est évident. Supposons le donc démontré pour tout espace euclidien de
dimension strictement inférieure à n et soit E de dimension n, u \in O(E).
Si u admet une valeur propre \lambda~, soit x un vecteur propre associé. On a
\textbar{}\lambda~\textbar{}\\textbar{}x\\textbar{}
=\\textbar{} u(x)\\textbar{}
=\\textbar{} x\\textbar{}, d'où \lambda~ = ±1. La
droite \mathbb{R}~x est stable par u, donc H = (\mathbb{R}~x)^\bot aussi. La
restriction v de u à H est un endomorphisme orthogonal de H et par
l'hypothèse de récurrence, il existe une base orthonormée
(e\_2,\\ldots,e\_n~)
de H telle que la matrice de v dans cette base soit de la forme voulue.
Alors ( x \over
\\textbar{}x\\textbar{}
,e\_2,\\ldots,e\_n~)
est une base orthonormée de E et à une permutation près de cette base
(si \lambda~ = -1), la matrice de u dans cette base est de la forme voulue. Si
u n'a pas de valeur propre (réelle), soit \Pi un plan stable par u, dont
l'existence est garantie par un lemme précédent. L'endomorphisme de \Pi
induit par u est un endomorphisme orthogonal de \Pi sans valeur propre,
donc une rotation d'angle \theta\_1 \in \mathbb{R}~ \diagdown \pi~ℤ. Soit
(e\_1,e\_2) une base orthonormée de \Pi. Le sous-espace de
dimension n - 2, H = \Pi^\bot est également stable par u et
l'endomorphisme v de H induit par u est un endomorphisme orthogonal de H
sans valeur propre. Par hypothèse de récurrence, il existe une base
orthonormée
(e\_3,\\ldots,e\_n~)
de H telle que la matrice de v dans cette base soit de la forme voulue
(avec p = q = 0). Alors la matrice de u dans la base orthonormée
(e\_1,e\_2,e\_3,\\ldots,e\_n~)
est de la forme voulue, ce qui achève la démonstration.

Exemple~12.6.1 Si dim~ E = 3, on a les formes
réduites possibles (en tenant compte de
\mathrm{det}~ u =
(-1)^q et de p + q + 2s = 3)

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \mathrm{det}~ u = 1

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    \left
    (\matrix\,1&0&0 \cr
    0&1&0 \cr 0&0&1\right )
    (identité),
  \item
    \left (\matrix\,1&0
    &0 \cr 0&-1&0 \cr 0&0
    &-1\right ) (retournement d'axe \mathbb{R}~e\_1),
  \item
    \left (\matrix\,1&0
    &0 \cr 0&cos~
    \theta&-sin~ \theta \cr
    0&sin \theta&\cos~ \theta
    \right ) (rotation d'axe \mathbb{R}~e\_1)
  \end{itemize}
\item
  \mathrm{det}~ u = -1

  \begin{itemize}
  \itemsep1pt\parskip0pt\parsep0pt
  \item
    \left (\matrix\,-1&0
    &0 \cr 0 &-1&0 \cr 0 &0
    &-1\right )\quad (
    -\mathrmId\_E),
  \item
    \left
    (\matrix\,1&0&0 \cr
    0&1&0 \cr 0&0&-1\right )
    (symétrie par rapport au plan
    \mathrmVect(e\_1,e\_2~)),
  \item
    \left (\matrix\,-1&0
    &0 \cr 0 &cos~
    \theta&-sin~ \theta \cr 0
    &sin \theta&\cos~ \theta
    \right ) (composée de la symétrie par rapport au
    plan
    \mathrmVect(e\_2,e\_3~)
    et d'une rotation d'axe \mathbb{R}~e\_1)
  \end{itemize}
\end{itemize}

\paragraph{12.6.6 Produit vectoriel, produit mixte}

Théorème~12.6.12 Soit E un espace euclidien orienté de dimension n.
L'application n linéaire alternée
\mathrm{det} \_\mathcal{E}~ est
indépendante du choix de la base orthonormée directe \mathcal{E}.

Démonstration Si \mathcal{E}' est une autre base orthonormée directe, la matrice
de passage P\_\mathcal{E}^\mathcal{E}' est à la fois orthogonale et de
déterminant strictement positif, donc de déterminant 1. Or on a

\mathrm{det} \_\mathcal{E}~
= \mathrm{det}~
\_\mathcal{E}(\mathcal{E}')\mathrm{det}~
\_\mathcal{E}' = \mathrm{det}~
P\_\mathcal{E}^\mathcal{E}'\mathrm{det}~
\_ \mathcal{E}' = \mathrm{det}~
\_\mathcal{E}'

Définition~12.6.3 On notera
{[}x\_1,\\ldots,x\_n~{]}
= \mathrm{det}~
\_\mathcal{E}(x\_1,\\ldots,x\_n~)
et on l'appellera le produit mixte des n vecteurs
x\_1,\\ldots,x\_n~.

Remarque~12.6.3 Il est clair qu'un changement d'orientation de l'espace
change le produit mixte en son opposé.

Théorème~12.6.13 Soit E un espace euclidien orienté. Alors, pour toute
famille
(x\_1,\\ldots,x\_n~)
de E on a

\mathrm{det}~
Gram(x\_1,\\\ldots,x\_n~)
=
{[}x\_1,\\ldots,x\_n{]}^2~

Démonstration Soit \mathcal{E} une base orthonormée directe et soit A la matrice
des coordonnées de
(x\_1,\\ldots,x\_n~)
dans la base \mathcal{E}. On a alors
\mathrm{det}~ A =
{[}x\_1,\\ldots,x\_n~{]}.
D'autre part

(x\_i∣x\_\jmath) =
\sum \_k=1^na~\_
k,ia\_k,\jmath = (^tAA)\_ i,\jmath

si bien que
Gram(x\_1,\\\ldots,x\_n~)
= ^tAA. On a donc

\mathrm{det}~
Gram(x\_1,\\\ldots,x\_n~)
= \mathrm{det}~
^tAA =
(\mathrm{det} A)^2~
= {[}x\_
1,\\ldots,x\_n{]}^2~

Théorème~12.6.14 (et définition). Soit E un espace euclidien orienté de
dimension n. Soit
x\_1,\\ldots,x\_n-1~
\in E. Il existe un unique vecteur, appelé le produit vectoriel des n - 1
vecteurs
x\_1,\\ldots,x\_n-1~
et noté x\_1
∧\\ldots~ ∧
x\_n-1 tel que

\forall~~y \in E,
{[}x\_1,\\ldots,x\_n-1~,y{]}
= (x\_1
∧\\ldots~ ∧
x\_n-1∣y)

Démonstration L'application
y\mapsto~{[}x\_1,\\ldots,x\_n-1~,y{]}
est une forme linéaire sur E, donc représentée par le produit scalaire
avec un unique vecteur.

Proposition~12.6.15

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) x\_1
  ∧\\ldots~ ∧
  x\_n-1 = 0 \Leftrightarrow
  (x\_1,\\ldots,x\_n-1~)
  est une famille liée
\item
  (ii) \forall~i \in {[}1,n - 1{]}, x\_1~
  ∧\\ldots~ ∧
  x\_n-1 \bot x\_i
\item
  (iii) si
  (x\_1,\\ldots,x\_n-1~)
  est une famille libre, alors
  (x\_1,\\ldots,x\_n-1,x\_1~
  ∧\\ldots~ ∧
  x\_n-1) est une base directe de E
\item
  (iv) \\textbar{}x\_1
  ∧\\ldots~ ∧
  x\_n-1\\textbar{}^2
  = \mathrm{det}~
  Gram(x\_1,\\\ldots,x\_n-1~).
\end{itemize}

Démonstration (i) On a en effet

\begin{align*}
(x\_1,\\ldots,x\_n-1~)\text
libre & \Leftrightarrow & \exists~y
\in E,
(x\_1,\\ldots,x\_n-1~,y)\text
base de E\%& \\ &
\Leftrightarrow & \exists~y \in E,
{[}x\_1,\\ldots,x\_n-1,y{]}\mathrel\neq~~0
\%& \\ & \Leftrightarrow &
\existsy \in E, (x\_1~
∧\\ldots~ ∧
x\_n-1∣y)\mathrel\neq~0
\%& \\ & \Leftrightarrow &
x\_1
∧\\ldots~ ∧
x\_n-1\neq~0 \%&
\\ \end{align*}

(ii) (x\_1
∧\\ldots~ ∧
x\_n-1∣x\_i) =
{[}x\_1,\\ldots,x\_i,\\\ldots,x\_n-1,x\_i~{]}
= 0

(iii) On a

\begin{align*}
{[}x\_1,\\ldots,x\_n-1,x\_1~
∧\\ldots~ ∧
x\_n-1{]}& =& (x\_1
∧\\ldots~ ∧
x\_n-1∣x\_1
∧\\ldots~ ∧
x\_n-1)\%& \\ & =&
\\textbar{}x\_1
∧\\ldots~ ∧
x\_n-1\\textbar{}^2 \textgreater{} 0
\%& \\ \end{align*}

(iv) Comme on vient de le voir,

\begin{align*}
\\textbar{}x\_1
∧\\ldots~ ∧
x\_n-1\\textbar{}^4&& \%&
\\ & =&
{[}x\_1,\\ldots,x\_n-1,x\_1~
∧\\ldots~ ∧
x\_n-1{]}^2 \%& \\ &
=& \mathrm{det}~
Gram(x\_1,\\\ldots,x\_n-1,x\_1~
∧\\ldots~ ∧
x\_n-1) \%& \\ & =&
\left
\textbar{}\matrix\,Gram(x\_1,\\\ldots,x\_n-1~)&0
\cr 0 &\\textbar{}x\_1
∧\\ldots~ ∧
x\_n-1\\textbar{}^2\right
\textbar{} \%& \\ & =&
\\textbar{}x\_1
∧\\ldots~ ∧
x\_n-1\\textbar{}^2\
\mathrm{det} Gram(x~\_
1,\\ldots,x\_n-1~)\%&
\\ \end{align*}

puisque (x\_1
∧\\ldots~ ∧
x\_n-1∣x\_i) = 0. Si
(x\_1,\\ldots,x\_n~)
est libre, on peut simplifier par \\textbar{}x\_1
∧\\ldots~ ∧
x\_n-1\\textbar{}^2 et on obtient
\\textbar{}x\_1
∧\\ldots~ ∧
x\_n-1\\textbar{}^2
= \mathrm{det}~
Gram(x\_1,\\\ldots,x\_n-1~),
formule qui est encore exacte si la famille est liée puisque les deux
termes valent 0.

Remarque~12.6.4 Si
(x\_1,\\ldots,x\_n-1~)
est une famille libre, (ii) définit la droite engendrée par x\_1
∧\\ldots~ ∧
x\_n-1, (iii) définit son orientation sur cette droite et (iv)
définit sa norme, ce qui fournit une construction géométrique du produit
vectoriel~: c'est le vecteur orthogonal à l'hyperplan
\mathrmVect(x\_1,\\\ldots,x\_n-1~),
tel que la base
(x\_1,\\ldots,x\_n-1,x\_1~
∧\\ldots~ ∧
x\_n-1) soit une base directe de E et dont la norme est
\sqrt\\mathrm{det}
  Gram (x\_1 ~ ,
\\ldots~ ,
x\_n-1  ).

Coordonnées du produit vectoriel

Soit \mathcal{E} une base orthonormée directe de E, x\_\jmath
= \\sum ~
\_i=1^n\alpha~\_i,\jmathe\_i, y
= \\sum ~
\_i=1^ny\_ie\_i. On a alors, en développant
le déterminant suivant la dernière colonne

\begin{align*}
{[}x\_1,\\ldots,x\_n-1~,y{]}&
=& \left
\textbar{}\matrix\,\alpha~\_1,1&\\ldots&\alpha~\_1,n-1&y\_1~
\cr
\\ldots~
&\\ldots&\\\ldots~
&\\ldots~
\cr
\alpha~\_n,1&\\ldots&\alpha~\_n,n-1&y\_n~\right
\textbar{} = \sum \_i=1^n\Delta~\_
iy\_i\%& \\ & =&
(\sum \_i=1^n\Delta~\_
ie\_i∣y) \%&
\\ \end{align*}

avec

\Delta\_i = (-1)^n+i\left
\textbar{}\matrix\,\alpha~\_1,1
&\\ldots&\alpha~\_1,n-1~
\cr
\\ldots~
&\\ldots&\\\ldots~
\cr
\alpha~\_i-1,1&\\ldots&\alpha~\_i-1,n-1~
\cr
\alpha~\_i+1,1&\\ldots&\alpha~\_i+1,n-1~
\cr
\\ldots~
&\\ldots&\\\ldots~
\cr \alpha~\_n,1
&\\ldots&\alpha~\_n,n-1~
\right \textbar{}

On en déduit que

x\_1
∧\\ldots~ ∧
x\_n-1 = \\sum
\_i=1^n\Delta\_ ie\_i

Produit vectoriel en dimension 3

On a alors \\textbar{}x\_1 ∧
x\_2\\textbar{}^2
= \mathrm{det}~
Gram(x\_1,x\_2~)
=\\textbar{}
x\_1\\textbar{}^2\\textbar{}x\_2\\textbar{}^2
- (x\_1∣x\_2)^2
=\\textbar{}
x\_1\\textbar{}^2\\textbar{}x\_2\\textbar{}^2(1
- cos ^2~\theta) où \theta désigne l'angle non
orienté des vecteurs x\_1 et x\_2. On a donc alors

\\textbar{}x\_1 ∧
x\_2\\textbar{} =\\textbar{}
x\_1\\textbar{}\,\\textbar{}x\_2\\textbar{}\
sin \theta

On a également le résultat important suivant

Théorème~12.6.16 Soit E un espace euclidien de dimension 3,
x\_1,x\_2,x\_3 \in E. Alors

(x\_1 ∧ x\_2) ∧ x\_3 =
(x\_1∣x\_3)x\_2 -
(x\_2∣x\_3)x\_1

Démonstration Si (x\_1,x\_2) est liée, on a par exemple
x\_2 = \lambda~x\_1 et on vérifie facilement que les deux
membres valent 0. Si (x\_1,x\_2) est libre, alors
(x\_1 ∧ x\_2) ∧ x\_3 \in (x\_1 ∧
x\_2)^\bot =\
\mathrmVect(x\_1,x\_2), si bien
qu'a priori (x\_1 ∧ x\_2) ∧ x\_3 = \lambda~x\_1
+ \mux\_2. Un calcul sur les coordonnées dans une base orthonormée
directe adéquate (par exemple ( x\_1 \over
\\textbar{}x\_1\\textbar{} ,
x\_1∧x\_2 \over
\\textbar{}x\_1∧x\_2\\textbar{}
,\\ldots~)) fournit
les valeurs de \lambda~ et \mu.

Remarque~12.6.5 On pourra utiliser le moyen mnémotechnique suivant~: le
produit scalaire affecté du signe + concerne les deux termes extrêmes de
l'expression (x\_1 ∧ x\_2) ∧ x\_3.

Corollaire~12.6.17 Soit a\neq~0. L'équation x ∧ a
= b a une solution si et seulement si~a \bot b.

Démonstration Il est clair que la condition est nécessaire. Si elle est
vérifiée, cherchons x sous la forme x\_0 = \lambda~a ∧ b. On a alors

x\_0 ∧ a = \lambda~(a ∧ b) ∧ a = \lambda~(a∣a)b -
\lambda~(a∣b)a =
\lambda~\\textbar{}a\\textbar{}^2b

Donc x\_0 = 1 \over
\\textbar{}a\\textbar{}^2 a ∧
b est une solution.

Remarque~12.6.6 On a alors

\begin{align*} x ∧ a = b&
\Leftrightarrow & x ∧ a = x\_0 ∧ a
\Leftrightarrow (x - x\_0) ∧ a = 0\%&
\\ & \Leftrightarrow & x -
x\_0 = \lambda~a \%& \\
\end{align*}

\paragraph{12.6.7 Angles}

On désigne par E un espace euclidien (de dimension finie), par O(E)
(resp. O^+(E)) le groupe orthogonal (resp. le groupe des
rotations de E).

Notion générale d'angles d'ob\jmathets

Soit X un ensemble de parties de E stable par O(E), c'est-à-dire que

\forall~~r \in O(E)\quad
\forall~~A \in X\quad r(A) \in X.

Exemple~: X peut être l'ensemble D(E) des droites de E, ou l'ensemble
\tildeD(\mathcal{E}) des demi-droites de E, ou l'ensemble des
plans de E, ou l'ensemble des hyperplans de E.

Définition~12.6.4 On appelle angle non orienté (resp angle orienté)
d'éléments de X le quotient de X \times X par la relation \mathcal{R} définie par

\begin{align*}
(D\_1,D\_2)\mathcal{R}(D\_1',D\_2')
\Leftrightarrow&& \%& \\
& & \exists~r \in O(E) (\textresp.
O^+(E))\quad r(D\_ 1) =
D\_1'\text et r(D\_2) =
D\_2'\%& \\
\end{align*}

On notera \overline(D\_1,D\_2)(resp.
\widehat(D\_1,D\_2)) la classe
d'équivalence du couple (D\_1,D\_2) et on l'appellera
l'angle non orienté (resp. l'angle orienté) des ob\jmathets D\_1 et
D\_2.

Cela revient à définir les angles par les propriétés

\overline(D\_1,D\_2) =
\overline(D\_1',D\_2')
\Leftrightarrow \exists~r \in O(E),
\quad r(D\_1) = D\_1',r(D\_2) =
D\_2'

et

\widehat(D\_1,D\_2)
=\widehat (D\_1',D\_2')
\Leftrightarrow \exists~r \in
O^+(E), \quad r(D\_ 1) =
D\_1',r(D\_2) = D\_2'

On s'intéressera par la suite uniquement au cas où X est l'ensemble D(E)
des droites de E ou l'ensemble \tildeD(\mathcal{E}) des
demi-droites de E (angles de droites ou de demi droites).

Comparaison des angles orientés et non orientés

Théorème~12.6.18 Si dim~ E ≥ 3 les notions
d'angles orientés ou non orientés coïncident aussi bien pour les droites
que pour les demi-droites, c'est-à-dire que

\existsr \in O(E)\quad r(D\_1~)
= D\_1'\text et r(D\_2) =
D\_2'

si et seulement si

\existsr \in O^+~(E)\quad
r(D\_ 1) = D\_1'\text et
r(D\_2) = D\_2'.

Démonstration L'implication '' ⇐'' est claire, et si la propriété de
gauche est vérifiée, soit r appartient à O^+(E) et c'est
terminé, soit r appartient à O^-(E), mais alors il suffit de
composer r par une symétrie s par rapport à un hyperplan contenant
D\_1' et D\_2' pour trouver un r' = s \cdot r \in
O^+(E) tel que r'(D\_1) = D\_1' et
r'(D\_2) = D\_2', car s laisse invariantes D\_1'
et D\_2'.

Mesure des angles non orientés de droites ou de demi-droites

Pour (D\_1,D\_2) \inD(E)^2, on définit
\phi(D\_1,D\_2) de la manière suivante~: soit x\_1
un vecteur directeur de D\_1 et x\_2 un vecteur
directeur de D\_2, le réel 
\textbar{}(x\_1∣x\_2)\textbar{}
\over
\\textbar{}x\_1\\textbar{}
\\textbar{}x\_2\\textbar{} \in
{[}0,1{]} est indépendant du choix des vecteurs directeurs de
D\_1 et D\_2 (changer x\_1 en \lambda~x\_1 et
x\_2 en \mux\_2 avec \lambda~\neq~0 et
\mu\neq~0 ne change pas sa valeur), on le définit
comme \phi(D\_1,D\_2).

Théorème~12.6.19 \forall~(D\_1,D\_2~)
\inD(E)^2\quad
\overline(D\_1,D\_2) =
\overline(D\_1',D\_2')\quad
\Leftrightarrow \quad
\phi(D\_1,D\_2) = \phi(D\_1',D\_2').

Démonstration ( \rigtharrow~). Il suffit de remarquer que si r \in O(E) alors


\textbar{}(r(x\_1)∣r(x\_2))\textbar{}
\over
\\textbar{}r(x\_1)\\textbar{}
\\textbar{}r(x\_2)\\textbar{}
=
\textbar{}(x\_1∣x\_2)\textbar{}
\over
\\textbar{}x\_1\\textbar{}
\\textbar{}x\_2\\textbar{} .

( ⇐). Supposons que \phi(D\_1,D\_2) =
\phi(D\_1',D\_2')\neq~1. Soit
d'abord r \in O(E) qui envoie D\_1 sur D\_1' et le plan
Vect(D\_1,D\_2) sur le plan
Vect(D\_1',D\_2') (la construire en prenant des bonnes
bases orthonormées). Alors si on pose D\_3 = r(D\_2), on
a \phi(D\_1',D\_3) = \phi(D\_1,D\_2) =
\phi(D\_1',D\_2'). Dans le plan
Vect(D\_1',D\_2') (qui contient les trois droites
D\_1', D\_2' et D\_3) ceci impose que soit
D\_3 = D\_2' (et dans ce cas on a trouvé r tel que
r(D\_1) = D\_1' et r(D\_2) = D\_2'),
soit D\_3 et D\_2' sont symétriques par rapport à
D\_1, auquel cas en composant r par la symétrie orthogonale par
rapport à l'hyperplan D\_1' \oplus~ V
ect(D\_1',D\_2')^\bot on trouve un r' tel que
r'(D\_1) = D\_1' et r'(D\_2) = D\_2'.

Si \phi(D\_1,D\_2) = \phi(D\_1',D\_2') = 1, on
a D\_1 = D\_2, D\_1' = D\_2' et il
suffit de choisir un r tel que r(D\_1) = D\_1'.

Définition~12.6.5 On appelle mesure de l'angle non orienté des droites
D\_1 et D\_2 l'unique réel \theta \in {[}0,\pi~\diagup2{]} tel que
cos \theta = \phi(D\_1,D\_2~).

Le théorème précédent montre que deux angles non orientés de droites
sont égaux si et seulement si leurs mesures sont égales.

Pour les demi-droites on suit un plan analogue en posant cette fois
\phi(D\_1,D\_2) =
(x\_1∣x\_2)
\over
\\textbar{}x\_1\\textbar{}
\\textbar{}x\_2\\textbar{} \in
{[}-1,1{]} qui ne dépend pas du choix des vecteurs directeurs des
demi-droites (car cette fois \lambda~ et \mu sont nécessairement positifs). On a
le même théorème (avec une démonstration analogue) et on peut donc poser

Définition~12.6.6 On appelle mesure de l'angle non orienté des
demi-droites D\_1 et D\_2 l'unique réel \theta \in {[}0,\pi~{]}
tel que cos \theta = \phi(D\_1,D\_2~).

Le théorème montre que deux angles non orientés de demi-droites sont
égaux si et seulement si leurs mesures sont égales.

Angles orientés de demi-droites dans le plan euclidien

On notera \tildeA(\mathcal{E}) l'ensemble des angles orientés
de demi-droites du plan euclidien E.

Théorème~12.6.20 Soit D \in\tildeD(\mathcal{E}). Alors
l'application f : O^+(E) \rightarrow~\tildeA(\mathcal{E}),
r\mapsto~\widehat(D,r(D)) est une
bi\jmathection qui ne dépend pas du choix de D.

Démonstration Pour l'in\jmathectivité, si on a f(r) = f(r') c'est qu'il
existe r'' \in O^+(E) tel que r''(D) = D et r'`\cdot r(D) = r'(D).
Mais la première relation impose que r'' = \mathrmId
(une rotation du plan euclidien qui laisse invariante une demi-droite
est l'identité) et la deuxième que r^-1 \cdot r'(D) = D soit r' =
r pour la même raison. En ce qui concerne l'indépendance de D il suffit
de remarquer que si D' \in\tildeD(\mathcal{E}), il existe
r\_0 \in O^+(E) tel que D' = r\_0(D) et alors

\widehat(D',r(D')) =\widehat
(r\_0(D),r \cdot r\_0(D)) =\widehat
(r\_0(D),r\_0 \cdot r(D)) =\widehat
(D,r(D))

(on voit ici le rôle essentiel de la commutativité de O^+(E)
en dimension 2). La sur\jmathectivité provient alors du fait que tout angle
\widehat(D\_1,D\_2) est de la forme
\widehat(D\_1,r(D\_1)) = f(r) en
utilisant une rotation r qui envoie D\_1 sur D\_2.

Cette bi\jmathection naturelle permet de transporter la structure de groupe
commutatif de O^+(E) à \tildeA(\mathcal{E}) en
posant~:

si \theta\_1 = f(r\_1) et \theta\_2 = f(r\_2) ,
alors on pose \theta\_1 + \theta\_2 = f(r\_1 \cdot
r\_2).

On définit de plus l'angle nul comme étant
f(\mathrmId) =\widehat (D,D),
l'angle plat comme étant f(-\mathrmId)
=\widehat (D,-D).

Théorème~12.6.21 (relation de Chasles)
\widehat(D\_1,D\_2)
+\widehat (D\_2,D\_3)
=\widehat (D\_1,D\_3).

Démonstration Soit r\_1 \in O^+(E) telle que
r\_1(D\_1) = D\_2 et r\_2 \in
O^+(E) telle que r\_2(D\_2) = D\_3.
Alors

\widehat(D\_1,D\_2)
+\widehat (D\_2,D\_3) =
f(r\_1) + f(r\_2) = f(r\_2 \cdot r\_1)
=\widehat (D\_1,r\_2 \cdot
r\_1(D\_1)) =\widehat
(D\_1,D\_3)

On retrouve alors sans difficulté toutes les propriétés des angles de
demi-droites. Comme de plus, si E est orienté, on connait un
isomorphisme de groupes abéliens entre \mathbb{R}~\diagup2\pi~ℤ et O^+(E), on en
déduit un isomorphisme entre \tildeA(\mathcal{E}) et \mathbb{R}~\diagup2\pi~ℤ qui
permet de mesurer les angles modulo 2\pi~ et d'effectuer les calculs (en
particulier les divisions par 2) dans \mathbb{R}~\diagup2\pi~ℤ. On en déduit par exemple
facilement qu'un couple de demi-droites a deux bissectrices opposés.

Angles orientés de droites dans le plan euclidien

On notera A(E) l'ensemble des angles orientés de droites du plan
euclidien E. La seule différence est que f n'est plus in\jmathective, mais
que f(r\_1) = f(r\_2) \Leftrightarrow
r\_2 = ±r\_1. On en déduit que f induit une bi\jmathection
\tildef de O^+(E)\diagup\
±\mathrmId\ sur A(E). On peut donc
encore transporter la structure de groupe de
O^+(E)\diagup\
±\mathrmId\ sur A(E) et on obtient
encore une relation de Chasles. Si E est orienté, on obtient un
isomorphisme de A(E) avec \mathbb{R}~\diagup\pi~ℤ qui permet de mesurer les angles de
droites modulo \pi~.

Exemple~12.6.2 L'application \theta\mapsto~2\theta est un
isomorphisme de groupes de \mathbb{R}~\diagup\pi~ℤ sur \mathbb{R}~\diagup2\pi~ℤ. On en déduit un isomorphisme
encore noté \theta\mapsto~2\theta de A(E) sur
\tildeA(\mathcal{E}). Soit D\_1 et D\_2 deux
droites de E, s\_1 et s\_2 les symétries orthogonales
par rapport à ces droites. Montrer que s\_2 \cdot s\_1 est
la rotation d'angle (de demi-droites)
2\widehat(D\_1,D\_2).

{[}
{[}
{[}
{[}

\end{document}

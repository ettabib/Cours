\documentclass[]{article}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={Reduction des formes quadratiques en dimension finie},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}
 
/* start css.sty */
.cmr-5{font-size:50%;}
.cmr-7{font-size:70%;}
.cmmi-5{font-size:50%;font-style: italic;}
.cmmi-7{font-size:70%;font-style: italic;}
.cmmi-10{font-style: italic;}
.cmsy-5{font-size:50%;}
.cmsy-7{font-size:70%;}
.cmex-7{font-size:70%;}
.cmex-7x-x-71{font-size:49%;}
.msbm-7{font-size:70%;}
.cmtt-10{font-family: monospace;}
.cmti-10{ font-style: italic;}
.cmbx-10{ font-weight: bold;}
.cmr-17x-x-120{font-size:204%;}
.cmsl-10{font-style: oblique;}
.cmti-7x-x-71{font-size:49%; font-style: italic;}
.cmbxti-10{ font-weight: bold; font-style: italic;}
p.noindent { text-indent: 0em }
td p.noindent { text-indent: 0em; margin-top:0em; }
p.nopar { text-indent: 0em; }
p.indent{ text-indent: 1.5em }
@media print {div.crosslinks {visibility:hidden;}}
a img { border-top: 0; border-left: 0; border-right: 0; }
center { margin-top:1em; margin-bottom:1em; }
td center { margin-top:0em; margin-bottom:0em; }
.Canvas { position:relative; }
li p.indent { text-indent: 0em }
.enumerate1 {list-style-type:decimal;}
.enumerate2 {list-style-type:lower-alpha;}
.enumerate3 {list-style-type:lower-roman;}
.enumerate4 {list-style-type:upper-alpha;}
div.newtheorem { margin-bottom: 2em; margin-top: 2em;}
.obeylines-h,.obeylines-v {white-space: nowrap; }
div.obeylines-v p { margin-top:0; margin-bottom:0; }
.overline{ text-decoration:overline; }
.overline img{ border-top: 1px solid black; }
td.displaylines {text-align:center; white-space:nowrap;}
.centerline {text-align:center;}
.rightline {text-align:right;}
div.verbatim {font-family: monospace; white-space: nowrap; text-align:left; clear:both; }
.fbox {padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
div.fbox {display:table}
div.center div.fbox {text-align:center; clear:both; padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
div.minipage{width:100%;}
div.center, div.center div.center {text-align: center; margin-left:1em; margin-right:1em;}
div.center div {text-align: left;}
div.flushright, div.flushright div.flushright {text-align: right;}
div.flushright div {text-align: left;}
div.flushleft {text-align: left;}
.underline{ text-decoration:underline; }
.underline img{ border-bottom: 1px solid black; margin-bottom:1pt; }
.framebox-c, .framebox-l, .framebox-r { padding-left:3.0pt; padding-right:3.0pt; text-indent:0pt; border:solid black 0.4pt; }
.framebox-c {text-align:center;}
.framebox-l {text-align:left;}
.framebox-r {text-align:right;}
span.thank-mark{ vertical-align: super }
span.footnote-mark sup.textsuperscript, span.footnote-mark a sup.textsuperscript{ font-size:80%; }
div.tabular, div.center div.tabular {text-align: center; margin-top:0.5em; margin-bottom:0.5em; }
table.tabular td p{margin-top:0em;}
table.tabular {margin-left: auto; margin-right: auto;}
div.td00{ margin-left:0pt; margin-right:0pt; }
div.td01{ margin-left:0pt; margin-right:5pt; }
div.td10{ margin-left:5pt; margin-right:0pt; }
div.td11{ margin-left:5pt; margin-right:5pt; }
table[rules] {border-left:solid black 0.4pt; border-right:solid black 0.4pt; }
td.td00{ padding-left:0pt; padding-right:0pt; }
td.td01{ padding-left:0pt; padding-right:5pt; }
td.td10{ padding-left:5pt; padding-right:0pt; }
td.td11{ padding-left:5pt; padding-right:5pt; }
table[rules] {border-left:solid black 0.4pt; border-right:solid black 0.4pt; }
.hline hr, .cline hr{ height : 1px; margin:0px; }
.tabbing-right {text-align:right;}
span.TEX {letter-spacing: -0.125em; }
span.TEX span.E{ position:relative;top:0.5ex;left:-0.0417em;}
a span.TEX span.E {text-decoration: none; }
span.LATEX span.A{ position:relative; top:-0.5ex; left:-0.4em; font-size:85%;}
span.LATEX span.TEX{ position:relative; left: -0.4em; }
div.float img, div.float .caption {text-align:center;}
div.figure img, div.figure .caption {text-align:center;}
.marginpar {width:20%; float:right; text-align:left; margin-left:auto; margin-top:0.5em; font-size:85%; text-decoration:underline;}
.marginpar p{margin-top:0.4em; margin-bottom:0.4em;}
.equation td{text-align:center; vertical-align:middle; }
td.eq-no{ width:5%; }
table.equation { width:100%; } 
div.math-display, div.par-math-display{text-align:center;}
math .texttt { font-family: monospace; }
math .textit { font-style: italic; }
math .textsl { font-style: oblique; }
math .textsf { font-family: sans-serif; }
math .textbf { font-weight: bold; }
.partToc a, .partToc, .likepartToc a, .likepartToc {line-height: 200%; font-weight:bold; font-size:110%;}
.chapterToc a, .chapterToc, .likechapterToc a, .likechapterToc, .appendixToc a, .appendixToc {line-height: 200%; font-weight:bold;}
.index-item, .index-subitem, .index-subsubitem {display:block}
.caption td.id{font-weight: bold; white-space: nowrap; }
table.caption {text-align:center;}
h1.partHead{text-align: center}
p.bibitem { text-indent: -2em; margin-left: 2em; margin-top:0.6em; margin-bottom:0.6em; }
p.bibitem-p { text-indent: 0em; margin-left: 2em; margin-top:0.6em; margin-bottom:0.6em; }
.subsectionHead, .likesubsectionHead { margin-top:2em; font-weight: bold;}
.sectionHead, .likesectionHead { font-weight: bold;}
.quote {margin-bottom:0.25em; margin-top:0.25em; margin-left:1em; margin-right:1em; text-align:justify;}
.verse{white-space:nowrap; margin-left:2em}
div.maketitle {text-align:center;}
h2.titleHead{text-align:center;}
div.maketitle{ margin-bottom: 2em; }
div.author, div.date {text-align:center;}
div.thanks{text-align:left; margin-left:10%; font-size:85%; font-style:italic; }
div.author{white-space: nowrap;}
.quotation {margin-bottom:0.25em; margin-top:0.25em; margin-left:1em; }
h1.partHead{text-align: center}
.sectionToc, .likesectionToc {margin-left:2em;}
.subsectionToc, .likesubsectionToc {margin-left:4em;}
.sectionToc, .likesectionToc {margin-left:6em;}
.frenchb-nbsp{font-size:75%;}
.frenchb-thinspace{font-size:75%;}
.figure img.graphics {margin-left:10%;}
/* end css.sty */

\title{Reduction des formes quadratiques en dimension finie}
\author{}
\date{}

\begin{document}
\maketitle

\textbf{Warning: 
requires JavaScript to process the mathematics on this page.\\ If your
browser supports JavaScript, be sure it is enabled.}

\begin{center}\rule{3in}{0.4pt}\end{center}

[
[
[]
[

\section{12.3 Réduction des formes quadratiques en dimension
finie}

\subsection{12.3.1 Familles et bases orthogonales}

Définition~12.3.1 Soit E un K-espace vectoriel ~et \Phi une forme
quadratique sur E de forme polaire \phi. Soit (e_i)_i\inI
une famille d'éléments de E. On dit que la famille est

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) orthogonale si i\neq~j \rigtharrow~
  \phi(e_i,e_j) = 0
\item
  (ii) orthonormée si \forall~~i,j,
  \phi(e_i,e_j) = \delta_i^j
\end{itemize}

Proposition~12.3.1 Une famille orthogonale ne contenant pas de vecteur
isotrope est libre~; en particulier toute famille orthonormée est libre.

Démonstration Soit (e_i)_i\inI une famille orthogonale.
Soit (\lambda_i)_i\inI des scalaires tels que
\i \in
I∣\lambda_i\mathrel\neq~0\
est fini et \\sum ~
\lambda_ie_i = 0. Soit k \in I. On a alors

0 = \phi(e_k,\sum \lambda_ie_i~)
= \sum \lambda_i\phi(e_k,e_i~) =
\lambda_k\phi(e_k,e_k) = \lambda_k\Phi(e_k)

Comme \Phi(e_k)\neq~0, on a \lambda_k =
0 ce qui montre que la famille est libre.

En dimension finie nous nous intéresserons tout particulièrement aux
bases qui sont orthogonales ou même mieux orthonormées.

Proposition~12.3.2 Soit E un K-espace vectoriel ~de dimension finie et \Phi
une forme quadratique sur E de forme polaire \phi. Soit \mathcal{E} une base de E.
Les propositions suivantes sont équivalentes

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  (i) \mathcal{E} est une base orthogonale (resp. orthonormée)
\item
  (ii) \mathrmMat~ (\phi,\mathcal{E}) est
  diagonale (resp. la matrice identité)
\item
  (iii) \forall~~x \in E, \Phi(x) =\
  \sum  \alpha_ix_i^2~
  (resp. \Phi(x) = \\sum ~
  x_i^2) si x =\
  \sum  x_ie_i~.
\end{itemize}

Démonstration Evident puisque
\mathrmMat~ (\phi,\mathcal{E}) =
(\phi(e_i,e_j))_1\leqi,j\leqn.

Théorème~12.3.3 Soit E un K-espace vectoriel ~de dimension finie et \Phi
une forme quadratique sur E de forme polaire \phi. Alors il existe des
bases de E orthogonales pour \phi.

Démonstration Nous allons montrer ce résultat par récurrence sur
dim E. Pour \dim~ E =
1, il n'y a rien à démontrer toute base étant orthogonale. Supposons le
résultat démontré pour tout espace vectoriel de dimension n - 1 et soit
E de dimension n. Si \Phi = 0, alors toute base est orthogonale. Sinon,
soit a \in E tel que \Phi(a)\neq~0~; on a
a\neq~0 et on peut donc compléter a en une base
(a,v_2,\\ldots,v_n~)
de E. Posons e_i = v_i + \lambda_ia et cherchons à
déterminer \lambda_i pour que \phi(a,e_i) = 0~; ceci conduit à
l'équation \phi(a,v_i) + \lambda_i\Phi(a) = 0, soit encore
\lambda_i = - \phi(a,e_i) \over \Phi(a) . Les
\lambda_i (et donc les e_i) étant ainsi choisis, la famille
(a,e_2,\\ldots,e_n~)
est encore une base de E (on vérifie facilement qu'elle est libre et
elle a le bon cardinal), avec \forall~~i \in [2,n],
e_i \bot a. Soit H =\
\mathrmVect(e_2,\\ldotse_n~)~;
on a donc a \bot H. Par hypothèse de récurrence, H admet une base
(a_2,\\ldots,a_n~)
orthogonale pour \Phi__H (et donc pour \Phi).
Comme Ka et H sont supplémentaires dans E,
(a,a_2,\\ldots,a_n~)
est une base de E et elle est orthogonale pour \phi.

Corollaire~12.3.4 Soit A \in M_K(n) une matrice symétrique. Alors
il existe une matrice inversible P telle que ^tPAP soit
diagonale.

Démonstration Soit \Phi la forme quadratique sur K^n dont la
matrice dans la base canonique \mathcal{E} est A. Soit \mathcal{E}' une base orthogonale
pour \phi et P la matrice de passage de \mathcal{E} à \mathcal{E}'. Alors la matrice de \phi dans
la base \mathcal{E}' est ^tPAP et elle est diagonale.

Remarque~12.3.1 On prendra soin de ne pas confondre ^tPAP et
P^-1AP~; ce corollaire ne concerne aucunement une quelconque
diagonalisabilité de la matrice A (dont nous verrons qu'elle dépend
essentiellement du corps de base).

Soit E un K-espace vectoriel ~de dimension finie et \Phi une forme
quadratique sur E de forme polaire \phi. Soit \mathcal{E} une base orthogonale de E.
Alors la matrice de \phi dans la base \mathcal{E} est diagonale donc de la forme

\left
(\matrix\,\alpha_1&0&\\ldots~&0
\cr 0
&⋱&\mathrel⋱&\⋮~
\cr \⋮~
&⋱&\mathrel⋱&0
\cr 0
&\\ldots&0&\alpha_n~\right
)

et quitte à permuter les vecteurs de base on peut supposer que
\alpha_1\neq~0,\\ldots,\alpha_r\mathrel\neq~0,\alpha_r+1~
= \\ldots~ =
\alpha_n = 0 pour un certain r \in [0,n]. On a bien entendu r
=\
\mathrmrg\mathrmMat~
(\phi,\mathcal{E})) = \mathrmrg~\phi ce qui
montre que r ne dépend pas de la base choisie. Les vecteurs
e_r+1,\\ldots,e_n~
sont bien entendu dans
\mathrmKer~\phi (étant
orthogonaux à tous les autres vecteurs de base mais aussi à eux mêmes,
ils sont orthogonaux à tout vecteur de E)~; mais
dim~
\mathrmKer~\phi = n
-\mathrmrg~\phi = n - r. On en
déduit que ces vecteurs forment une base de
\mathrmKer~\phi et que donc
\mathrmKer~\phi
=\
\mathrmVect(e_r+1,\\ldots,e_n~).
Donnons nous d'autre part
\lambda_1,\\ldots,\lambda_r~
non nuls et considérons la base \mathcal{E}' =
(\lambda_1e_1,\\ldots,\lambda_re_r,e_r+1,\\\ldots,e_n~).
Il s'agit encore d'une base orthogonale et

\mathrmMat~ (\phi,\mathcal{E}) =
\left
(\matrix\,\lambda_1^2\alpha_1&0&\\ldots~
&0&0 \cr 0
&⋱&\mathrel⋱
&\\ldots&\\⋮~
\cr \⋮~
&⋱&\lambda_r^2\alpha_r&\mathrel⋱&\⋮~
\cr \⋮~
&\\ldots&\mathrel⋱~
&0&⋱ \cr
\⋮~
&\\ldots&\\\ldots~
&⋱&\mathrel⋱\right
)

On voit donc que l'on peut multiplier
\alpha_1,\\ldots,\alpha_r~
par des carrés non nuls arbitraires. En particulier, si
\alpha_1,\\ldots,\alpha_r~
sont des carrés, en prenant \lambda_i tel que \lambda_i^2
= 1 \over \alpha_i on obtient une base dans
laquelle

\mathrmMat~ (\phi,\mathcal{E}) =
\left
(\matrix\,I_r&0
\cr 0 &0\right )

Si K est algébriquement clos, tout élément de K est un carré et cette
réduction est toujours possible. On a donc

Théorème~12.3.5 Soit K un corps algébriquement clos, E un K-espace
vectoriel ~de dimension finie et \Phi une forme quadratique sur E de forme
polaire \phi, de rang r. Alors il existe des bases (orthogonales) de E
telles que \mathrmMat~ (\phi,\mathcal{E})
= \left
(\matrix\,I_r&0
\cr 0 &0\right ). En particulier, si \Phi
est non dégénérée, il existe des bases orthonormées de E.

Corollaire~12.3.6 Soit K un corps algébriquement clos et A,B \in
M_K(n) des matrices symétriques. Alors A et B sont congruentes
si et seulement si~elles ont même rang. En particulier, si A est une
matrice symétrique inversible, il existe P inversible telle que A =
^tPP.

Démonstration Le premier point résulte immédiatement du théorème. En ce
qui concerne le deuxième, si A est une matrice symétrique inversible,
elle est congruente à l'identité, donc il existe P inversible telle que
A = ^tPI_nP = ^tPP.

\subsection{12.3.2 Décomposition en carrés. Algorithme de Gauss}

Théorème~12.3.7 (décomposition en carrés). Soit E un K-espace vectoriel
~de dimension finie et \Phi une forme quadratique sur E. Alors il existe
des formes linéaires
f_1,\\ldots,f_r~
linéairement indépendantes et des scalaires
\alpha_1,\\ldots,\alpha_r~
non nuls tels que \forall~~x \in E, \Phi(x)
= \\sum ~
_i=1^r\alpha_if_i(x)^2. Dans toute
telle décomposition, on a
\mathrmrg~\Phi = r.

Démonstration Soit \mathcal{E} =
(e_1,\\ldots,e_n~)
une base orthogonale pour \Phi, A =\
\mathrmdiag(\alpha_1,\\ldots,\alpha_n~)
la matrice de \Phi dans la base \mathcal{E}. Quitte à permuter la base, on peut
supposer que
\alpha_1\neq~0,\\ldots,\alpha_r\mathrel\neq~~0
et que \alpha_r+1 =
\\ldots~ =
\alpha_n = 0. Dans une telle base, on a, en notant
(e_1^∗,\\ldots,e_n^∗~)
la base duale de \mathcal{E},

\Phi(x) = ^tXAX = \\sum
_i=1^r\alpha_ ix_i^2 =
\sum _i=1^r\alpha~_
ie_i^∗(x)^2

ce qui montre l'existence d'une telle décomposition avec f_i =
e_i^∗ pour 1 \leq i \leq r. Inversement, considérons une telle
décomposition. Comme la famille
(f_1,\\ldots,f_r~)
est libre, on peut la compléter en une base
(f_1,\\ldots,f_n~)
de E^∗~; cette base est la base duale d'une unique base
(e_1,\\ldots,e_n~)
de E. Si x = \\sum ~
x_ie_i, alors

\Phi(x) = \sum _i=1^r\alpha~_
if_i(x)^2 = \\sum
_i=1^r\alpha_ ie_i^∗(x)^2
= \sum _i=1^r\alpha~_
ix_i^2

On en déduit que la matrice de \Phi dans la base \mathcal{E} est la matrice
\mathrmdiag(\alpha_1,\\\ldots,\alpha_r,0,\\\ldots~,0),
ce qui montre que r est le rang de \Phi.

Remarque~12.3.2 La démonstration précédente montre qu'à toute base
orthogonale de E est associée une telle décomposition en carrés de \Phi et
qu'inversement à toute telle décomposition (avec
f_1,\\ldots,f_r~
linéairement indépendantes) correspond une base orthogonale. Les
problèmes de la décomposition en carrés d'une forme quadratique ou de la
construction d'une base orthogonale sont donc équivalents (ils sont en
fait duaux l'un de l'autre). Nous allons commencer par un algorithme de
décomposition en carrés en renvoyant au subsectione suivant un algorithme
de construction de bases orthogonales.

Pour décrire un algorithme de décomposition en carrés de formes
linéaires nous allons travailler sur les polynômes homogènes. Soit en
effet \mathcal{E} une base de E. Il existe un unique polynôme homogène de degré 2,
P \in
H_2(X_1,\\ldots,X_n~),
tel que \Phi(x) =
P(x_1,\\ldots,x_n~)
si x = \\sum ~
x_ie_i. De même, si f est une forme linéaire sur E, on
a f = \\sum ~
a_ie_i^∗, d'où f(x) =\
\sum  a_ix_i~ =
F(x_1,\\ldots,x_n~)
où F est un polynôme homogène de degré 1~; inversement à tout tel
polynôme homogène de degré 1 est associée une unique forme linéaire. Une
traduction du théorème de décomposition en carrés est donc

Proposition~12.3.8 Soit P \in
K[X_1,\\ldots,X_n~]
un polynôme homogène de degré 2. Alors il existe des polynômes homogènes
de degré 1,
P_1,\\ldots,P_r~,
linéairement indépendants et des scalaires non nuls
\alpha_1,\\ldots,\alpha_r~
tels que P = \\sum ~
_i=1^r\alpha_iP_i^2.

Algorithme de Gauss

L'algorithme de Gauss va permettre d'expliciter une telle décomposition
en travaillant par récurrence sur le nombre n de variables du polynôme P
(en considérant par convention que pour n = 0, le polynôme est nul).

Si n = 1, alors P(X_1) = \alpha_1X_1^2 et
on a soit r = 0 si \alpha_1 = 0, soit P(X_1) =
\alpha_1P_1(X_1)^2 avec
P_1(X_1) = X_1 si
\alpha_1\neq~0.

Supposons donc connue une telle décomposition pour tout polynôme à n - 1
ou n - 2 variables. Soit P \in
K[X_1,\\ldots,X_n~]
un polynôme homogène de degré 2 à n variables. On a donc

P(X_1,\\ldots,X_n~)
= \sum \omega_i,iX_i^2~ +
2\\sum
_i<j\omega_i,jX_iX_j

Distinguons alors deux cas

Premier cas~: il existe i \in [1,n] tel que
\omega_i,i\neq~0. Quitte à permuter les noms
des variables, on peut supposer que
\omega_n,n\neq~0. Utilisant une mise sous
forme canonique du trinome du second degré en la variable X_n,
on peut donc écrire

P(X_1,\\ldots,X_n~)
= \omega_n,n\left (X_n +
\sum _i=1^n-1 \omega_i,n~
\over \omega_n,n X_i\right
)^2 + Q(X_
1,\\ldots,X_n-1~)

où Q est un polynôme homogène de degré 2 en n - 1 variables. D'après
l'hypothèse de récurrence, on peut écrire Q =\
\sum ~
_i=1^k\alpha_iP_i^2 où P_i \in
K[X_1,\\ldots,X_n-1~]
\subset~
K[X_1,\\ldots,X_n~],
les P_i étant homogènes de degré 1 et linéairement
indépendants, les \alpha_i étant non nuls. En posant P_k+1
= X_n +\ \\sum
 _i=1^n-1 \omega_i,n \over
\omega_n,n X_i et \alpha_k+1 =
\omega_n,n\neq~0 on a alors P
= \\sum ~
_i=1^k+1\alpha_iP_i^2~; il nous reste
à vérifier que
P_1,\\ldots,P_k+1~
sont linéairement indépendants. Mais si \lambda_1P_1 +
\\ldots~ +
\lambda_k+1P_k+1 = 0, en considérant le coefficient de la
variable X_n (qui ne figure que dans P_k+1 avec le
coefficient 1), on a \lambda_k+1 = 0~; mais alors, comme la famille
(P_1,\\ldots,P_k~)
est libre, on a \forall~i \in [1,k], \lambda_i~ =
0, ce qui termine le traitement de ce cas.

Deuxième cas~: pour tout i \in [1,n], on a \omega_i,i = 0, mais il
existe i et j tels que i < j et
\omega_i,j\neq~0. Quitte à permuter les noms
des variables, on peut supposer que
\omega_n-1,n\neq~0. On a alors

\begin{align*}
P(X_1,\\ldots,X_n~)
= 2\\sum
_i<j\omega_i,jX_iX_j&& \%&
\\ & =&
2\omega_n-1,n\left (X_n-1 +
\sum _i=1^n-2 \omega_i,n~
\over \omega_n-1,n
X_i\right )\left (X_n
+ \sum _i=1^n-2~
\omega_i,n-1 \over \omega_n-1,n
X_i\right )\%& \\
& \text &
+Q(X_1,\\ldots,X_n-2~)
\%& \\ \end{align*}

où Q est un polynôme homogène de degré 2 en n - 2 variables. D'après
l'hypothèse de récurrence, on peut écrire Q =\
\sum ~
_i=1^k\alpha_iP_i^2 où P_i \in
K[X_1,\\ldots,X_n-2~]
\subset~
K[X_1,\\ldots,X_n~],
les P_i étant homogènes de degré 1 et linéairement
indépendants, les \alpha_i étant non nuls. Utilisant l'identité 2ab
= 1 \over 2 \left ((a +
b)^2 - (a - b)^2\right ), on obtient
alors P = \\sum ~
_i=1^k+2\alpha_iP_i^2 avec
\alpha_k+1 = -\alpha_k+2 = \omega_n-1,n
\over 2 ,

P_k+1 = X_n-1 + X_n +
\sum _i=1^n-2 \omega_i,n~ +
\omega_i,n-1 \over \omega_n-1,n X_i

et

P_k+2 = X_n-1 - X_n +
\sum _i=1^n-2 \omega_i,n~ -
\omega_i,n-1 \over \omega_n-1,n X_i

Il nous reste à vérifier que
P_1,\\ldots,P_k+2~
sont linéairement indépendants. Si \lambda_1P_1 +
\\ldots~ +
\lambda_k+2P_k+2 = 0, en considérant le coefficient de la
variable X_n-1 (qui ne figure que dans P_k+1 et
P_k+2), on a \lambda_k+1 + \lambda_k+2 = 0 et en
considérant le coefficient de la variable X_n (qui ne figure
que dans P_k+1 et P_k+2), on a \lambda_k+1 -
\lambda_k+2 = 0~; on a donc \lambda_k+1 = \lambda_k+2 = 0~;
mais alors, comme la famille
(P_1,\\ldots,P_k~)
est libre, on a \forall~i \in [1,k], \lambda_i~ =
0, ce qui termine le traitement de ce cas.

Troisième cas~: \Phi est la forme quadratique nulle, et il n'y a rien à
faire.

Ceci achève la description de l'algorithme de Gauss.

[
[
[
[

\end{document}
